\chapter{Akcelerator śledzenia promieni z użyciem układu FPGA}
\section{Założenia}
Wszystko, o czym wspomniano do tej pory w poprzedzających rozdziałach miało na celu stworzyć podwaliny teoretyczne, które mogą zostać wykorzystane w praktyce do budowy systemu śledzenia promieni w oparciu o układy FPGA. Projekt, którego realizacji się podjęto zakładał od samego początku:
\begin{enumerate}
\item Przy użyciu Vivado HLS
\item zaprojektowanie modułu do akceleracji grafiki metodą śledzenia promieni,
\item zdolnego do wizualizacji świata złożonego z prostych kształtów geometrycznych,
\item których powierzchnie zachowują się zgodnie z odpowiednimi funkcjami BSDF,
\item w czasie rzeczywistym.
\end{enumerate}

Chociaż sposób wykonania projektu był zmieniany w czasie, powyższe wymagania pozostawały aktualne. Warto jednak w tym momencie dokonać sprecyzowania każdego z nich.

\begin{enumerate}
\item Głównym, nadrzędnym celem pracy była ewaluacja możliwości Vivado HLS, jako narzędzia umożliwiającego porzucenie konfiguracji za pomocą HDL na rzecz opisu algorytmicznego w języku podobnym do C/C++. W momencie rozpoczęcia projektu znane były wyniki i wnioski z prac eksperymentalnych używających tego narzędzia w pewnych typowych zastosowaniach. Szczególnie ważna okazała się być informacja, o tym, że Vivado HLS posiada tendencję do tworzenia opisu RTL powodującego użycie stosunkowo dużej ilości elementów logicznych znajdujących się w układzie. Chcąc mieć swobodę w tworzeniu funkcjonalności należało dysponować układem FPGA o odpowiednio dużej ilości elementów logicznych, dlatego do projektu wybrano układ \textit{Virtex 7} znajdujący się na płytce ewaluacyjnej \textit{VC707}~\cite{VC707_UG}, który został później zastąpiony przez układ \textit{Kintex UltraScale+} wchodzący w skład płytki ewaluacyjnej \textit{KCU116}~\cite{KCU116_UG}. 
\addimage{chapters/ch3/img/vc707.jpg}{scale=0.75}{Płytka ewaluacyjna VC707. Oprócz układu FPGA znajdującego się pod widocznym na zdjęciu układem chłodzenia, płytka ewaluacyjna udostępnia do wykorzystania wiele interfejsów danych i sposobów komunikacji, które mogą zostać użyte przez projektanta w realnym systemie przetwarzania danych~\cite{VC707_UG}}{Płytka ewaluacyjna VC707}{ch3:img:vc707}
Użycie płytek ewaluacyjnych ma tę zaletę, iż wraz z nimi użytkownik otrzymuje dostęp do funkcjonalności oferowanych przez dodatkowe elementy elektroniczne zamontowane na takich płytkach i mogące kooperować z układem FPGA w procesie przetwarzania danych. W kontekście omawianego projektu kluczowe okazały się być możliwość przechowywania danych w pamięci RAM oraz wykorzystanie komunikacji wizualnej zgodnej ze standardem HDMI~(obie wymienione płytki posiadają porty HDMI mogące służyć jako wyjście obrazu).
\begin{savenotes}
\begin{table}[H]
\centering
\caption{Porównanie podstawowych parametrów opisujących wykorzystane układy FPGA}
\label{ch3:tab:fpga_comp}
\begin{tabular}{|r|c|c|c|c|c|}
\hline
\multirow{2}{*}{} & \multicolumn{4}{c|}{\textbf{Elementy składowe}} & \multirow{2}{*}{\textbf{Proces technologiczny}} \\ \cline{2-5}
                  & BRAM\footnote{Każdy element pamięci blokowej BRAM jest w stanie przechowywać 18~kb danych. W układach FPGA z serii UltraScale oraz UltraScale+ występuje również dodatkowy typ pamięci zwany \textit{UltraRAM}, URAM co w zamierzeniu pozwala przechowywać większe ilości danych bezpośrednio w układzie FPGA~(każdy blok URAM może pomieścić 288 kb danych), zmniejszając konieczność odwoływania się do zewnętrznych zasobów a przez to zwiększając wydajność przetwarzania. }      & DSP\footnote{Moduły DSP znajdują zastosowanie w przypadku akceleracji działań arytmetycznych, zwłaszcza stałopozycyjnych~\cite{DSP48E1}\cite{DSP48E2}. Pozwalają na efektywniejszą implementację i uzyskiwanie wyższych częstotliwości pracy, niż gdyby te same operacje miały zostać wykonane za pomocą LUT.}       & FF         & LUT        &                                                                                 \\ \hline
\textbf{VC707}    & 2060      & 2800      & 607200     & 303600     & 28 nm                                                                   \\ \hline
\textbf{KCU116}   & 960       & 1824      & 433920     & 216960     & 16 nm                                                                \\ \hline
\end{tabular}
\end{table}
\end{savenotes}
Oba układy\footnote{Od tej pory, dla wygody, poprzez układ rozumieć należy tak płytkę ewaluacyjną jak i rodzaj układu FPGA, który na niej się znajduje. Związane jest to z faktem, iż pełne nazwy układów FPGA mają skomplikowaną postać zależną od m.in. rodziny, technologii, wielkości czy oceny szybkości~(ang. \textit{speed grade}) układu.} przedstawione w tabeli~\ref{ch3:tab:fpga_comp} posiadają stosunkowo dużą ilość podstawowych elementów, na bazie których można tworzyć funkcjonalność, jednak to VC707 jest znacznie większy pod względem dostępnych zasobów~(różnice zaczynają się od 40\% dla LUT i kończą na 115\% dla pamięci BRAM). Dziwić może zatem zmiana na układ o teoretycznie mniejszych możliwościach. Rzeczywiście KCU116 jest tylko teoretycznie gorszy - jego przewaga uwidoczniła się na etapie implementacji funkcjonalności, dzięki temu, iż jest to układ wykonany w znacznie nowszej technologii, dającej większe możliwości podczas procesu implementacji i łączenia ze sobą elementów za pomocą sieci konfigurowalnych połączeń.
\item U samych podstaw przetwarzania grafiki metodą śledzenia promieni leży fakt, iż obliczenia dotyczące jednej rodziny promieni~(na którą składają się wszystkie promienie powiązane z danym promieniem pierwotnym: odbite, załamane, promienie cieni) odpowiedzialnej za obliczenie koloru konkretnego piksela obrazu są niezależne od pozostałych rodzin. Wynika z tego, że w idealnym przypadku kolory wszystkich pikseli mogłyby być obliczane jednocześnie przez dedykowane dla każdego z nich układy przetwarzające. Realizacja takiego systemu w rzeczywistym układzie FPGA graniczy aktualnie z niemożliwością, choćby ze względu na wymagane w tym celu zasoby sprzętowe. Niemniej jednak udostępniane przez układy FPGA naturalne możliwości przetwarzania jednoczesnego dają duże szanse na zwiększenie efektywności algorytmu, względem jego wersji działającej na procesorze CPU komputera.
\item Jedną z podstawowych cech śledzenia promieni, o której wspomniano przy okazji porównania z rasteryzacją, jest fakt, iż jeśli tylko istnieje sposób matematycznego rozwiązania przecięcia powierzchni z promieniem, to można jej użyć w procesie renderowania bez konieczności stosowania triangulacji. Podczas gdy sfera opisana przez macierz jej przekształcenia jest jednym obiektem, który należy sprawdzić na drodze promienia, triangulacja kuli wymaga setek pojedynczych trójkątów, z którymi taki test trzeba przeprowadzić. Z jednej strony zaproponowane postępowanie niweluje potrzebę stosowania struktur akcelerujących, z drugiej zapewnia, iż uzyskiwane punkty przecięcia będą możliwie dokładne~(w zależności od precyzji obliczeń użytego typu danych).
\item Omawiana technika umożliwia uzyskiwanie realistycznych i interesujących obrazów dopiero wtedy, jeśli zostaną odpowiednio zastosowane różne techniki oświetlenia powierzchni. Tworzony system powinien oferować możliwość użycia różnych funkcji BSDF, które mogłyby być odpowiednio konfigurowane za pomocą parametrów.
\item Nie istnieje ścisła definicja działania programu w czasie rzeczywistym. W branży elektronicznej rozrywki~(tj. gry wideo) przyjmuje się, że minimalna częstotliwość generowania pełnych klatek obrazu, dla zachowania złudzenia płynności, nie powinna być niższa niż 25-30~(chociaż coraz częściej mówi się o 60). Możliwości szybkiego generowania obrazu używając śledzenia promieni zależą głównie od:
\begin{itemize}
\item rozdzielczości klatki obrazu,
\item ilości rozpatrywanych promieni w danej rodzinie,
\item ilości świateł i obiektów w scenie,
\item stosowanych funkcji BSDF.
\end{itemize} 
W związku z tym zachowawczo przyjęto, że jeśli tylko zaprogramowany układ będzie w stanie generować obrazy o rozdzielczości 1280 x 720 pikseli z uwzględnieniem pierwszej rodziny promieni wtórnych w czasie poniżej 0.1s, to efekt taki będzie można uznać za satysfakcjonujący. W sprawdzeniu warunku dostatecznej płynności~(poza standardowym pomiarem czasu wykonania) w praktyce miało pomóc użycie dostępnego na wykorzystywanych płytkach kodeka i portu HDMI\footnote{Poza tym w taki sposób najłatwiej zaprezentować możliwości stworzonego systemu podczas pokazów. Zamiast operować zbiorem statycznych scen, które wcale nie muszą być efektem działającego systemu w układzie FPGA, widz otrzymuje interaktywną~(np. poprzez zmianę położenia obserwatora z pomocą dostępnych na płytce przycisków dowolnego przeznaczenia) demonstrację, w którą jest w stanie uwierzyć.}.
\end{enumerate}

\section{Budowa systemu śledzenia promieni}
Tak postawiony problem można zasadniczo rozwiązać na dwa skrajnie różne sposoby wiążące się z zupełnie innymi wyzwaniami na etapie implementacji:
\begin{enumerate}
\item Stworzenie prostego układu procesorowego, pozwalającego przetwarzać podaną przez użytkownika listę rozkazów implementujących wymagany algorytm.
\item Zaprojektowanie modułu, który implementuje skończony zbiór zachowań~(algorytmów), których wywołanie może być sterowane poprzez parametry wejściowe, czyli tzw. \textit{potok przetwarzania o ustalonej funkcjonalności}~(ang. \textit{fixed pipeline}).
\end{enumerate}
O ile w pierwszym przypadku nadrzędnym celem jest to, aby instrukcje były wykonywane jak najszybciej, a sam układ potrzebował jak najmniej zasobów, o tyle w drugim przypadku może okazać się wyzwaniem pogodzenie ze sobą ilości oferowanych funkcji z dostępnym na układzie miejscem i koniecznością zapewnienia synchronizacji danych na etapie implementacji.

W obu przypadkach ważna jest kontrola nad utylizacją zasobów, która jest nierozerwalnie powiązana z wykorzystywanymi typami danych do przeprowadzenia obliczeń. W tabeli~\ref{ch3:tab:type_area_time} zestawiono jak dużo zasobów potrzeba do implementacji operacji dodawania, mnożenia, dzielenia i pierwiastkowania w przypadku posługiwania się różnymi typami danych oraz ile cykli zegara~(\#) należy oczekiwać na wynik w każdym przypadku. Widać, że w przypadku typów całkowitoliczbowych oraz stałopozycyjnych~(\texttt{ap\_fixed<W, N>}, gdzie \texttt{W} to ilość bitów przypadająca na pełen zapis liczby~(tzw. \textit{długość słowa}), \texttt{N} - bity części całkowitej ze znakiem, a pozostałe przypadają na zapis części ułamkowej) elementarne operacje tj. dodawanie i mnożenie mogą nie tylko być wykonywane w każdym cyklu zegara (\# = 1), ale również zajmują niewiele zasobów układu. Mniejszy z zaprezentowanych typów stałopozycyjnych \texttt{ap\_fixed\textless{}24, 18\textgreater{}} w celu wykonania mnożenia używa 1 zamiast 3 DSP, co może mieć znaczenie w przypadku układów o niwielkiej ilości tychże. Z drugiej strony typy całkowitoliczbowe oraz stałopozycyjne w przypadku dwóch innych działań~(a mających duże znaczenie w momencie rozwiązywania równań kwadratowych oraz normalizacji wektorów) mają albo bardzo duże opóźnienie~(dzielenie), albo wymagają dużej ilości LUT~(pierwiastkowanie). Chcąc dokonać implementacji pierwiastkowania liczby opisanej przez typ \texttt{ap\_fixed\textless{}32, 20\textgreater{}} w układzie VC707 należy liczyć się z koniecznością poświęcenia ok. 1,5\% wszystkich dostępnych LUT. Atrakcyjniej pod tym względem wyglądają typy zmiennoprzecinkowe, a zwłaszcza typy \texttt{half} oraz \texttt{float}. Dziwi jednak fakt, że pierwiastkowanie typu \texttt{half} wymaga znacznie więcej zasobów niż \texttt{float}, jednocześnie przechowując informację tylko o 16 bitach zamiast 32\footnote{Przykład ten ilustruje poziom zaawansowania obsługi typu \texttt{half} przez Vivado HLS.}. Tam gdzie typy całkowitoliczbowe oraz stałopozycyjne pokazywały swoją znaczną przewagę~(tj. dodawanie i mnożenie), tam liczby zmiennoprzecinkowe wymagają więcej zasobów a oczekiwanie na wynik jest dłuższy.  

Wybór reprezentacji danych jest ważnym etapem tworzenia rzeczywistego systemu przetwarzania. Należy odpowiedzieć sobie na pytanie, jakie dane będą przetwarzane oraz jakie będzie ich zróżnicowanie~(dynamika). Jeśli wykorzystywany jest 16 bitowy typ całkowitoliczbowy czy może dojść do sytuacji, że parametry iloczynu mogą dać wynik, który jest większy niż maksymalnie obsługiwany? Czy 8 bitów przeznaczonych na część ułamkową w zapisie stałopozycyjnym umożliwi poprawne znalezienie punktu przecięcia w każdej sytuacji, a jeśli nie to czy zwiększenie szerokości bitowej nie wpłynie negatywnie na inne metryki związane z tworzonym modułem IP? Jakie korzyści może przynieść zastosowanie reprezentacji zmiennoprzecinkowej, jeśli zadaniem układu jest głównie dokonywanie równolegle wielu operacji dodawania i mnożenia?  Podjęcie decyzji i odpowiedzialność za nią spoczywa na projektancie.

\begin{landscape}
\phantom{\rule{1em}{6em}}
\begin{table}[H]
\centering
\caption[Zestawienie typów danych wraz z estymacją wykorzystania poszczególnych zasobów oraz czasu wykonania dla podstawowych operacji arytmetycznych]{Zestawienie danych wraz z estymacją wykorzystania poszczególnych typów zasobów oraz czasu wykonania~(\#) dla podstawowych operacji arytmetycznych. W przypadku pierwiastkowania wartości typu \texttt{half} utylizacja LUT oraz FF musiała zostać oszacowana ze względu na fakt, iż Vivado HLS włącza operacje implementujące to działanie bezpośrednio do hierarchii funkcji, w której zostało wywołane. Do sporządzenia niniejszego zestawienia użyto Vivado HLS 2017.4 dla układu VC707 działającego z częstotliwością 100~MHz}
\label{ch3:tab:op_type_util_time}
\begin{tabular}{|r|l|l|l|l||l|l|l|l||l|l|l|l||l|l|l|l|}
\hline
\multicolumn{1}{|l|}{\multirow{2}{*}{}}           & \multicolumn{4}{c||}{\textbf{Dodawanie}}                                                                       & \multicolumn{4}{c||}{\textbf{Mnożenie}}                                                                       & \multicolumn{4}{c||}{\textbf{Dzielenie}}                                                                      & \multicolumn{4}{c|}{\textbf{Pierwiastek}}                                                                    \\ \cline{2-17} 
\multicolumn{1}{|l|}{}                            & \multicolumn{1}{c|}{LUT} & \multicolumn{1}{c|}{DSP} & \multicolumn{1}{c|}{FF} & \multicolumn{1}{c||}{\#} & \multicolumn{1}{c|}{LUT} & \multicolumn{1}{c|}{DSP} & \multicolumn{1}{c|}{FF} & \multicolumn{1}{c||}{\#} & \multicolumn{1}{c|}{LUT} & \multicolumn{1}{c|}{DSP} & \multicolumn{1}{c|}{FF} & \multicolumn{1}{c||}{\#} & \multicolumn{1}{c|}{LUT} & \multicolumn{1}{c|}{DSP} & \multicolumn{1}{c|}{FF} & \multicolumn{1}{c|}{\#} \\ \hline
\texttt{int}                                      & 39                       & 0                        & 0                       & 1                             & 21                       & 3                        & 0                       & 1                            & 238                      & 0                        & 394                     & 36                           & 1416                     & 0                        & 317                     & 5                            \\ \hline
\texttt{ap\_fixed\textless{}32, 20\textgreater{}} & 39                       & 0                        & 0                       & 1                             & 21                       & 3                        & 0                       & 1                            & 326                      & 0                        & 539                     & 48                           & 4720                     & 0                        & 1281                    & 8                            \\ \hline
\texttt{ap\_fixed\textless{}24, 18\textgreater{}} & 24                       & 0                        & 0                       & 1                             & 40                       & 1                        & 0                       & 1                            & 224                      & 0                        & 370                     & 34                           & 2414                     & 0                        & 433                     & 7                            \\ \hline
\texttt{half}                                     & 112                      & 2                        & 106                     & 4                             & 34                       & 2                        & 64                      & 3                            & 209                      & 0                        & 123                     & 5                            & $\sim$950                & 3                        & $\sim$180               & 6                            \\ \hline
\texttt{float}                                    & 214                      & 2                        & 227                     & 4                             & 135                      & 3                        & 128                     & 2                            & 802                      & 0                        & 359                     & 8                            & 508                      & 0                        & 238                     & 7                            \\ \hline
\texttt{double}                                   & 762                      & 3                        & 430                     & 4                             & 203                      & 11                       & 299                     & 5                            & 3253                     & 0                        & 1697                    & 17                           & 1912                     & 0                        & 1099                    & 17                           \\ \hline
\end{tabular}
\label{ch3:tab:type_area_time}
\end{table}

\end{landscape}

\subsection{Układ procesorowy}
Działanie najprostszego procesora polega na kolejnym~\cite{RISCV}:
\begin{enumerate}
\item Pobraniu instrukcji z listy i jej odkodowaniu.
\item Wykonaniu operacji zgodnie z przekazanym opisem.
\item Zapisaniu wyniku.
\item Powrotu do kroku 1. ze zmienionym wskaźnikiem kolejnej instrukcji.
\end{enumerate}
Dostępny dla użytkownika zbiór dozwolonych instrukcji zależy od twórcy danego procesora i określa on swobodę dotyczącą jego programowania. Dla przykładu, w przypadku, gdy nie istnieje sprzętowa obsługa operacji pierwiastkowania, można dokonać emulacji tej funkcjonalności poprzez odpowiednią sekwencję operacji elementarnych~\cite{FAST_INV_SQRT}. Przeważnie czas wykonania emulowanej funkcji będzie dłuższy niż gdyby procesor udostępniał dedykowaną do tego instrukcję. Z punktu widzenia wydajności ważne jest też, aby procesor był zdolny przetwarzać instrukcje z interwałem jak najbliższym 1 - wykorzystywana jest tutaj niezależność między poszczególnymi etapami przetwarzania instrukcji - z  możliwie najwyższą częstotliwością pracy. 

Jednym z kierunków rozwoju architektur procesorów jest poszukiwanie takiego rozwiązania, które udostępniałoby rozsądny zestaw instrukcji\footnote{Przez to sformułowanie należy rozumieć zachowanie balansu między możliwościami oddawanymi w ręce użytkownika a skomplikowaniem technologicznym.}, jednocześnie wymagając do jego implementacji jak najmniej zasobów sprzętowych. Warto w tym miejscu wspomnieć o projekcie \textit{iDEA}~\cite{iDEA}, który został stworzony od podstaw z myślą o maksymalnym wykorzystaniu znajdujących się w układach FPGA firmy Xilinx bloków DSP. Autorzy zauważyli, że elastyczność oferowana przez bloki DSP pozwala na implementację większości operacji bezpośrednio z ich użyciem. W efekcie uzyskano 32-bitowy procesor\footnote{Wszystkie dostępne instrukcje, za wyjątkiem mnożenia, przeprowadzane są na 32-bitowych liczbach całkowitych. Jedynie parametry mnożenia są ograniczone do 16 bitów~(wynik jest 32-bitowy), z uwagi na fakt, iż bloki DSP, w zależności od wersji, posiadają wbudowany blok dokonujący iloczynu czynników 25(27)- i 18-bitowego.} mogący pracować z częstotliwością ok.~400~MHz przy tym wymagający do jego implementacji jedynie 1~bloku~DSP, 2~BRAM oraz 335~LUT\footnote{Podane wartości dotyczą układu Virtex-6.}. Porównanie tych wartości z oferowanymi przez obecne układy FPGA zasobami~(tabela~\ref{ch3:tab:fpga_comp})  prowadzi do wniosku, że procesorów takiego lub bardziej rozbudowanego typu na jednym układzie można byłoby umieścić setki - otrzymując tym samym sieć procesorów zdolnych współbieżnie i stosunkowo szybko, jak na układy FPGA, przetwarzać dane. 

Na bazie tej obserwacji do tej pory powstało wiele prototypowych systemów, których celem była realizacja śledzenia promieni w czasie rzeczywistym scen o dowolnej złożoności. Wartym wspomnienia jest tutaj cykl prac~\cite{Realtime_FPGA}\cite{RPU}\cite{Realtime_ASIC}, gdzie autorzy szczegółowo przedstawiają, w jaki sposób udało im się osiągnąć zamierzony efekt poprzez bardzo dokładną analizę zależności między podsystemami: pamięci, procesorów oraz jednostek analizujących przecięcia promieni z geometrią i wykorzystanych przez nie zasobów układu FPGA. Udostępniając użytkownikowi możliwość generowania promieni wtórnych do 4 pokolenia, programowanie sposobu oświetlenia powierzchni~(użytkownik mógł tworzyć własne BRDF) oraz przetwarzania scen złożonych z milionów trójkątów rozwiązanie to potrafiło generować obraz z szybkością co najmniej 1 klatki obrazu na sekundę~(uwarunkowane jest to oczywiście poprzez rozdzielczość obrazu oraz złożoność sceny). Inne ciekawe rozwiązanie zostało zaproponowane w pracy~\cite{TRAX}. Jak podnoszą sami autorzy ich system był prostszy w budowie niż ten, o którym wspomniano wcześniej, jednak eksplorował w znacznie większym stopniu wykorzystanie hierarchicznej sieci prostych procesorów arytmetycznych. Pojedynczy rdzeń~(tych w układzie można było umieszczać dowolne ilości) składał się z 32 wątków zdolnych wykonywać podstawowe operacje na liczbach całkowitych oraz zmiennopozycyjnych jednak w obrębie rdzenia współdzieliły one między sobą jednostki odpowiedzialne za obliczanie iloczynów czy odwrotności liczby. Takie postępowanie było uzasadnione obserwacją, iż w kodzie programu operacje te są wykonywane odpowiednio rzadko i nie ma potrzeby, by każdy z wątków posiadał własne jednostki do przeprowadzania operacji arytmetycznych tego typu.

Cechą wspólną obu przedstawionych systemów śledzenia promieni jest to, że polegają one w znacznym stopniu na wydajności pojedynczego podsystemu przetwarzania instrukcji, który na dodatek musi być odpowiednio niewielki~(używać niewiele zasobów FPGA) aby można było współbieżnie przetwarzać wiele promieni. Co więcej ich twórcy podkreślają rolę języków opisu sprzętu w swobodnym kreowaniu sposobu przepływu danych w ich systemach.

\subsubsection{Projekt układu procesorowego z użyciem Vivado HLS}
Niniejszy projekt układu procesorowego wykonano dla układu VC707 przy użyciu Vivado Design Suite 2017.2\footnote{Pliki projektu zostały umieszczone w repozytorium dostępnym pod adresem:
\url{https://bitbucket.org/rtMasters/simpipeline/src/FINAL_SPU/}.}. Stworzony moduł IP zaprojektowano w taki sposób, aby jego uruchomienie z dostarczoną listą instrukcji oraz opcjonalnymi danymi zewnętrznymi skutkowało zapisem wartości do bufora klatki obrazu o podanych rozmiarach, stąd dla każdego piksela w pętli z zastosowaną dyrektywą \texttt{DATAFLOW} najpierw następuje wygenerowanie promienia o odpowiednim punkcie początkowym i kierunku, odpowiadającym rzutowaniu perspektywicznemu~(\texttt{CreateRay()}), potem następuje przetworzenie ciągu instrukcji (\texttt{ProcessInstructions()}), zwieńczone zapisem obliczonej wartości do bufora koloru~(\texttt{PutColor()}). Dalszy opis będzie skoncentrowany tylko na zagadnieniach związanych z przetwarzaniem rozkazów przez \texttt{ProcessInstructions()}.
\paragraph{Rejestry procesora i architektura instrukcji}
Z uwagi na fakt, iż śledzenie promieni wymaga przetwarzania danych wektorowych podjęta została decyzja o tym by procesor miał do swojej dyspozycji 16 $[0:15]$ wektorowych rejestrów wewnętrznych, z których każdy składa się z 4 32-bitowych elementów, co pozwoliłoby na przechowywanie większości potrzebnych danych. Każda instrukcja natomiast składa się z 4 wykonywanych jednocześnie podinstrukcji, których wynikiem w przypadku działań arytmetycznych jest skalar, którego wartość może być zapisana  do dowolnego rejestru wektorowego, jednakże indeks zapisu w rejestrze wektorowym jest jednakowy z indeksem podinstrukcji. Każda podinstrukcja jest opisana za pomocą 32-bitowej wartości, której rozmieszczenie i znaczenie poszczególnych bitów, w zależności od typu podinstrukcji, zostało ukazane na poniższym schemacie:
\addimage{chapters/ch3/img/instruction.png}{scale=0.43}{Rozmieszczenie bitów danych opisujących podinstrukcję}{Rozmieszczenie bitów danych opisujących podinstrukcję}{ch3:img:instruction}
\begin{itemize}
\item[] $[31:28]$ - \texttt{it} - opisuje rodzaj podinstrukcji, która ma być wykonana,
\item[] $[27:23]$ - \texttt{wr} - indeks rejestru wektorowego, do którego zostanie zapisany rezultat~(indeks skalara w wektorze jest dedukowany na podstawie numeru podinstrukcji),
\item[] $[22:21]$ - \texttt{idx0} - indeks skalara pierwszego parametru~(inne znaczenie w przypadku skoku warunkowego, patrz tabela~\ref{ch3:tab:instructions}),
\item[] $[20:29]$ - \texttt{idx1} - indeks skalara drugiego parametru~(inne znaczenie w przypadku skoku warunkowego, patrz tabela~\ref{ch3:tab:instructions}),
\item[] $[15:8]$ - \texttt{r0} - wartość liczbowa ze znakiem, wskazująca na indeks rejestru wektorowego będącego pierwszym parametrem, jeśli wartość jest ujemna tzn. $[15]=1$ wartość tego rejestru wzięta do obliczeń zostanie zanegowana,
\item[] $[7:0]$ - \texttt{r1} - wartość liczbowa ze znakiem, wskazująca na indeks rejestru wektorowego będącego drugim parametrem, jeśli wartość jest ujemna tzn. $[7]=1$ wartość tego rejestru wzięta do obliczeń zostanie zanegowana,
\item[] $[18:0]$ - \texttt{val} - stała podawana przez użytkownika
\end{itemize}
Stworzony procesor potrafi przetwarzać 16 instrukcji zebranych i opisanych w tabeli~\ref{ch3:tab:instructions}. Chociaż przedstawiony zbiór instrukcji jest niewielki, procesor jest w stanie dokonywać obliczeń przecięcia promieni z obiektami oraz dokonywać obliczeń koloru danego piksela~(zwłaszcza po uwzględnieniu obecności instrukcji \textbf{PRE\_S} oraz \textbf{PRE\_D}, które dokonują inicjalizujących manipulacji na parametrach będących wstępem do obliczeń przybliżonych metodą Newtona-Raphsona). 
\input{chapters/ch3/instructions}
\paragraph{Działanie procesora} Schemat przetwarzania został ukazany na rysunku~\ref{ch3:img:processing_pipeline}. 
\addimage{chapters/ch3/img/processing_pipeline.png}{scale=0.4}{Potok przetwarzania w stworzonym procesorze. Wejście stanowi lista instrukcji oraz dane zewnętrzne. W pętli zoptymalizowanej dyrektywą \texttt{PIPELINE} następuje pobranie instrukcji, jej odkodowanie a następnie przetworzenie przez układy logiczne i/lub arytmetyczny~(ALU). Wyniki są zapisywane do odpowiednich rejestrów i przetwarzana jest kolejna instrukcja. Po wykonaniu wszystkich instrukcji pierwszy z rejestrów wektorowych jest przyjmowany za ten, którego zawartość stanowi kolor piksela}{Potok przetwarzania w stworzonym procesorze}{ch3:img:processing_pipeline}
Widać na nim (oraz co wynika z analizy dostępnych instrukcji), że jest to układ nieskomplikowany, pozbawiony pamięci podręcznej czy możliwości zwrotnego asynchronicznego zapisu wartości poza układ za to z licznymi ograniczeniami~(opisanymi w uwagach w tabeli~\ref{ch3:tab:instructions}). Rzecz w tym, że Vivado HLS nie umożliwiło jego dalszej komplikacji i to przez co najmniej kilka przyczyn. 
\begin{enumerate}
\item Z uwagi na występujące w procesorach sprzężenie zwrotne między rejestrami, Vivado HLS dobiera taki interwał pomiędzy przetwarzaniem kolejnych instrukcji, aby w każdym przypadku zapis wyniku do rejestru następował przed jego możliwym odczytem związanym z przetwarzaniem kolejnej instrukcji. Teoretycznie zachowanie się Vivado HLS w przypadku wykrycia przez nie zależności między danymi można modyfikować dzięki zastosowaniu dyrektywy \texttt{DEPENDENCE}, jednak w żaden sposób nie udało się tego wymusić, a czas syntezy HLS znacznie wzrastał (z kilku minut do kilku godzin). Gdyby ta optymalizacja działała, należałoby z teoretycznymi zależnościami między instrukcjami radzić sobie poprzez odpowiednie napisanie kodu (zmieniając kolejność instrukcji bez wpływu na algorytm czy wstawiając instrukcje puste \texttt{NOP}) jednak nie istniałoby sztywne ograniczenie szybkości przetwarzania. 

Poleganie jedynie na statycznym osądzie HLS co do zależności między danymi wymusiło, aby operacje wykonywane przez jednostkę arytmetyczną~(ALU) były wykonywane jak najszybciej. Zgodnie z informacjami zawartymi w tabeli~\ref{ch3:tab:op_type_util_time} nadawały się do tego jedynie typy liczbowe stałopozycyjne, dla których czas wykonania operacji dodawania i mnożenia zawiera się w jednym cyklu zegara. Przyjęto zatem, że elementy skalarne rejestrów wektorowych będą typu \texttt{ap\_fixed<32, 16>}, zaś wartości, które są wczytywane bezpośrednio z przekazanej podinstrukcji~(\texttt{val}) \texttt{ap\_fixed<19, 13>}. Mimo takich zabiegów Vivado HLS mógł jedynie zaoferować interwał równy 3~(opóźnienie iteracji pętli wyniosło 12) przy częstotliwości zegara~100~MHz. 

\item Z podobnych przyczyn jak powyżej nie udało się dokonać implementacji skoków między partiami wykonywanego programu (skoki są ważne wszędzie tam, gdzie dochodzi do warunkowego wykonania określonej porcji instrukcji). W większości procesorów, gdy następuje konieczność wykonania skoku następuje wyczyszczenie potoku przetwarzania~(tzn. wszystkie instrukcje, które rozpoczęły być przetwarzane zanim znaleziono polecenie skoku są dyskredytowane, a wskaźnik na kolejną instrukcję jest ustalony w nowym miejscu). W prezentowanym rozwiązaniu teoretycznie istnieją polecenia dokonujące skoku \texttt{JMP}, \texttt{JMP\_IF}, \texttt{JMP\_IFN} jednak ich efektem działania jest tylko to, że wyniki przetwarzanych \texttt{unsigned(val)} instrukcji nie są zapisywane~(nie można też przez to cofać się w wykonaniu instrukcji, co uniemożliwia tworzenie pętli). W rezultacie każda dodana instrukcja, na którą składają się 4 podinstrukcje, dodaje stały przyczynek do czasu wykonania równy interwałowi~(3 cykle zegara). 

\item Implementacja powyższego procesora w strukturze układu VC707 wymaga stosunkowo dużej ilości zasobów~(tabela~\ref{ch3:tab:spu_util}). 

\begin{table}[H]
\centering
\caption[Wykorzystanie zasobów sprzętowych przez procesor instrukcji]{Wykorzystanie zasobów sprzętowych przez procesor instrukcji~(\texttt{ProcessInstructions()}). Dolny wiersz przedstawia procentowe wykorzystanie zasobów układu VC707 raportowane po syntezie HLS}
\label{ch3:tab:spu_util}
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{BRAM}} & \multicolumn{1}{c|}{\textbf{DSP}} & \multicolumn{1}{c|}{\textbf{FF}} & \multicolumn{1}{c|}{\textbf{LUT}} \\ \hline
0                                   & 64                                & 41457                            & 17404                             \\ \hline\hline
0\%                                 & 2,29\%                            & 6,83\%                           & 5,73\%                            \\ \hline
\end{tabular}
\end{table}

W dużej mierze wynika to z przyjętego przetwarzania 4 podinstrukcji jednocześnie, gdzie każda z nich może odwoływać się do dwóch dowolnych rejestrów wektorowych. Układy BRAM, które implementują funkcjonalność tablic umożliwiają do dwóch operacji dostępu w jednym cyklu zegara. Mogłoby się wydawać, że w takim razie pamięć związaną z rejestrami można podzielić na 4 i wtedy każda podinstrukcja będzie wykorzystywała dostępne dla siebie 2 operacje odczytu. Nie jest to prawdą, gdyż nieznany jest schemat dostępu do danych~(instrukcje wymagane przez użytkownika mogą odwoływać się dowolnie do rejestrów) stąd konieczność użycia kompletnego podziału tablicy (dyrektywa \texttt{ARRAY\_PARTITION}) rejestrów na poszczególne składowe - okupione jest to znacznym wzrostem zapotrzebowania na LUT i FF. Pozornym rozwiązaniem tego problemu, byłoby przejście na tradycyjny model przetwarzania tylko jednego rozkazu przez jedną instrukcję. Takie działanie wydłużyłoby tylko listę rozkazów lecz powyższe 2 problemy by pozostały.

\end{enumerate}

W celu sprawdzenia poprawności działania układu procesorowego, jakości wyników oraz estymacji czasu wykonania w typowym zastosowaniu stworzono prosty program testowy, którego celem było znalezienie odległości od obserwatora $O$ znajdującego się w początku układu współrzędnych $\vec{p_o} = [0; 0; 0]$ ustawionego w kierunku $\vec{d_p} = [0; 0; -1]$ do najbliższego punktu znajdującej się przed nim sfery o promieniu $R = 1$ i środku $\vec{p_s} = [0; 0; -2,5]$. W ten sposób wynikiem, który się otrzymuje jest tzw. \textit{mapa głębokości}\footnote{Opisywany dalej algorytm został zapisany jako ciąg instrukcji tekstowych w pliku \url{src/CodeParser/program.asm} znajdujący się w repozytorium projektu. Instrukcje te następnie są transformowane do kodu bajtowego interpretowalnego przez procesor z użyciem \url{src/CodeParser/PYCodeParser.py}.}. Transformacja sfery w przestrzeni była opisana poprzez macierz jej przekształcenia $\mathbf{M}$, a obliczeń dokonywano w przestrzeni tego obiektu\footnote{Postępowanie takie umożliwia deformację obiektu za pomocą odpowiedniej macierzy. Dodatkowo równania przecięcia, które należy rozwiązać, aby uzyskać wartość $t$, będącą odległością między obserwatorem a obiektem wzdłuż promienia, ulega uproszczeniu z postaci:
\begin{equation*}
\sum_{i=0}^2\left(r_i - p_{s_i} \right)^2 = R^2
\end{equation*}
do:
\begin{equation*}
\sum_{i=0}^2 r_i'^2 = 1
\end{equation*}

}. Wymagało to, aby promienie $\vec{r} = \vec{p_o} + t\vec{d}$ były transformowane za pomocą macierzy odwrotnej $\mathbf{M^{-1}}$~($\mathbf{MM^{-1} = I}$) do przestrzeni sfery $\vec{r}' = \mathbf{M^{-1}}\vec{r} = \vec{p_o}' + t'\vec{d}'$. 

Rozwiązanie równania przecięcia promienia ze sferą wymaga rozwiązania równania kwadratowego, a w szczególności obliczenia wyróżnika~$\sqrt{\Delta}$. W tym celu posłużono się  dostępną instrukcją \texttt{PRE\_S}, po której wywołano dwukrotnie ciąg instrukcji obliczający dwie iteracje metodą Newtona-Raphsona. Następnie obliczane były odległość od obserwatora $t'$\footnote{Z uwagi na fakt, iż kula była poddana jedynie translacji $t = t'$.} w przestrzeni obiektu, normalna w punkcie zderzenia $\vec{n}'$ oraz punkt przecięcia w przestrzeni obiektu $\vec{h_p}'$.

Wszystkie wspomniane operacje udało się opisać za pomocą 20 instrukcji, przy czym tylko 43 podinstrukcje z 80 były różne od \texttt{NOP}. Związane jest to z faktem, iż iteracyjne obliczanie pierwiastka kwadratowego wymagało w tym przypadku w sumie 10 instrukcji, a każda z nich wykorzystuje nie więcej niż 2 podinstrukcje. 

Program ten wykorzystano do stworzenia mapy głębokości o rozdzielczości 100~x~100 pikseli~($10^4$ punktów obrazu), która została zaprezentowana na rysunku~\ref{ch3:img:depth_map_sphere}. Ogólny przebieg zależności jest zbieżny z oczekiwanym - sfera w najbliższym dla obserwatora miejscu jest oddalona o $x=1,5$ jednostki, a w najdalszym $x=2,5$~(gdy promień jest niemal styczny do powierzchni sfery). Niepokojąca jest jednak zauważalna nieciągłość wartości  w okolicach $x\approx 1,75$ od obserwatora, a związana z przyjętą precyzją obliczeń~(\texttt{ap\_fixed<32, 16>}) i wykorzystaniem obliczeń przybliżonych użytych do obliczenia wyróżnika~$\sqrt{\Delta}$~(na rysunku~\ref{ch3:img:depth_map_sphere_cut} ukazany został jeden z profili odległości przechodzący przez punkt najbliższy obserwatorowi). 

\addimage{chapters/ch3/img/depth_map_sphere.png}{scale=0.5}{Mapa głębokości wykonana na podstawie obliczonych przez procesor danych. Sfera o promieniu $R=1$ i środku w punkcie $\vec{p_s} = [0; 0; -2,5]$ w najbliższym obserwatorowi miejscu, zgodnie z oczekiwaniami jest oddalona o wartość $x=1.5$}{Mapa głębokości wykonana na podstawie obliczonych przez procesor danych}{ch3:img:depth_map_sphere}
\addimage{chapters/ch3/img/depth_map_sphere_cut.png}{scale=0.5}{Profil odległości sfery od obserwatora przechodzący przez punkt najbliższy obserwatorowi. Widoczne są nieciągłości dla odległości $x\approx 1,75$ wynikające z precyzji obliczeń. Uzyskany profil nie jest kolisty ze względu na zniekształcenie perspektywy obserwatora}{Profil odległości sfery od obserwatora przechodzący przez punkt najbliższy obserwatorowi}{ch3:img:depth_map_sphere_cut}

Zgodnie z tym, co powiedziano wcześniej stworzony program składał się z 20 instrukcji, gdzie każda z nich jest wykonywana z interwałem równym 3. Wykonanie takiego programu dla wspomnianej rozdzielczości~($10^4$ pikseli) z zegarem 100~MHz~(1~cykl zegara odpowiada okresowi 10~ns) zajmuje:
\begin{equation}
20\cdot 3 \cdot 10^4 \cdot 10\ \mathrm{ns} = 6\ \mathrm{ms}
\end{equation}
z użyciem jednego procesora. Jednakże:
\begin{enumerate}
\item Przedstawiony program dokonuje tylko testu z jednym obiektem. Dodanie kolejnych obiektów wiąże się z dalszymi liniami kodu, które wydłużają czas wykonania liniowo.
\item Obliczenia, jak pokazano nie charakteryzują się wysoką precyzją. Zastosowanie liczb stałopozycyjnych~(wymuszone przez brak oczekiwanego działania dyrektywy \texttt{DEPENDENCE}) nakłada warunki m. in. na skalę sceny tzn. wielkości obiektów i odległości między nimi musiałyby być porównywalne.
\item Należy zwrócić uwagę, iż program ten nie dokonuje obliczenia koloru obiektu w wyniku oddziaływania ze źródłami światła oraz rozproszeń~(odbicia i załamania światła).
\item Obliczenia zostały wykonane dla zaledwie 1\% rozdzielczości docelowej.
\end{enumerate}
Nawet jeśli w strukturze układu FPGA udałoby się realnie umieścić 10 takich procesorów przetwarzających odpowiednią partię sceny i każdy z nich działałby z częstotliwością 150~MHz~(taką wartość udało się uzyskać po implementacji procesora w układzie VC707), otrzymana wydajność nie pozwoliłaby na osiągnięcie zamierzonych celów związanych ze stworzeniem systemu śledzenia promieni działającego w czasie rzeczywistym. Oczywista porażka w tym przypadku wynika z poświęcenia części elastyczności, którą zapewniają języki opisu sprzętu, na rzecz łatwego w interpretacji zapisu algorytmicznego poddawanego translacji do RTL za pomocą Vivado HLS. Zgodnie z tym co przedstawiono, Vivado HLS nie nadaje się do budowy modułów wymagających dużej kontroli nad sposobem przepływu danych oraz wykonaniem algorytmu. Użycie kodu C/C++ nie pozwala również na stworzenie w jednym module zadań wykonywanych asynchronicznie - te wymagane są do implementacji pamięci podręcznej czy struktur akcelerujących przetwarzanie przecięć promieni z geometrią sceny.

Kończąc opis tego rozwiązania, należy mieć na względzie, iż możliwość stworzenia za pomocą Vivado HLS szybkiego i małego~(w sensie utylizacji zasobów układu FPGA) procesora geometrii była przez długi czas główną koncepcją, na jakiej oparty miał być system generowania obrazów metodą śledzenia promieni. Przedstawiony tutaj procesor jest najszybszym ze stworzonych, aczkolwiek wniosek ten jest prawdziwy tak długo jak do syntezy wykorzystywana jest wersja 2017.2 Vivado Design Suite. Ten sam procesor poddany syntezie z użyciem wersji 2016.2 tego narzędzia z syntezą o takich samych parametrach tworzył moduł o interwale 5, zatem wyraźnie wolniejszy. Z drugiej jednak strony nowsza wersja nie potrafiła poprawnie planować wykonania zadań w regionie objętym dyrektywą \texttt{DATAFLOW}~(przez co jej wykorzystanie nie dawało żadnych korzyści w postaci zmniejszenia czasu wykonania) oraz nie umożliwiała wykonania testów tworzonego modułu w środowisku C/C++\footnote{Wymuszało to postępowanie, takie że synteza HLS była przeprowadzana w wersji 2017.2 narzędzia, zaś testy wykonywano w wersji 2016.2.}. Z drugiej strony nowsze wersje środowiska tzn. 2017.3 i nowsze w ogóle nie potrafią przeprowadzić syntezy przygotowanego kodu~(głównie ze względu na zmianę interfejsów funkcji odpowiedzialnych za obsługę liczb stałopozycyjnych, na których projekt opiera swoje działanie). Przytoczone obserwacje pokazują, że Vivado HLS ulega zmianom, nie zawsze tylko wszystkie zmiany w nim zachodzące są pożądane i aktualnie istnieje duży problem związany z wyborem optymalnej jego wersji.

\subsection{Wyspecjalizowany akcelerator o ustalonej funkcjonalności}
Wiedza oraz doświadczenie zdobyte podczas prac nad stworzeniem modułu śledzenia promieni opartego o przetwarzanie zestawu instrukcji miały się jednak przydać podczas projektowania zupełnie innego rozwiązania, opartego o zestaw funkcjonalności na stałe zakodowany w module. W porównaniu z procesorem, rozwiązanie to ma taką zaletę, że już na etapie syntezy Vivado HLS wie, jakie działania składają się na wykonanie algorytmu, a przez to jest w stanie optymalnie szeregować wykonanie operacji dla jak największej wydajności - o ile tylko program jest napisany wystarczająco starannie tzn. twórca ma świadomość, że to, co jest reprezentowane przez linie kodu będzie docelowo stanowić alokację fizycznych zasobów sprzętowych układu FPGA. Stąd od razu widać, iż dodanie każdej nowej funkcjonalności do tworzonego akceleratora, będzie wiązało się z wykorzystaniem pewnej części układu. Są to dwa wzajemnie wykluczające się czynniki warunkujące rozwój tego typu akceleratora. Trzecim jest wydajność. Omówione na początku tego rozdziału założenia narzucają, by interwał między obliczeniem koloru kolejnych pikseli był nie większy niż 10 cykli zegara przy częstotliwości pracy 100~MHz. Taki efekt można uzyskać jedynie wtedy, gdy stworzony algorytm umożliwia zastosowanie dyrektyw \texttt{PIPELINE} i/lub \texttt{DATAFLOW} w odpowiednich miejscach programu. Im wymagania względem interwału pracy bloku kodu objętego dyrektywą \texttt{PIPELINE} są wyższe~(tzn. interwał dąży do jedności), tym  Vivado HLS ma mniejsze możliwości w zakresie użycia tych samych zasobów na kolejnych etapach przetwarzania danych, w efekcie wzrasta utylizacja elementów układu FPGA.
\addimage{chapters/ch3/img/fpga_triangle.png}{scale=0.3}{Trójkąt zależności między sprzecznymi ze sobą charakterystykami akceleratora: funkcjonalnością, wydajnością oraz utylizacją zasobów}{Trójkąt zależności między sprzecznymi ze sobą charakterystykami akceleratora}{ch3:img:fpga_triangle}

W wyniku przeprowadzonych prac badawczo-rozwojowych powstał \textsc{ViRay}, czyli modularny system generowania obrazów metodą śledzenia promieni, implementowalny i działający w czasie rzeczywistym z użyciem układów FPGA firmy Xilinx. Jego podstawowa wersja została zoptymalizowana pod kątem układu  Kintex UltraScale+ znajdującego się na płytce ewaluacyjnej KCU116, a do jego stworzenia wykorzystano Vivado Design Suite w wersji 2017.4\footnote{Nazwa systemu jest skrótowcem od ang. \textit{Virtex ray tracer}, który został wymyślony jeszcze na samym początku prac, kiedy do dyspozycji Autora był układ Virtex~7.}\footnote{Pliki projektu dostępne są pod adresem: \url{https://bitbucket.org/rtMasters/ffcore/src/Oren-Nayar_correct/}}.

\addimage{chapters/ch3/img/viray_scheme.png}{scale=0.5}{Ogólna zasada działania modułu \textsc{ViRay}.}{Ogólna zasada działania modułu \textsc{ViRay}}{ch3:img:viray_scheme}

Ogólna zasada działania stworzonego modułu z użyciem Vivado HLS została przedstawiona na rysunku~\ref{ch3:img:viray_scheme}. Na początku w funkcji głównej~(\texttt{Init()}) dokonywana jest inicjalizacja wewnętrznych struktur danych na podstawie parametrów dostarczonych do modułu, po czym następuje główna pętla przetwarzania~(\texttt{RenderScene*()}), w której przeprowadzane są obliczenia dotyczące wszystkich żądanych pikseli obrazu zgodnie z dostarczonym opisem sceny. Tutaj dla każdego nowo obliczanego piksela, najpierw tworzony jest promień pierwotny~(\texttt{CreatePrimaryRay()}), który jest następnie testowany na wypadek przecięcia z obiektami~(\texttt{VisibilityTest()}). Jeśli zderzenie nastąpi, obliczany jest kolor piksela~(\texttt{Shade()}) oraz generowany jest rozproszony promień wtórny względem pierwotnego~(\texttt{ray = ray'}). Ten staje się w kolejnej iteracji promieniem odpowiedzialnym za dostarczenie informacji o świetle rozproszonym. Ilość iteracji, a przez to głębokość śledzenia promieni związanych z kolorem danego piksela jest konfigurowalna. Finalny kolor piksela opisany za pomocą trzech składowych czerwonej, zielonej i niebieskiej~(\texttt{RGB}) jest następnie zapisywany w buforze ramki~(\texttt{SaveColorToBuffer()}).

Modularność \textsc{ViRay}'a powoduje, że wiele kluczowych podsystemów biorących udział w tworzeniu finalnego obrazu może zostać ustalone za pomocą jednego pliku konfiguracyjnego~\texttt{typedefs.h}. Z jego pomocą można m. in.:
\begin{itemize}
\item określić pulę rodzajów i maksymalną ilość obiektów możliwych do renderowania przez system,
\item zmienić interwał między kolejnymi pikselami,
\item dostosować możliwości podsystemu odpowiedzialnego za teksturowanie obiektów lub całkowicie go wyłączyć,
\item wybrać, które z zaawansowanych modeli oświetlenia mają być dostępne w systemie,
\item usprawnić szybkość wykonania w środowisku testowym.
\end{itemize}
Każdy parametr jest osobną dyrektywą preprocesora~(\texttt{\#define}), a najważniejsze z nich zostały zebrane i opisane w tabeli~\ref{ch3:tab:typedefs}. Koncepcja modularności sprawia z jednej strony, iż kod programu jest dłuższy i bardziej skomplikowany poprzez zastosowanie konstrukcji typu:
\begin{lstlisting}
#ifdef DYREKTYWA
	a = 2;
#else
	a = 0.5;
#endif
\end{lstlisting}
jednak posiada niezrównaną zaletę, jaką jest możliwość łatwego dostosowania parametrów modułu do aktualnych potrzeb. Pozwala to na eksplorację najbardziej optymalnych rozwiązań pod kątem tego, co zilustrowane zostało na rysunku~\ref{ch3:img:fpga_triangle}. Na dodatek pozwala zastosować mniej wymagające algorytmy, jeśli implementacja napotyka problemy związane z wytworzeniem odpowiedniej sieci połączeń. Jest to też rozwiązanie przyszłościowe - dysponując nowszą generacją układów FPGA będzie można szybko ulepszyć charakterystykę systemu np. zmniejszając interwał czy zwiększając głębokość śledzenia promieni.

\input{chapters/ch3/typedefs}

\subsubsection{\textsc{ViRay} - najważniejsze komponenty modułu}
\begin{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item \underline{Inicjalizacja modułu}

Wejście modułu \textsc{ViRay} stanowi zespół wskaźników na tablice danych i wartości, które w jednoznaczny sposób przechowują definicję sceny tzn.:
\begin{itemize}
\item określają transformacje oraz typy obiektów geometrycznych,
\item zawierają parametry mówiące o materiale, z jakiego obiekt jest wykonany tj. BRDF, dane tekstury,
\item ustanawiają parametry związane ze źródłami światła,
\item definiują położenie, orientację w przestrzeni i inne podstawowe parametry kamery~(obserwatora).
\end{itemize}
Dane te przychodzą do modułu w postaci 32-bitowych liczb~(zmiennopozycyjnych oraz całkowitoliczbowych). W przypadku tablic, dane przez nie zawierane są zlinearyzowane tzn. każda tablica przechowuje dane o $k$ wektorach. Każdy 32-bitowy element takiego wektora, zależnie od jego położenia w tym wektorze, posiada odpowiednie znaczenie, które musi być odpowiednio zinterpretowane~(rysunek~\ref{ch3:img:decode}). Wymaga to zastosowania procedur, które na podstawie dostarczonych danych będą w stanie dokonać odpowiedniej inicjalizacji struktur wewnętrznych.
\addimage{chapters/ch3/img/decode.png}{scale=0.5}{Przykład zapisu danych w tablicach wejściowych. Elementy \texttt{a, b, c, d} niosą odpowiednie informacje o \texttt{i}-tym elemencie struktury danych odpowiedzialnej za jedną z części opisu sceny}{Przykład zapisu danych w tablicach wejściowych}{ch3:img:decode}
Alternatywnie, parametry wejściowe mogłyby zostać przekazane w formie tablic odpowiednich struktur, co uprościłoby proces inicjalizacji w module. W takiej sytuacji domyślnym zachowaniem Vivado HLS jest takie, że każdy element struktury staje się nowym portem danych.
\begin{lstlisting}
typedef struct{
	float s;
	float t;
}scale;
\end{lstlisting}
W sytuacji przedstawionej powyżej w wyniku syntezy zostaną utworzone oddzielne porty dla \texttt{s} oraz \texttt{t}. Jeśli \texttt{scale} jest tablicą, to \texttt{s}, \texttt{t} będą tak naprawdę portami odwołującymi się do tablic \texttt{s[]}, \texttt{t[]}. Stąd port odpowiadający \texttt{s[]} musiałby wskazywać na liniowy element przechowujący kolejne wartości \texttt{s} tablicy struktur \texttt{scale}. Takie rozwiązanie, choć działa, okazało się niepraktyczne w momencie obsługi modułu za pomocą mikrokontrolera. Zgodnie z dokumentacją Vivado HLS~\cite{UG902} możliwa jest jednak automatyczna linearyzacja struktur, skutkująca wygenerowaniem pojedynczego portu dla struktury za pomocą dyrektywy \texttt{DATA\_PACK}. Pomimo wielu testów, skuteczność tej dyrektywy nie została potwierdzona. Działa ona w przypadku, gdy struktura przechowuje dane całkowite oraz stałopozycyjne. Jeśli jednak zawarte są w niej wartości zmiennoprzecinkowe, odczytywane dane przez moduł nie są poprawne. 

W związku z powyższym, odkodowanie parametrów wejściowych jest dokonywane bezpośrednio przez algorytm, w sposób ręczny, gdyż tylko w taki sposób można zapewnić poprawność odczytu danych przy zachowaniu rozsądnej~(tj.~możliwie niskiej) liczby portów.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item \underline{Model kamery i parametry obrazu}

Jedynym udostępnianym przez \textsc{ViRay} modelem kamery jest kamera perspektywiczna~(rysunek~\ref{ch3:img:camera_model}) o nieskończonej głębi ostrości. Opisana jest ona poprzez następujące parametry:
\begin{itemize}
\item pozycję obserwatora (\texttt{eyePosition)} zadaną w globalnym układzie współrzędnych,
\item ortonormalną bazę wektorów $\vec{u}$, $\vec{v}$, $\vec{w}$ tworzących lokalny dla obserwatora prawoskrętny układ współrzędnych określający jego orientację w przestrzeni,
\item odległość rzutni (\texttt{nearPlane}) od obserwatora w kierunku $-\vec{w}$ definiującą pole widzenia,
\item parametr odpowiedzialny za powiększenie (\texttt{zoom}) - im jest on mniejszy, tym powiększenie większe.
\end{itemize}
Parametry rzutni tj. szerokość~(\texttt{WIDTH}) oraz wysokość~(\texttt{HEIGHT}) ramki obrazu muszą zostać podane w momencie syntezy HLS~(patrz tabela~\ref{ch3:tab:typedefs}). Kiedy rozpoczyna się przetwarzanie nowego piksela obrazu, wywoływana jest funkcja \texttt{GetCameraRayForPixel()}, która przyjmuje parametr zależny od współrzędnych piksela $[w; h] \in [0; \mathtt{WIDTH} - 1]\times[0; \mathtt{HEIGHT} - 1]$ - ten wpływa na kierunek propagacji nowego promienia pierwotnego.

\addimage{chapters/ch3/img/camera_model.png}{scale=0.5}{Kamera w module \textsc{ViRay}. Parametry kamery oraz położenie piksela w ramce obrazu~$[w;h]$ definiują początek oraz kierunek propagacji promienia pierwotnego}{Kamera w module \textsc{ViRay}}{ch3:img:camera_model}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item \underline{Konstrukcja głównej pętli przetwarzania \texttt{RenderScene*()}}

\textsc{ViRay} umożliwia wykorzystanie dwóch różnych konstrukcji głównej pętli przetwarzania, które ideowo przedstawiają się następująco:
\begin{enumerate}
\item {\color{white}a}

\begin{lstlisting}
for(unsigned h = 0; h < HEIGHT; ++h)
{
#pragma HLS DATAFLOW
	
	InnerLoop();
	memcpy();
}
void InnerLoop()
{
	...
	for(unsigned w = 0; w < WIDTH; ++w)
	{
	#pragma HLS PIPELINE
		...
	}
}
\end{lstlisting}
\item {\color{white}a}
\begin{lstlisting}
for(unsigned n = 0; n < NUM_OF_PIXELS; ++n)
{
#pragma HLS PIPELINE
	...
	memcpy();
}
\end{lstlisting}

\end{enumerate}
W przypadku (a) przetwarzanie pikseli obrazu zostało rozłożone na dwie pętle. Zewnętrzna dokonuje zmiany indeksu pionowego piksela \texttt{h}, zaś w wewnętrznej~(znajdującej się w funkcji \texttt{InnerLoop()}) z zastosowaną dyrektywą \texttt{PIPELINE} następuje obliczenie kolorów pełnego wiersza pikseli przy czym wszystkie piksele z wiersza zapisywane są do tymczasowego bufora pikseli, który jest w całości opróżniany do bufora ramki na koniec iteracji pętli zewnętrznej. Zachowanie takie pozwoliło wydzielić ciało zewnętrznej pętli jako region, który może zostać objęty dyrektywą \texttt{DATAFLOW}. Dane, czyli zawartość bufora tymczasowego, przepływają pomiędzy dwoma zadaniami tj.~obliczeniami, a zapisem do bufora ramki. Kiedy kończy się przetwarzanie danych w pętli wewnętrznej, dane przekazywane są do operacji zapisu \texttt{memcpy()} i w tym samym momencie wewnętrzna pętla może znowu rozpocząć pracę. Problem w takim przypadku, jest taki, iż kolejne obliczenia w pętli wewnętrznej nie stanowią kontynuacji dopiero co zakończonej funkcji \texttt{InnerLoop()} tzn. zanim zostanie wyliczony kolor pierwszego piksela w nowym wierszu minie czas równy opóźnieniu iteracji pętli wewnętrznej, który w finalnej wersji \textsc{ViRay}'a wynosi 1331 cykli zegara. Biorąc pod uwagę, iż ramka obrazu w jakości Full HD ma wysokość równą 1080 daje to niemal $1,43\cdot 10^6$ nadmiarowych cykli zegara\footnote{Nadmiarowa ilość cykli wynikająca z każdorazowego rozpoczęcia funkcji \texttt{InnerLoop()} wynosi: 
\begin{equation}
1331 - \mathtt{DESIRED\_INNER\_LOOP\_II} = 1331 - 8 = 1323
\end{equation}
}. Przy standardowym okresie zegara równym 10~ns, czas tracony tylko z tego powodu to 14,3~ms. Twórcy Vivado HLS przewidzieli występowanie takich sytuacji w tego typu konstrukcjach wprowadzając modyfikator \texttt{rewind} do dyrektywy \texttt{PIPELINE} stosowanej w pętlach. W zamierzeniu sprawia on, że pętla wykonywać będzie się bez przerw na ponowne rozpoczęcie działania, jednak na etapie tworzenia \textsc{ViRay}'a nie udało się takiego zachowania wymusić.

Najprostsze możliwe rozwiązanie, które można włączyć poprzez niezdefiniowanie \texttt{RENDER\_DATAFLOW\_ENABLE} w pliku konfiguracyjnym \texttt{typedefs.h} zostało przedstawione ideowo w przykładzie~(b). Implementuje ono przetwarzanie pikseli w pojedynczej pętli, której ciało zostało objęte dyrektywą \texttt{PIPELINE}. Indeksy piksela w ramce obrazu $[w;h]$ są obliczane na podstawie aktualnej wartości iteratora \texttt{n}, a kolor obliczonego piksela jest zapisywany do bufora ramki bezpośrednio po jego obliczeniu. Eliminuje to nie tylko problem z wielokrotnym rozpoczęciem pętli, ale również usuwa konieczność przechowywania wartości kolorów pikseli w tymczasowym buforze oszczędzając elementy BRAM. 

Wyprzedzając w pewien sposób kolejność prezentacji poszczególnych elementów składowych pełnego systemu śledzenia promieni należy powiedzieć, iż rozwiązanie~(b) jest nieimplementowalne w układzie KCU116 z częstotliwością pracy uzasadniającą jego użycie\footnote{Rozwiązanie typu~(a) nawet pomimo nadmiarowych cykli zegara uzyskiwało znacznie krótsze czasy wykonania z uwagi na odpowiednio wyższe częstotliwości pracy.}. 

W związku z powyższym zaproponowano, aby zmniejszyć częstość wywoływania \texttt{InnerLoop()} w przypadku~(a). Pętla wewnętrzna każdorazowo musiałaby przetwarzać więcej niż jeden wiersz bufora ramki, a wielkość bufora tymczasowego uległaby odpowiedniemu zwiększeniu. Ilość cykli zegara, które są potrzebne na przeprowadzenie obliczeń wszystkich pikseli ramki obrazu dana jest w przybliżeniu poniższą zależnością:
\begin{equation}
f(x) = \frac{\mathtt{HEIGHT}}{x}\left[IL + \left(\mathtt{WIDTH}\cdot x - 1 \right) \cdot c \right] + \mathtt{WIDTH}\cdot x = f_1(x) + f_2(x),
\label{ch3:eq:dataflow_latency}
\end{equation}
gdzie:
\begin{itemize}
\item[] $x$ - ilość wierszy obrazu obliczanych w jednym wywołaniu \texttt{InnerLoop()},
\item[] $IL$ - opóźnienie iteracji pętli wewnętrznej,
\item[] $c$ - interwał pętli wewnętrznej~(\texttt{DESIRED\_INNER\_LOOP\_II}).
\end{itemize}
Pierwszy składnik sumy $f_1(x)$ to przyczynek do całkowitego opóźnienia związany z obliczaniem pikseli obrazu, zaś $f_2(x)$ wyraża ilość cykli zegara wymaganą na zapis do bufora ramki ostatniej porcji danych przechowywanych w buforze tymczasowym~(wykorzystywany jest tryb seryjnego zapisu danych). Dla parametrów domyślnych systemu śledzenia promieni~(patrz tabela~\ref{ch3:tab:typedefs}) wykres funkcji $f(x)$ prezentuje się następująco:

\addimage{chapters/ch3/img/dataflow_opt.png}{scale=0.5}{Zależność czasu wykonania głównej pętli algorytmu w funkcji ilości wierszy obrazu $x$ liczonych przy jednym wywołaniu funkcji implementującej pętlę wewnętrzną \texttt{InnerLoop()}}{Optymalizacja czasu wykonania głównej pętli algorytmu}{ch3:img:dataflow_opt}

Z wykresu~\ref{ch3:img:dataflow_opt} widać, że znaczne oszczędności czasu wykonania można uzyskać już dla relatywnie niewielkich wartości $x$. Minimum globalne $f(x)$ można zaś wyliczyć z zależności:
\begin{align*}
\frac{\mathrm{d}f(x)}{\mathrm{d}x} &= -\frac{\mathtt{HEIGHT}\left(IL - c \right)}{x^2} + \mathtt{WIDTH} \equiv 0,\\
x &= \sqrt{\frac{\mathtt{HEIGHT}\left(IL - c \right)}{\mathtt{WIDTH}}} = 27,28\approx 27.
\end{align*}
Przyjęcie $x=27$ pozwala zaoszczędzić $1,326\cdot 10^6$ cykli zegara względem wersji niezoptymalizowanej~($x=1$). Trzeba tylko mieć na uwadze, że wielkość bufora tymczasowego w bitach zależy wprost proporcjonalnie od $x$: 
\begin{equation}
\mathtt{WIDTH}\cdot x \cdot 32\ \mathrm{b}.
\end{equation}
Stąd w finalnej wersji przyjęto, że $\mathtt{FRAME\_ROWS\_IN\_BUFFER}\equiv x = 20$ - taka wartość sprawia, że czas wykonania głównej pętli algorytmu \texttt{RenderScene*()} mierzony poprzez ilość cykli jest jedynie o 5082 cykle gorszy od minimalnego. Dokonując samodzielnych zmian parametru \texttt{FRAME\_ROWS\_IN\_BUFFER} należy zapewnić, aby podana wartość była dzielnikiem \texttt{HEIGHT}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item \underline{Przetwarzanie geometrii sceny}

Znalezienie przecięcia promienia z najbliższą  powierzchnią jest sednem całej metody śledzenia promieni. \textsc{ViRay} dokonuje testu przecięcia każdego promienia ze wszystkimi obiektami w scenie za pomocą funkcji \texttt{PerformHits()} oraz \texttt{PerformShadowHits()}. Nie jest to na pewno najbardziej optymalny sposób. Rzeczywiste systemy śledzenia promieni stosują struktury akcelerujące wykrywanie przecięć dzięki wielokrotnym podziałom przestrzeni na mniejsze podprzestrzenie. Aczkolwiek zgodnie z przyjętymi założeniami renderowane obiekty nie są złożone z siatek trójkątów, dzięki czemu każdy dostępny kształt geometryczny jest jednym obiektem w scenie. 

Test przecięcia polega na rozwiązaniu równania typu $f(\vec{r}) = f(\vec{o} + t\vec{d})= 0$, którego rozwiązaniem jest dodatnia liczba $t \in [\mathtt{CORE\_BIAS};\mathtt{MAX\_DISTANCE})$~(patrz tabela~\ref{ch3:tab:typedefs}). Zastosowanie \texttt{CORE\_BIAS} wynika z faktu skończonej precyzji obliczeń, które domyślnie wykonywane są za pomocą typu \texttt{float}~(\texttt{USE\_FLOAT}).

\addimage{chapters/ch3/img/core_bias.png}{scale=0.5}{Wykorzystanie \texttt{CORE\_BIAS} w teście przecięcia. Z uwagi na precyzję obliczeń test przecięcia {\color{green}promienia} z {\color{red}powierzchnią} może skutkować tym, że obliczony punkt znajdzie się pod {\color{red}powierzchnią} zamiast na niej. W takiej sytuacji, promienie wtórne wychodzące z tego punktu będą dawać fałszywie pozytywne testy przecięcia {\color{gray}promienia} z {\color{red}powierzchnią}, chyba że zostanie zastosowany parametr tolerancji \texttt{CORE\_BIAS}}{Wykorzystanie \texttt{CORE\_BIAS} w teście przecięcia}{ch3:img:core_bias}

Obliczenia dotyczące przecięcia promienia z powierzchniami przeprowadzane są w układzie współrzędnych związanym z obiektem. Ma to taką zaletę, że ogólne równania przecięcia $f(\vec{r})=0$ mogą zostać odpowiednio uproszczone oraz pozwala przekształcać obiekty w nietrywialny sposób. W tym celu należy dokonać transformacji promienia takiej, że:
\begin{equation}
\vec{r}' = \mathcal{T}^{-1}\left\lbrace\vec{r}\right\rbrace,
\end{equation}
gdzie:
\begin{itemize}
\item[] $\vec{r}'$ - promień w lokalnej przestrzeni obiektu,
\item[] $\mathcal{T}^{-1}$ - transformacja odwrotna względem transformacji $\mathcal{T}$ opisującej przekształcenie obiektu we współrzędnych globalnych.
\end{itemize}
Najogólniejsza forma podanego przekształcenia wymaga wykorzystania do opisu transformacji obiektów $\mathcal{T}$  macierzy $M$ postaci:
\begin{equation}
M = 
\begin{bmatrix}
    m_{11} & m_{12} & m_{13}  & t_{1} \\
    m_{21} & m_{22} & m_{23}   & t_{2} \\
    m_{31} & m_{32} & m_{33}   & t_{3} \\
    0 & 0 & 0 & 1 \\
\end{bmatrix}.
\end{equation}
Jej odwrotność $M^{-1}$ dokonuje transformacji promienia do przestrzeni obiektu w następujący sposób:
\begin{equation}
\vec{r}' = 
\begin{cases}
\vec{o}' = M^{-1}\vec{o}\\
\vec{d}' = M_{3\times 3}^{-1}\vec{d}
\end{cases},
\end{equation}
przy czym $M_{3\times 3}^{-1}$ jest macierzą złożoną tylko z elementów $m_{ij}$ macierzy $M^{-1}$.

Rozwiązanie równania $f(\vec{r}') = 0$ pozwala obliczyć punkt przecięcia $\vec{p}'$ oraz normalną do powierzchni  w tym punkcie $\vec{n}'$ w przestrzeni obiektu, które do dalszych obliczeń muszą zostać przetransformowane do globalnego układu współrzędnych za pomocą macierzy transformacji $M$ obiektu.

Z uwagi na stopień komplikacji, który uniemożliwia implementację w układzie FPGA, \textsc{ViRay} standardowo~(\texttt{SIMPLE\_OBJECT\_TRANSFORM\_ENABLE} jest zdefiniowane w pliku \texttt{typedefs.h}) umożliwia jedynie dokonywanie transformacji wyrównanych do osi globalnego układu współrzędnych. Oznacza to, że skalowanie oraz orientacja obiektów w przestrzeni jest ograniczona i nie może zachodzić w inny sposób niż wzdłuż wersorów globalnego układu\footnote{Paradoksalnie taka reprezentacja transformacji w znaczny sposób wpływa na przetwarzanie informacji o przecięciu, w skutek czego kod stał się bardziej skomplikowany i trudniejszy w interpretacji.}. 

Funkcja odpowiedzialna za odnalezienie najbliższego obiektu została wyposażona w możliwość testowania promieni z kulami, cylindrami, stożkami, płaszczyznami, dyskami i kwadratami. W pierwszych trzech przypadkach należy rozwiązać równanie kwadratowe ze względu na odległość $t$:
\begin{align*}
at^2 + bt + c = 0,\\
t_{1,2} = \frac{-b\pm\sqrt{\Delta}}{2a},
\end{align*}
przy czym $t = \min(t_1, t_2) \geq \mathtt{CORE\_BIAS}$, zaś współczynniki $a, b, c$ zależą od równania opisującego daną powierzchnię:
\begin{itemize}
\item Sfera o jednostkowym promieniu $R=1$ i początku w $\vec{o_o} = [0,0,0]$

\begin{align*}
(\vec{r}' - \vec{o_o}')^2 = R^2\qquad &\Rightarrow \qquad\vec{r}'^2 - 1 = 0,\\
a &= \vec{d}'\cdot\vec{d}',\\
b &= 2\vec{d}'\cdot\vec{o}',\\
c &= \vec{o}'\cdot\vec{o}' - 1.\\
\end{align*}

\item Cylinder o osi obrotu wokół wersora $\vec{y}'$, jednostkowym promieniu $R=1$ i początku w $\vec{o_o}' = [0,0,0]$

\begin{align*}
(\vec{r}'_{xz} - \vec{o_o})^2 = R^2\qquad &\Rightarrow\qquad r_x'^2 + r_z'^2 - 1 = 0,\\
a &= d_x'^2 + d_z'^2,\\
b &= 2\left(d_x'o_x' + d_z'o_z' \right),\\
c &= o_x'^2 + o_z'^2 - 1.
\end{align*}

\item Stożek o promieniu podstawy $R=1$, wysokości $h = 1$ oraz osi obrotu wokół wersora $\vec{y}'$

\begin{align*}
\left(\frac{hr_x'}{R} \right)^2 - (r_y' - h)^2 + \left(\frac{hr_z'}{R} \right)^2 = 0\qquad &\Rightarrow\qquad r_x'^2 - (r_y' - 1)^2 + r_z'^2 = 0,\\
a &= d_x'^2 - d_y'^2 + d_z'^2,\\
b &= 2\left(d_x'o_x' - d_y'o_y' + d_y' + d_z'o_z'\right),\\
c &= o_x'^2 - o_y'^2 + 2o_y' - 1 + o_z'^2
\end{align*}

\end{itemize}

Pozostałe trzy obiekty tj. płaszczyzna, dysk oraz kwadrat wymagają rozwiązania równania:
\begin{equation*}
(\vec{r}' - \vec{o_o}') \cdot \vec{n} = 0,
\end{equation*}
które w przypadku gdy w układzie związanym z obiektem $\vec{o_o}' = [0,0,0]$, a $\vec{n}' = [0, 1, 0]$ redukuje się do postaci:
\begin{equation*}
t = -\frac{o_y'}{d_y'}
\end{equation*}

Określenie czy promień trafił w dysk albo kwadrat wymaga dodatkowo użycia informacji o lokalnym punkcie przecięcia:
\begin{equation}
\vec{p}' = \vec{o}' + t\vec{d}'
\end{equation}
Jeżeli spełniony jest warunek:
\begin{itemize}
\item $p_x'^2 + p_z'^2 \leq 1$ - promień trafił w jednostkowy dysk,
\item $|p_x'| \leq 1 \wedge |p_z'| \leq 1$ - promień trafił w kwadrat.
\end{itemize}
Przyjęcie takich parametrów dla powyższych powierzchni sprawia, że w lokalnym układzie współrzędnych obiektu:
\begin{equation*}
\vec{p}'\in [-1, 1]^3.
\end{equation*}
Fakt ten jest wykorzystywany podczas teksturowania\footnote{Oczywiście przypadkiem specjalnym jest płaszczyzna, dla której $\vec{p}'\in \mathcal{R}^3$.}.

Funkcjonalność związana ze znalezieniem najbliższego obiektu na drodze promienia jest realizowana przez funkcje \texttt{PerformHits()} i \texttt{PerformShadowHits()}. Pierwsza z nich jest wywoływana dla promieni pierwotnych i rozproszonych, zaś druga dla promieni cienia, sprawdzających czy między źródłem światła a znalezionym punktem na obiekcie nie znajduje się jakakolwiek przeszkoda. Utylizacja zasobów układu FPGA związana z pojedynczą instancją obu tych funkcji przedstawiona została w tabeli~\ref{ch3:tab:perform_hits_util}.

\begin{table}[H]
\centering
\caption[Wykorzystanie zasobów sprzętowych układu KCU116 przez instancje funkcji sprawdzające przecięcie promienia z geometrią]{Wykorzystanie zasobów sprzętowych układu KCU116 przez instancje funkcji sprawdzające przecięcie promienia z geometrią raportowane po wykonaniu syntezy HLS}
\label{ch3:tab:perform_hits_util}
\begin{tabular}{|r|c|c|c|c|}
\hline
\multicolumn{1}{|l|}{}                  & \textbf{BRAM} & \textbf{DSP} & \textbf{FF}    & \textbf{LUT}   \\ \hline
\textbf{$\mathtt{PerformHits()}$}       & 0 (0\%)       & 109 (5,96\%) & 58496 (13,48\%) & 19136 (8,82\%) \\ \hline
\textbf{$\mathtt{PerformShadowHits()}$} & 0 (0\%)       & 107 (5,87\%) & 22887 (5,27\%) & 16121 (7,43\%) \\ \hline
\end{tabular}
\end{table}


Tak wysokie wymagania tychże funkcji względem układu FPGA związane są z faktem, iż:
\begin{itemize}
\item funkcje te zostały poddane działaniu dyrektywy \texttt{PIPELINE} z interwałem równym 1 dla uzyskania maksymalnej wydajności obliczeń, przez co Vivado HLS ma ograniczone możliwości współdzielenia zasobów odpowiedzialnych za wykonanie poszczególnych operacji,
\item każdy dostępny typ obiektu geometrycznego wymaga dokonania zespołu operacji arytmetycznych koniecznych do pełnego rozwiązania testu przecięcia, które są dla niego charakterystyczne\footnote{Chociaż kule, walce i stożki łączy to, iż wymagają rozwiązania równania kwadratowego, jednak współczynniki $a, b, c$ tego równania muszą być dla nich obliczone w różny sposób.}
\end{itemize}
To jednak nie wszystko. Ilość instancji tychże funkcji\footnote{W zaimplementowanym module funkcja realizowana jest za pomocą zespołu elementów logicznych. Liczba instancji stanowi, ile identycznych zespołów znajdzie się w układzie.} w \textsc{ViRay}'u zależy od:
\begin{itemize}
\item maksymalnej ilości obiektów w scenie \texttt{OBJ\_NUM},
\item interwału między kolejnymi pikselami obrazu \texttt{DESIRED\_INNER\_LOOP\_II},
\item głębokości śledzenia promieni \texttt{RAYTRACING\_DEPTH},
\item maksymalnej ilości świateł w scenie \texttt{LIGHTS\_NUM}.
\end{itemize}
W najprostszym przypadku, gdy \texttt{OBJ\_NUM} = \texttt{DESIRED\_INNER\_LOOP\_II}, a promieniami rozproszonymi są jedynie promienie odbite, liczba instancji dana jest poprzez:
\begin{align*}
\#\mathtt{PerformHits()} &= \mathtt{RAYTRACING\_DEPTH},\\
\#\mathtt{PerformShadowHits()} &= \mathtt{RAYTRACING\_DEPTH} \cdot \left(\mathtt{LIGHTS\_NUM} - 1\right).
\end{align*}
Z tego właśnie powodu \textsc{ViRay} w finalnej wersji nie dokonuje obliczeń związanych z promieniami załamanymi, a jedynie rozproszonymi i cienia przy ilości świateł w scenie ograniczonej do dwóch~(jedno otaczające i jedno punktowe). W ten sposób obie te funkcje łącznie konsumują 32,5~\% LUT oraz 37,5~\% FF układu KCU116~(wg. raportu po syntezie HLS). 

W tym miejscu należy również podnieść bardzo istotną kwestię związaną z wielkością \texttt{RAYTRACING\_DEPTH}. Aby mieć możliwość generowania informacji o odbiciach powstających na powierzchni musi być spełniona następująca zależność:
\begin{equation*}
\mathtt{RAYTRACING\_DEPTH} \geq 2.
\end{equation*}
Podczas prób implementacji wstępnych wersji \textsc{ViRay}'a na układzie VC707 możliwe było zastosowanie jedynie $\mathtt{RAYTRACING\_DEPTH} = 1$, podczas gdy KCU116 pozwoliło osiągnąć $\mathtt{RAYTRACING\_DEPTH} = 2$. Właśnie ten fakt przesądził o zmianie platformy docelowej, pomimo teoretycznie gorszych parametrów związanych z ilością dostępnych elementów~(tabela~\ref{ch3:tab:fpga_comp}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\item \underline{Cieniowanie - funkcja \texttt{Shade()}}

Zadaniem funkcji cieniującej \texttt{Shade()} jest określenie koloru piksela w przestrzeni barw \texttt{RGB} odpowiadającego znalezionemu punktowi przecięcia $\vec{p}$ z obiektem zgodnie z właściwą funkcją BRDF. Proces ten dokonuje się na podstawie:
\begin{itemize}
\item położenia punktu $\vec{p}$ względem źródeł światła,
\item zastosowanych BRDF dla określenia materiału,
\item informacji o teksturze, która ma zostać nałożona na obiekt.
\end{itemize} 

Poniższe równanie będące uogólnieniem równania~\eqref{ch1:eq:shading_equation} opisuje, w jaki sposób liczona jest radiancja w danym punkcie z uwzględnieniem wszystkich źródeł światła dla $k$-tego promienia~(operator $*$ oznacza mnożenie $i$-tych składowych obu operandów ze sobą)~\cite{RTFTGU}:
\begin{align}
\label{ch3:eq:shading_equation_general}
L_{o_k}(\vec{p}, \vec{\omega_o}) \equiv L_o(\vec{p}, \vec{\omega_o}) &= k_a(\vec{p})c_a(\vec{p}) * L_a\nonumber\\
&+ \sum_{i=1}^{\mathtt{LIGHTS\_NUM}} k_d(\vec{p})c_d(\vec{p}) * L_d(\vec{p}, \vec{\omega_o}) \cdot c_i\cdot s_i\cdot s_{cf_i} \nonumber\\
&+ \sum_{i=1}^{\mathtt{LIGHTS\_NUM}} k_s(\vec{p})c_s(\vec{p}) * L_s(\vec{p}, \vec{\omega_o}) \cdot c_i\cdot s_i\cdot s_{cf_i},
\end{align}
gdzie:
\begin{itemize}
\item $k_a(\vec{p}), k_d(\vec{p}), k_s(\vec{p}) \in [0, 1]$ - współczynniki określające udział światła otoczenia, rozproszonego i odbitego zwierciadlanie w tworzeniu radiancji,
\item $c_a(\vec{p}), c_d(\vec{p}), c_s(\vec{p}) \in [0, 1]^3$ - kolor materiału w świetle otaczającym, rozproszonym i odbitym zwierciadlanie,
\item $L_a, L_d(\vec{p}, \vec{\omega_o}), L_s(\vec{p}, \vec{\omega_o})$ - BRDF dla światła otoczenia, rozproszonego i odbitego zwierciadlanie,
\item $c_i = \frac{\max\left(\vec{n} \cdot \frac{\vec{p} - \vec{l_i}}{|\vec{p} - \vec{l_i}|}  , 0\right)}{|\vec{p} - \vec{l_i}|^2} $ - współczynnik związany z kwadratowym zanikiem oraz orientacją względem kierunku padania światła~($\vec{l_i}$ - położenie źródła światła),
\item $s_i\in\lbrace 0, 1 \rbrace$ - wynik testu zasłaniania (\texttt{ShadowVisibilityTest()}) $i$-tego źródła światła przez obiekty sceny, jeśli $s_i=0$ punkt $\vec{p}$ jest w cieniu,
\item $s_{cf_i}\in[0, 1]$ - współczynnik determinujący czy punkt $\vec{p}$ znajduje się w stożku świetlnym źródła umieszczonego w $\vec{l_i}$.
\end{itemize}

Natomiast całkowita radiancja w danym punkcie $L_{o_t}(\vec{p}, \vec{\omega_o})$ wynikająca z wielokrotnych rozproszeń~(odbić) promieni dana jest wzorem:
\begin{equation}
L_{o_t}(\vec{p}, \vec{\omega_o}) = \sum_{k=1}^{\mathtt{RAYTRACING\_DEPTH}}\left(\prod_{l=1}^k r_{l-1} \right)L_{o_k}(\vec{p}, \vec{\omega_o}), \qquad r_0 = 1,
\label{ch3:eq:total_radiance}
\end{equation}
gdzie:
\begin{itemize}
\item[] $r_{l-1}$ jest współczynnikiem odbicia od powierzchni, na której $l$-ty promień ma swój początek~(dla promieni pierwotnych $k=1$: $r_0=1$). 
\end{itemize}

W scenie renderowanej za pomocą \textsc{ViRay}'a, oprócz globalnego bezkierunkowego źródła światła otaczającego, można umieszczać \textit{punktowe źródła światła} wysyłające promieniowanie w określonym przez użytkownika stożku świetlnym - ten zadany jest przez kierunek główny $\overrightarrow{l_{dir}}$, oraz kosinus połowy kąta rozwarcia $\cos \frac{\alpha}{2}$~(rysunek~\ref{ch3:img:light_params}). Dodatkowy kąt $\beta$ decyduje o kosinusie $\cos\frac{\beta}{2} \geq \cos\frac{\alpha}{2}$, którego przekroczenie będzie wpływać na przybieranie przez $s_{cf_i}$ wartości pośrednich między 0 a 1:
\begin{equation}
s_{cf_i} = \max\left(\min\left(  \frac{\max\left(\vec{n} \cdot \frac{\vec{p} - \vec{l_i}}{|\vec{p} - \vec{l_i}|}  , 0\right) - \cos\frac{\alpha}{2}}{\cos\frac{\beta}{2} - \cos\frac{\alpha}{2}}, 1\right), 0\right)
\end{equation}
Wpływ położenia płaszczyzny względem kierunku światła $\overrightarrow{l_{dir}}$ oraz przyjętego kąta $\frac{\beta}{2}$ na jej oświetlenie prezentuje rysunek~\ref{ch3:img:light_comp}.

Naturalnie punktowe źródło światła jest tylko przybliżeniem rzeczywistego zachowania, ponieważ rzeczywiste źródła emitują promieniowanie z pewnej skończonej powierzchni, czego przejawem jest fakt, że cienie nie mają ostrych granic. 
\addimage{chapters/ch3/img/light_params.png}{scale=0.5}{Punktowe źródło światła w module \textsc{ViRay}. Światło jest emitowane w kierunku danym przez $\overrightarrow{l_{dir}}$ w stożku o kącie rozwarcia $\alpha$. Pełna intensywność występuje jedynie w mniejszym stożku o kącie rozwarcia $\beta < \alpha$}{Punktowe źródło światła w module \textsc{ViRay}}{ch3:img:light_params}

\input{chapters/ch3/light_params}

Część światła padającego na obiekt, zgodnie z równaniem~\eqref{ch3:eq:shading_equation_general} może się na nim rozproszyć lub odbić w sposób zwierciadlany\footnote{Przypadek kierunkowego odbicia rozproszonego nie jest rozpatrywany przez \textsc{ViRay}.}. W pierwszym przypadku rozproszenie to jest przybliżane przez model Orena-Nayara~\eqref{ch1:eq:ON_BRDF}, którego przypadkiem granicznym, gdy $\sigma^2 = 0$, jest model Lamberta~\eqref{ch1:eq:LambertBRDF}. Wpływ parametru szorstkości $\sigma^2$ na oświetlenie powierzchni został zobrazowany na rysunku~\ref{ch3:img:diffuse_params}. Na jego podstawie można stwierdzić, iż wraz ze wzrostem $\sigma^2$ rozkład oświetlenia staje się bardziej równomierny, a maksimum jasności ma mniejszą wartość. 

\input{chapters/ch3/diffuse_params}

Drugim z komponentów oświetlenia jest odbicie zwierciadlane, które w \textsc{ViRay}'u można modelować za pomocą modelu Blinna-Phonga~\eqref{ch1:eq:PhongBRDFNormalized} bądź też Torrance'a-Sparrowa~\eqref{ch1:eq:TorranceSparrowFull}. Decyzja o rezygnacji z modelu Phonga na rzecz Blinna-Phonga podyktowana została tym, że model Blinna-Phonga oraz Torrance'a-Sparrowa współdzielą ze sobą obliczenia związane z czynnikiem rozkładu orientacji mikrościanek wokół wektora połówkowego $D(\vec{\omega_h})$~\eqref{ch1:eq:TorranceSparrow_D}, przez co implementacja tego pierwszego nie wiąże się z wykorzystaniem dodatkowych zasobów układu FPGA. Wpływ parametru skupienia rozbłysku $e \in \mathcal{N}$ w modelu Blinna-Phonga został zaprezentowany na przykładzie oświetlenia powierzchni walcowej~(rysunek~\ref{ch3:img:blinn_phong}).
\input{chapters/ch3/blinn_phong_params}

Analizę działania modelu Torrance'a-Sparrowa najłatwiej dokonać w połączeniu ze sprawdzeniem, jak różne wartości współczynnika załamania $\eta$~(oraz absorpcji $k$ dla przewodników) wpływają na zdolność odbijania promieni od powierzchni. Wynika to z faktu, iż model Torrance'a-Sparrowa ingeruje bezpośrednio w wartość współczynnika odbicia $r_{l-1}$, który zależy tu od przestrzennej relacji między wektorem połówkowym $\vec{\omega_h}$ a kątem $\vec{\omega_i}$~(w przeciwieństwie do typowej zależności między wektorem normalnym $\vec{n}$ a $\vec{\omega_i}$).

\input{chapters/ch3/reflection_params}

\item \underline{Teksturowanie powierzchni}

Teksturowanie powierzchni pozwala uatrakcyjnić wizualnie obiekty bez konieczności zwiększania ich złożoności geometrycznej poprzez nadanie punktom znajdującym się na obiekcie odpowiednich kolorów\footnote{Tak naprawdę tekstura może być odpowiedzialna nie tylko za nadanie konkretnego koloru obiektowi, ale może również modulować wektory normalne, współczynniki załamania oraz wiele innych parametrów mających wpływ na ostateczny odbiór obiektu przez obserwatora.}. \textsc{ViRay} pozwala nadać obiektowi pożądaną teksturę, której dane zapisane są w postaci mapy bitowej albo mapy szarości. W tym drugim przypadku, odcień szarości $\mathtt{mix}\in[0, 1]$ decyduje o stopniu mieszania między dwoma wybranymi przez użytkownika kolorami:
\begin{equation}
\mathtt{color = color1\cdot mix + color2\cdot\left(1 - mix \right)}.
\end{equation}

Problem teksturowania sprowadza się do nałożenia dwuwymiarowej mapy pikseli $\mathtt{w}\times\mathtt{h}$ na powierzchnię obiektu trójwymiarowego, który może wprowadzać zniekształcenie w jej odwzorowaniu. Z tego powodu współrzędne na mapie pikseli transformowane są liniowo do przestrzeni $[u, v] \in [0, 1]^2$~(rysunek~\ref{ch3:img:texture_mapping}) zaś współrzędne punktu przecięcia promienia z obiektem w przestrzeni obiektu $\vec{p}'\in[-1, 1]^3$ poddawane są innej~(w ogólnym przypadku nieliniowej) transformacji do przestrzeni $[u, v]$. 


\addimage{chapters/ch3/img/texture_mapping.png}{width=0.95\textwidth}{Transformacja pozycji piksela z przestrzeni tekstury do współrzędnych $[u, v] \in [0, 1]^2$. Tekstura na podstawie~\cite{EARTH_NASA}}{Transformacja pozycji piksela do współrzędnych u, v}{ch3:img:texture_mapping}

Najprostszym sposobem transformacji współrzędnych punktu $\vec{p}'$ do $[u,v]$ jest transformacja liniowa zwana \textit{mapowaniem prostokątnym}:
\begin{align*}
u &= \frac{p_x' + 1}{2},\\
v &= \frac{p_z' + 1}{2}.
\end{align*}
Dostępność dodatkowych trybów mapowania w \textsc{ViRay}'u jest sterowana poprzez \texttt{ADVANCED\_TEXTURE\_MAPPING\_ENABLE}. Definicja ta daje dostęp do odwzorowania \textit{cylindrycznego}:
\begin{align*}
u &= \frac{\arctan\frac{p_x'}{p_z'}}{2\pi},\\
v &= \frac{v_y' + 1}{2}
\end{align*} 
oraz \textit{sferycznego}:
\begin{align*}
u &= \frac{\arctan\frac{p_x'}{p_z'}}{2\pi},\\
v &= 1 - \frac{\arccos y}{\pi}.
\end{align*} 

Wpływ trzech wymienionych powyżej trybów na finalne odwzorowanie tekstury na powierzchni różnych obiektów został przedstawiony na rysunku~\ref{ch3:img:texture_proj}.

\input{chapters/ch3/texture_params}

Z zastosowaniem odwzorowania cylindrycznego oraz sferycznego wiąże się konieczność obliczenia odpowiednich kątów na podstawie współrzędnych punktu $\vec{p}'$ z użyciem funkcji cyklometrycznych. Wykorzystanie w tym celu wprost funkcji \texttt{hls::atan2()} oraz \texttt{hls::acos()} dostarczanych wraz z Vivado HLS rodzi jednak kłopoty związane z użyciem przez nie dużej ilości zasobów układu~(tabela~\ref{ch3:tab:atan_acos}), co w praktyce mogłoby oznaczać niemożliwość implementacji odwzorowania cylindrycznego oraz sferycznego w końcowym systemie śledzenia promieni. Chcąc temu zaradzić \textsc{ViRay} może korzystać z obliczeń przybliżonych w celu znalezienia aproksymacji wartości funkcji \texttt{atan2()} oraz \texttt{acos()}. Są to odpowiednio \texttt{ViRayUtils::Atan2()} oraz \texttt{ViRayUtils::Acos()}, które włączane są poprzez definicje \texttt{FAST\_ATAN2\_ENABLE} oraz \texttt{FAST\_ACOS\_ENABLE}.

\input{chapters/ch3/atan_acos_table}


\begin{itemize}
\item \texttt{ViRayUtils::Atan2()}

Funkcja ta opiera swoje działanie na następującej obserwacji~\cite{ATAN_APPROX}:

\begin{equation}
\arctan(z)\approx 0,9724z - 0,1919z^3,\qquad z=\frac{y}{x}\in[-1, 1]
\end{equation}
oraz tożsamości:
\begin{equation}
\arctan(z) = \frac{\pi}{2} - \arctan\left(z^{-1}\right), \mathrm{gdy} \left| z \right| > 1
\end{equation}

\begin{figure}[H]
\centering
\subfigure{\includegraphics[width=0.8\textwidth]{chapters/ch3/img/atan2_error.png}}
\subfigure{\includegraphics[width=0.8\textwidth]{chapters/ch3/img/atan2_relative_error.png}}
\caption[Błąd bezwzględny oraz względny generowany przez przybliżoną implementację funkcji \texttt{atan2()}]{Błąd bezwzględny oraz względny generowany przez przybliżoną implementację funkcji \texttt{atan2()}. Maksymalny błąd wynosi $0,00496\ \mathrm{rad}$, co przekłada się w najgorszym przypadku na odstępstwo od dokładnego wyniku równe 2,8 \%. Różnice te praktycznie nie wpływają na sposób odwzorowania tekstury na powierzchni}
\label{ch3:img:atan2_error}
\end{figure}


\item \texttt{ViRayUtils::Acos()}

W tym przypadku rozwiązanie przybliżone oparte jest o tablicę 33 wartości, będących dokładnymi wynikami funkcji \texttt{acos()} dla równo oddalonych od siebie parametrów $x_i \in [0, 1]$. Dla parametru wejściowego $x'$ następuje określenie najbliższych mu parametrów $x_i$ oraz $x_{i+1}$, dla których znane są dokładne wartości funkcji. Następnie dokonywana jest interpolacja liniowa pomiędzy tymi wartościami, zależna od odległości $x'$ od $x_i$ oraz $x_{i+1}$. W przypadku, gdy $x' < 0$ wykorzystywana jest tożsamość:
\begin{equation}
\arccos(x') = \pi - \arccos(|x'|).
\end{equation}

\begin{figure}[H]
\centering
\subfigure{\includegraphics[width=0.8\textwidth]{chapters/ch3/img/acos_error.png}}
\subfigure{\includegraphics[width=0.8\textwidth]{chapters/ch3/img/acos_relative_error.png}}
\caption[Błąd bezwzględny oraz względny generowany przez przybliżoną implementację funkcji \texttt{acos()}]{Błąd bezwzględny oraz względny generowany przez przybliżoną implementację funkcji \texttt{acos()}. Maksymalny błąd wynosi $0.0624\ \mathrm{rad}$, który występuje w okolicach 0 oraz $\pi$ radianów, a związane jest to z faktem, iż funkcja \texttt{acos()} przejawia tam największe odstępstwa od liniowości~($\frac{\mathrm{d}(\arccos(x))}{\mathrm{d}x} = \frac{1}{\frac{\mathrm{d}\cos(x)}{\mathrm{d}x}} = -\frac{1}{\sin(x)}$). Mimo tej jednej niedogodności, zastosowane przybliżenie sprawdza się podczas teksturowania obiektów}
\label{ch3:img:acos_error}
\end{figure}

\end{itemize}

Algorytmy dokonujące teksturowania pozwalają również dokonywać translacji tekstury oraz jej skalowania poprzez powielanie. Możliwości te zostały zilustrowane na rysunku~\ref{ch3:img:texture_transform}.

\addimage{chapters/ch3/img/texture_proj/texture_transform.png}{width=0.9\textwidth}{Translacja oraz skalowanie tekstury. a) Kwadrat z oryginalną teksturą. b) Tekstura została przesunięta o 0.1 jednostki w lewo oraz 0.2 jednostki w dół. c) Oryginalna tekstura została przeskalowana w taki sposób, że została powielona dwukrotnie w kierunku $u$ oraz trzykrotnie w kierunku $v$~(możliwe są również niecałkowite wartości skali). d) Oryginalny obiekt a) został poddany skalowaniu co wpłynęło również na deformację tekstury}{Translacja oraz skalowanie tekstury}{ch3:img:texture_transform}

Tekstury w \textsc{ViRay}'u są całkowicie przechowywane w pamięci BRAM układu FPGA\footnote{Własność ta wynika z faktu, iż Vivado HLS nie pozwala dokonywać asynchronicznych, względem potoku przetwarzania, operacji odczytu danych z pamięci zewnętrznej.}\footnote{Możliwe jest również poinstruowanie Vivado HLS, aby pamięć tekstur znalazła się w układach UltraRAM za pomocą definicji \texttt{TEXTURE\_URAM\_STORAGE}. Rozwiązanie to jest jednakże niezalecane z uwagi na fakt, iż bloki UltraRAM są zlokalizowane w układzie FPGA tzn. nie są tak bardzo rozproszone po całym układzie jak bloki BRAM, w wyniku czego na etapie implementacji dochodzi do nadmiernego stłoczenia, czyli lokalnego przeciążenia sieci połączeń, co prowadzi do niepowodzenia implementacji.}. Fakt ten wymusza stosowanie tekstur o odpowiednio niskiej rozdzielczości~(standardowo \textsc{ViRay} udostępnia miejsce na $256^2$ 32-bitowych wartości, patrz \texttt{TEXT\_PAGE\_SIZE}). W takim wypadku nałożony na powierzchnię obraz może być poszarpany z wyraźnymi krawędziami pomiędzy pikselami tekstury. Zdefiniowanie w pliku konfiguracyjnym \texttt{BILINEAR\_TEXTURE\_FILTERING\_ENABLE} za cenę rozmycia szczegółów tekstury pozwala wyeliminować wyraźne granice między pikselami~(rysunek~\ref{ch3:img:bilinear_filtering}). 

\addimage{chapters/ch3/img/bilinear_filtering.png}{width=0.8\textwidth}{Algorytm filtracji biliniowej tekstury. Zaznaczony na {\color{red}czerwono} punkt $\vec{p}'$ na powierzchni obiektu odpowiada środkowemu pikselowi tekstury, jednak nie wypada on w samym centrum obszaru~(tzw. \textit{centroid}). W kierunku $u$ oraz $v$ znajdowane są najbliższe piksele tekstury przylegające do piksela centralnego i najbliższe $\vec{p}'$. Kolor tekstury w $\vec{p}'$ obliczony zostaje na podstawie kolorów pikseli tekstury i ich wag, zależnych od odległości $\vec{p}'$ od centroidów wzdłuż osi $u$ oraz $v$, jako interpolacja liniowa w kierunku $u$ oraz $v$}{Algorytm filtracji biliniowej tekstury}{ch3:img:bilinear_filtering}

\item \underline{Zapis finalnego koloru piksela - \texttt{SaveColorToBuffer()}}

\input{chapters/ch3/complexity_params}





wpływ parametrów, obrazki
\begin{itemize}
\item stożek świetlny prostopadle do płaszczyzny, spot cutoff (z wykresem), wpływ pochylenia
\item model lamberta
\item model Blinna-Phonga, kolor rozbłysku i jego skupienie
\item model Oren-Nayar, zmienność z sigma, czemu nie działa w realnym układzie
\item model Torrance-Sparrow
\item współczynnik Fresnela (kula i różna eta)
\end{itemize}
{\color{red}OBRAZKI - DUŻO OBRAZKÓW!!!!}

\end{enumerate}

\subsection{Przepływ danych przez akcelerator}
Zgrubne i bardziej szczegółowe opisanie funkcjonalności poszczególnych bloczków
\subsubsection{Optymalizacje czasu i powierzchni za pomocą dyrektyw}
DATAFLOW, ATAN2, ACOS

\subsection{Ograniczenia}
Brak MC, ograniczona ilość obiektów i świateł, brak obsługi przezroczystości, obrazy LDR, brak swobodnej orientacji (z uwagi na ograniczenia technologiczne)

\section{Implementacja w układzie}
\subsection{Przepływ danych}
\subsubsection{MicroBlaze}
\subsubsection{ADV7511}
Jaki max zegar udało się uzyskać???

\section{Oprogramowanie mikrokontrolera}
Inicjalizacja, obsługa kontrolera animacji, prezentacja przykładowej sceny i wydajności.
\section{WPADKI}
Małe zmiany w kodzie - ogromne w układzie: brak determinizmu i wynikające z tego problemy w poszukiwaniu optymalnych rozwiązań.
\begin{itemize}
\item Użycie Kintexa U+ podyktowane było nowocześniejszą technologią. VC707 posiada więcej elementów logicznych jednak starsza technologia wykonania nie pozwoliła zaimplementować symulacji odbić i cieni pierwszego rzędu. Z drugiej strony płytka z VC707 posiada pełne wyprowadzenie do ADV7511 i nie wymagane były specjalne dodatkowe zabiegi związane z kodowaniem koloru - artefaktów koloru nie było.
\item Nawet najmniejsza zmiana w kodzie może mieć wpływ na spełnienie wymagań czasowych podczas implementacji. Błąd znaleziony w obliczeniach współczynników Fresnela dla materiałów przewodzących, którego załatanie w C sprowadzało się do zmiany miejsca obliczania kwadratów amplitudowych współczynników odbicia w przypadku dielektryków, zmusiło do zmniejszenia zegara układu z 335MHz do 320MHz
\item Pomimo, iż w praktyce korzystniej byłoby dokonanie takiej implementacji, która pomija DATAFLOW i buforowanie wierszy pikseli tzn. użyty byłby potok PIPELINE(specjalny przełącznik w pliku konfiguracyjnym typedefs.h) i piksele zapisywane byłyby w każdej iteracji, bezpośrednio na zewnętrznej pętli renderowania to na etapie implementacji okazało się również, że jest to rozwiązanie nieimplementowalne przynajmniej z takim samym zegarem niż rozwiązanie buforowane przez co nie ma zysku netto czasu wykonania
\item Chociaż model Oren-Nayar oświetlenia powierzchni wydaje się stosunkowo prosty (porównywalny z Torrance-Sparrow) w implementacji w kodzie C sprawia on, że rozwiązanie staje się nieimplementowalne nawet po znacznym obniżeniu taktowania zegara. Użycie zasobów jest większe (w szczególności LUT wzrasta o 2\% dla Kintexa) niż zwykły model Lamberta jednak przeprowadzono zabiegi mające na celu redukcję rozmiaru układu jako całości poprzez zmniejszenie precyzji obliczeń w niekrytycznych miejscach układu (np. w module teksturującym) co przełożyło się na ok. 8\% zmniejszenie zapotrzebowania na LUT. W tym celu wykorzystano typ zmiennoprzecinkowy połówkowej precyzji (half). Implementacja wykazała, że zabieg ten nie wpłynął pozytywnie na implementowalność zatem należy sądzić, że Vivado napotyka trudności w implementacji nie z powodu rozmiaru całego układu a wskutek operacji wykonywanych w celu obliczenia współczynnika rozproszenia w modelu Oren-Nayar (przy obliczeniach ON wykorzystywano w głównej mierze typ połówkowy)

\end{itemize}