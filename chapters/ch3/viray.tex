\chapter{Akcelerator śledzenia promieni z użyciem układu FPGA}
\section{Założenia}
Wszystko, o czym wspomniano do tej pory w poprzedzających rozdziałach miało na celu stworzyć podwaliny teoretyczne, które mogą zostać wykorzystane w praktyce do budowy systemu śledzenia promieni w oparciu o układy FPGA. Projekt, którego realizacji się podjęto zakładał od samego początku:
\begin{enumerate}
\item Przy użyciu Vivado HLS
\item zaprojektowanie modułu do akceleracji grafiki metodą śledzenia promieni,
\item zdolnego do wizualizacji świata złożonego z prostych kształtów geometrycznych,
\item których powierzchnie zachowują się zgodnie z odpowiednimi funkcjami BSDF,
\item w czasie rzeczywistym.
\end{enumerate}

Chociaż sposób wykonania projektu był zmieniany w czasie, powyższe wymagania pozostawały aktualne. Warto jednak w tym momencie dokonać sprecyzowania każdego z nich.

\begin{enumerate}
\item Głównym, nadrzędnym celem pracy była ewaluacja możliwości Vivado HLS, jako narzędzia umożliwiającego porzucenie konfiguracji za pomocą HDL na rzecz opisu algorytmicznego w języku podobnym do C/C++. W momencie rozpoczęcia projektu znane były wyniki i wnioski z prac eksperymentalnych używających tego narzędzia w pewnych typowych zastosowaniach. Szczególnie ważna okazała się być informacja, o tym, że Vivado HLS posiada tendencję do tworzenia opisu RTL powodującego użycie stosunkowo dużej ilości elementów logicznych znajdujących się w układzie. Chcąc mieć swobodę w tworzeniu funkcjonalności należało dysponować układem FPGA o odpowiednio dużej ilości elementów logicznych, dlatego do projektu wybrano układ \textit{Virtex 7} znajdujący się na płytce ewaluacyjnej \textit{VC707}~\cite{VC707_UG}, który został później zastąpiony przez układ \textit{Kintex UltraScale+} wchodzący w skład płytki ewaluacyjnej \textit{KCU116}~\cite{KCU116_UG}. 
\addimage{chapters/ch3/img/vc707.jpg}{scale=0.75}{Płytka ewaluacyjna VC707. Oprócz układu FPGA znajdującego się pod widocznym na zdjęciu układem chłodzenia, płytka ewaluacyjna udostępnia do wykorzystania wiele interfejsów danych i sposobów komunikacji, które mogą zostać użyte przez projektanta w realnym systemie przetwarzania danych~\cite{VC707_UG}}{Płytka ewaluacyjna VC707}{ch3:img:vc707}
Użycie płytek ewaluacyjnych ma tę zaletę, iż wraz z nimi użytkownik otrzymuje dostęp do funkcjonalności oferowanych przez dodatkowe elementy elektroniczne zamontowane na takich płytkach i mogące kooperować z układem FPGA w procesie przetwarzania danych. W kontekście omawianego projektu kluczowe okazały się być możliwość przechowywania danych w pamięci RAM oraz wykorzystanie komunikacji wizualnej zgodnej ze standardem HDMI~(obie wymienione płytki posiadają porty HDMI mogące służyć jako wyjście obrazu).
\begin{savenotes}
\begin{table}[H]
\centering
\caption{Porównanie podstawowych parametrów opisujących wykorzystane układy FPGA}
\label{ch3:tab:fpga_comp}
\begin{tabular}{|r|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{} & \multicolumn{4}{c|}{\textbf{Elementy składowe}} & \multirow{2}{*}{\textbf{Proces technologiczny}} & \multirow{2}{*}{\textbf{Koszt}} \\ \cline{2-5}
                  & BRAM\footnote{Każdy element pamięci blokowej BRAM jest w stanie przechowywać 18~kb danych. W układach FPGA z serii UltraScale oraz UltraScale+ występuje również dodatkowy typ pamięci zwany \textit{UltraRAM}, URAM co w zamierzeniu pozwala przechowywać większe ilości danych bezpośrednio w układzie FPGA~(każdy blok URAM może pomieścić 288 kb danych), zmniejszając konieczność odwoływania się do zewnętrznych zasobów a przez to zwiększając wydajność przetwarzania. }      & DSP\footnote{Moduły DSP znajdują zastosowanie w przypadku akceleracji działań arytmetycznych, zwłaszcza stałopozycyjnych~\cite{DSP48E1}\cite{DSP48E2}. Pozwalają na efektywniejszą implementację i uzyskiwanie wyższych częstotliwości pracy, niż gdyby te same operacje miały zostać wykonane za pomocą LUT.}       & FF         & LUT        &                                                 &                                 \\ \hline
\textbf{VC707}    & 2060      & 2800      & 607200     & 303600     & 28 nm                                           & 3495 \$                         \\ \hline
\textbf{KCU116}   & 960       & 1824      & 433920     & 216960     & 16 nm                                           & 2995 \$                         \\ \hline
\end{tabular}
\end{table}
\end{savenotes}
Oba układy\footnote{Od tej pory, dla wygody, poprzez układ rozumieć należy tak płytkę ewaluacyjną jak i rodzaj układu FPGA, który na niej się znajduje. Związane jest to z faktem, iż pełne nazwy układów FPGA mają skomplikowaną postać zależną od m.in. rodziny, technologii, wielkości czy oceny szybkości~(ang. \textit{speed grade}) układu.} przedstawione w tabeli~\ref{ch3:tab:fpga_comp} posiadają stosunkowo dużą ilość podstawowych elementów, na bazie których można tworzyć funkcjonalność, jednak to VC707 jest znacznie większy pod względem dostępnych zasobów~(różnice zaczynają się od 40\% dla LUT i kończą na 115\% dla pamięci BRAM). Dziwić może zatem zmiana na układ o teoretycznie mniejszych możliwościach. Rzeczywiście KCU116 jest tylko teoretycznie gorszy - jego przewaga uwidoczniła się na etapie implementacji funkcjonalności, dzięki temu, iż jest to układ wykonany w znacznie nowszej technologii, dającej większe możliwości podczas procesu implementacji i łączenia ze sobą elementów za pomocą sieci konfigurowalnych połączeń.
\item U samych podstaw przetwarzania grafiki metodą śledzenia promieni leży fakt, iż obliczenia dotyczące jednej rodziny promieni~(na którą składają się wszystkie promienie powiązane z danym promieniem pierwotnym: odbite, załamane, promienie cieni) odpowiedzialnej za obliczenie koloru konkretnego piksela obrazu są niezależne od pozostałych rodzin. Wynika z tego, że w idealnym przypadku kolory wszystkich pikseli mogłyby być obliczane jednocześnie przez dedykowane dla każdego z nich układy przetwarzające. Realizacja takiego systemu w rzeczywistym układzie FPGA graniczy aktualnie z niemożliwością, choćby ze względu na wymagane w tym celu zasoby sprzętowe. Niemniej jednak udostępniane przez układy FPGA naturalne możliwości przetwarzania jednoczesnego dają duże szanse na zwiększenie efektywności algorytmu, względem jego wersji działającej na procesorze CPU komputera.
\item Jedną z podstawowych cech śledzenia promieni, o której wspomniano przy okazji porównania z rasteryzacją, jest fakt, iż jeśli tylko istnieje sposób matematycznego rozwiązania przecięcia powierzchni z promieniem, to można jej użyć w procesie renderowania bez konieczności stosowania triangulacji. Podczas gdy sfera opisana przez macierz jej przekształcenia jest jednym obiektem, który należy sprawdzić na drodze promienia, triangulacja kuli wymaga setek pojedynczych trójkątów, z którymi taki test trzeba przeprowadzić. Z jednej strony zaproponowane postępowanie niweluje potrzebę stosowania struktur akcelerujących, z drugiej zapewnia, iż uzyskiwane punkty przecięcia będą możliwie dokładne~(w zależności od precyzji obliczeń użytego typu danych).
\item Omawiana technika umożliwia uzyskiwanie realistycznych i interesujących obrazów dopiero wtedy, jeśli zostaną odpowiednio zastosowane różne techniki oświetlenia powierzchni. Tworzony system powinien oferować możliwość użycia różnych funkcji BSDF, które mogłyby być odpowiednio konfigurowane za pomocą parametrów.
\item Nie istnieje ścisła definicja działania programu w czasie rzeczywistym. W branży elektronicznej rozrywki~(tj. gry wideo) przyjmuje się, że minimalna częstotliwość generowania pełnych klatek obrazu, dla zachowania złudzenia płynności, nie powinna być niższa niż 25-30~(chociaż coraz częściej mówi się o 60). Możliwości szybkiego generowania obrazu używając śledzenia promieni zależą głównie od:
\begin{itemize}
\item rozdzielczości klatki obrazu,
\item ilości rozpatrywanych promieni w danej rodzinie,
\item ilości świateł i obiektów w scenie,
\item stosowanych funkcji BSDF.
\end{itemize} 
W związku z tym zachowawczo przyjęto, że jeśli tylko zaprogramowany układ będzie w stanie generować obrazy o rozdzielczości 1280 x 720 pikseli z uwzględnieniem pierwszej rodziny promieni wtórnych w czasie poniżej 0.1s, to efekt taki będzie można uznać za satysfakcjonujący. W sprawdzeniu warunku dostatecznej płynności~(poza standardowym pomiarem czasu wykonania) w praktyce miało pomóc użycie dostępnego na wykorzystywanych płytkach kodeka i portu HDMI\footnote{Poza tym w taki sposób najłatwiej zaprezentować możliwości stworzonego systemu podczas pokazów. Zamiast operować zbiorem statycznych scen, które wcale nie muszą być efektem działającego systemu w układzie FPGA, widz otrzymuje interaktywną~(np. poprzez zmianę położenia obserwatora z pomocą dostępnych na płytce przycisków dowolnego przeznaczenia) demonstrację, w którą jest w stanie uwierzyć.}.
\end{enumerate}

\section{Budowa systemu śledzenia promieni}
Tak postawiony problem można zasadniczo rozwiązać na dwa skrajnie różne sposoby wiążące się z zupełnie innymi wyzwaniami na etapie implementacji:
\begin{enumerate}
\item Stworzenie prostego układu procesorowego, pozwalającego przetwarzać podaną przez użytkownika listę rozkazów implementujących wymagany algorytm.
\item Zaprojektowanie modułu, który implementuje skończony zbiór zachowań~(algorytmów), których wywołanie może być sterowane poprzez parametry wejściowe, czyli tzw. \textit{potok przetwarzania o ustalonej funkcjonalności}~(ang. \textit{fixed pipeline}).
\end{enumerate}
O ile w pierwszym przypadku nadrzędnym celem jest to, aby instrukcje były wykonywane jak najszybciej, a sam układ potrzebował jak najmniej zasobów, o tyle w drugim przypadku może okazać się wyzwaniem pogodzenie ze sobą ilości oferowanych funkcji z dostępnym na układzie miejscem i koniecznością zapewnienia synchronizacji danych na etapie implementacji.

W obu przypadkach ważna jest kontrola nad utylizacją zasobów, która jest nierozerwalnie powiązana z wykorzystywanymi typami danych do przeprowadzenia obliczeń. W tabeli~\ref{ch3:tab:type_area_time} zestawiono jak dużo zasobów potrzeba do implementacji operacji dodawania, mnożenia, dzielenia i pierwiastkowania w przypadku posługiwania się różnymi typami danych oraz ile cykli zegara~(\#) należy oczekiwać na wynik w każdym przypadku. Widać, że w przypadku typów całkowitoliczbowych oraz stałopozycyjnych~(\texttt{ap\_fixed<W, N>}, gdzie \texttt{W} to ilość bitów przypadająca na pełen zapis liczby~(tzw. \textit{długość słowa}), \texttt{N} - bity części całkowitej ze znakiem, a pozostałe przypadają na zapis części ułamkowej) elementarne operacje tj. dodawanie i mnożenie mogą nie tylko być wykonywane w każdym cyklu zegara (\# = 1), ale również zajmują niewiele zasobów układu. Mniejszy z zaprezentowanych typów stałopozycyjnych \texttt{ap\_fixed\textless{}24, 18\textgreater{}} w celu wykonania mnożenia używa 1 zamiast 3 DSP, co może mieć znaczenie w przypadku układów o niwielkiej ilości tychże. Z drugiej strony typy całkowitoliczbowe oraz stałopozycyjne w przypadku dwóch innych działań~(a mających duże znaczenie w momencie rozwiązywania równań kwadratowych oraz normalizacji wektorów) mają albo bardzo duże opóźnienie~(dzielenie), albo wymagają dużej ilości LUT~(pierwiastkowanie). Chcąc dokonać implementacji pierwiastkowania liczby opisanej przez typ \texttt{ap\_fixed\textless{}32, 20\textgreater{}} w układzie VC707 należy liczyć się z koniecznością poświęcenia ok. 1,5\% wszystkich dostępnych LUT. Atrakcyjniej pod tym względem wyglądają typy zmiennoprzecinkowe, a zwłaszcza typy \texttt{half} oraz \texttt{float}. Dziwi jednak fakt, że pierwiastkowanie typu \texttt{half} wymaga znacznie więcej zasobów niż \texttt{float}, jednocześnie przechowując informację tylko o 16 bitach zamiast 32\footnote{Przykład ten ilustruje poziom zaawansowania obsługi typu \texttt{half} przez Vivado HLS.}. Tam gdzie typy całkowitoliczbowe oraz stałopozycyjne pokazywały swoją znaczną przewagę~(tj. dodawanie i mnożenie), tam liczby zmiennoprzecinkowe wymagają więcej zasobów a oczekiwanie na wynik jest dłuższy.  

Wybór reprezentacji danych jest ważnym etapem tworzenia rzeczywistego systemu przetwarzania. Należy odpowiedzieć sobie na pytanie, jakie dane będą przetwarzane oraz jakie będzie ich zróżnicowanie~(dynamika). Jeśli wykorzystywany jest 16 bitowy typ całkowitoliczbowy czy może dojść do sytuacji, że parametry iloczynu mogą dać wynik, który jest większy niż maksymalnie obsługiwany? Czy 8 bitów przeznaczonych na część ułamkową w zapisie stałopozycyjnym umożliwi poprawne znalezienie punktu przecięcia w każdej sytuacji, a jeśli nie to czy zwiększenie szerokości bitowej nie wpłynie negatywnie na inne metryki związane z tworzonym modułem IP? Jakie korzyści może przynieść zastosowanie reprezentacji zmiennoprzecinkowej, jeśli zadaniem układu jest głównie dokonywanie równolegle wielu operacji dodawania i mnożenia?  Podjęcie decyzji i odpowiedzialność za nią spoczywa na projektancie.

\begin{landscape}
\phantom{\rule{1em}{6em}}
\begin{table}[H]
\centering
\caption[Zestawienie typów danych wraz z estymacją wykorzystania poszczególnych zasobów oraz czasu wykonania dla podstawowych operacji arytmetycznych]{Zestawienie danych wraz z estymacją wykorzystania poszczególnych typów zasobów oraz czasu wykonania~(\#) dla podstawowych operacji arytmetycznych. W przypadku pierwiastkowania wartości typu \texttt{half} utylizacja LUT oraz FF musiała zostać oszacowana ze względu na fakt, iż Vivado HLS włącza operacje implementujące to działanie bezpośrednio do hierarchii funkcji, w której zostało wywołane. Do sporządzenia niniejszego zestawienia użyto Vivado HLS 2017.4 dla układu VC707 działającego z częstotliwością 100~MHz}
\label{ch3:tab:op_type_util_time}
\begin{tabular}{|r|l|l|l|l||l|l|l|l||l|l|l|l||l|l|l|l|}
\hline
\multicolumn{1}{|l|}{\multirow{2}{*}{}}           & \multicolumn{4}{c||}{\textbf{Dodawanie}}                                                                       & \multicolumn{4}{c||}{\textbf{Mnożenie}}                                                                       & \multicolumn{4}{c||}{\textbf{Dzielenie}}                                                                      & \multicolumn{4}{c|}{\textbf{Pierwiastek}}                                                                    \\ \cline{2-17} 
\multicolumn{1}{|l|}{}                            & \multicolumn{1}{c|}{LUT} & \multicolumn{1}{c|}{DSP} & \multicolumn{1}{c|}{FF} & \multicolumn{1}{c||}{\#} & \multicolumn{1}{c|}{LUT} & \multicolumn{1}{c|}{DSP} & \multicolumn{1}{c|}{FF} & \multicolumn{1}{c||}{\#} & \multicolumn{1}{c|}{LUT} & \multicolumn{1}{c|}{DSP} & \multicolumn{1}{c|}{FF} & \multicolumn{1}{c||}{\#} & \multicolumn{1}{c|}{LUT} & \multicolumn{1}{c|}{DSP} & \multicolumn{1}{c|}{FF} & \multicolumn{1}{c|}{\#} \\ \hline
\texttt{int}                                      & 39                       & 0                        & 0                       & 1                             & 21                       & 3                        & 0                       & 1                            & 238                      & 0                        & 394                     & 36                           & 1416                     & 0                        & 317                     & 5                            \\ \hline
\texttt{ap\_fixed\textless{}32, 20\textgreater{}} & 39                       & 0                        & 0                       & 1                             & 21                       & 3                        & 0                       & 1                            & 326                      & 0                        & 539                     & 48                           & 4720                     & 0                        & 1281                    & 8                            \\ \hline
\texttt{ap\_fixed\textless{}24, 18\textgreater{}} & 24                       & 0                        & 0                       & 1                             & 40                       & 1                        & 0                       & 1                            & 224                      & 0                        & 370                     & 34                           & 2414                     & 0                        & 433                     & 7                            \\ \hline
\texttt{half}                                     & 112                      & 2                        & 106                     & 4                             & 34                       & 2                        & 64                      & 3                            & 209                      & 0                        & 123                     & 5                            & $\sim$950                & 3                        & $\sim$180               & 6                            \\ \hline
\texttt{float}                                    & 214                      & 2                        & 227                     & 4                             & 135                      & 3                        & 128                     & 2                            & 802                      & 0                        & 359                     & 8                            & 508                      & 0                        & 238                     & 7                            \\ \hline
\texttt{double}                                   & 762                      & 3                        & 430                     & 4                             & 203                      & 11                       & 299                     & 5                            & 3253                     & 0                        & 1697                    & 17                           & 1912                     & 0                        & 1099                    & 17                           \\ \hline
\end{tabular}
\label{ch3:tab:type_area_time}
\end{table}

\end{landscape}

\subsection{Układ procesorowy}
Działanie najprostszego procesora polega na kolejnym:
\begin{enumerate}
\item Pobraniu instrukcji z listy i jej odkodowaniu.
\item Wykonaniu operacji zgodnie z przekazanym opisem.
\item Zapisaniu wyniku.
\item Powrotu do kroku 1. ze zmienionym wskaźnikiem kolejnej instrukcji.
\end{enumerate}
Dostępny dla użytkownika zbiór dozwolonych instrukcji zależy od twórcy danego procesora i określa on swobodę dotyczącą jego programowania. Dla przykładu, w przypadku, gdy nie istnieje sprzętowa obsługa operacji pierwiastkowania, można dokonać emulacji tej funkcjonalności poprzez odpowiednią sekwencję operacji elementarnych~\cite{FAST_INV_SQRT}. Przeważnie czas wykonania emulowanej funkcji będzie dłuższy niż gdyby procesor udostępniał dedykowaną do tego instrukcję. Z punktu widzenia wydajności ważne jest też, aby procesor był zdolny przetwarzać instrukcje z interwałem równym 1 - wykorzystywana jest tutaj niezależność między poszczególnymi etapami przetwarzania instrukcji - z  możliwie najwyższą częstotliwością pracy. 

Jednym z kierunków rozwoju architektur procesorów jest poszukiwanie takiego rozwiązania, które udostępniałoby rozsądny zestaw instrukcji\footnote{Przez to sformułowanie należy rozumieć zachowanie balansu między możliwościami oddawanymi w ręce użytkownika a skomplikowaniem technologicznym.}, jednocześnie wymagając do jego implementacji jak najmniej zasobów sprzętowych. Warto w tym miejscu wspomnieć o projekcie \textit{iDEA}~\cite{iDEA}, który został stworzony od podstaw z myślą o maksymalnym wykorzystaniu znajdujących się w układach FPGA firmy Xilinx bloków DSP. Autorzy zauważyli, że elastyczność oferowana przez bloki DSP pozwala na implementację większości operacji bezpośrednio z ich użyciem. W efekcie uzyskano 32-bitowy procesor\footnote{Wszystkie dostępne instrukcje, za wyjątkiem mnożenia, przeprowadzane są na 32-bitowych liczbach całkowitych. Jedynie parametry mnożenia są ograniczone do 16 bitów~(wynik jest 32-bitowy), z uwagi na fakt, iż bloki DSP, w zależności od wersji, posiadają wbudowany blok dokonujący iloczynu czynników 25(27)- i 18-bitowego.} mogący pracować z częstotliwością ok.~400~MHz przy tym wymagający do jego implementacji jedynie 1~bloku~DSP, 2~BRAM oraz 335~LUT\footnote{Podane wartości dotyczą układu Virtex-6.}. Porównanie tych wartości z oferowanymi przez obecne układy FPGA zasobami~(tabela~\ref{ch3:tab:fpga_comp})  prowadzi do wniosku, że procesorów takiego lub bardziej rozbudowanego typu na jednym układzie można byłoby umieścić setki - otrzymując tym samym sieć procesorów zdolnych współbieżnie i stosunkowo szybko, jak na układy FPGA, przetwarzać dane. 

Na bazie tej obserwacji do tej pory powstało wiele prototypowych systemów, których celem była realizacja śledzenia promieni w czasie rzeczywistym scen o dowolnej złożoności. Wartym wspomnienia jest tutaj cykl prac~\cite{Realtime_FPGA}\cite{RPU}\cite{Realtime_ASIC}, gdzie autorzy szczegółowo przedstawiają, w jaki sposób udało im się osiągnąć zamierzony efekt poprzez bardzo dokładną analizę zależności między podsystemami: pamięci, procesorów oraz jednostek analizujących przecięcia promieni z geometrią i wykorzystanych przez nie zasobów układu FPGA. Udostępniając użytkownikowi możliwość generowania promieni wtórnych do 4 pokolenia, programowanie sposobu oświetlenia powierzchni~(użytkownik mógł tworzyć własne BRDF) oraz przetwarzanie scen złożonych z milionów trójkątów rozwiązanie to potrafiło generować obraz z szybkością co najmniej 1 klatki obrazu na sekundę~(uwarunkowane jest to oczywiście poprzez rozdzielczość obrazu oraz złożoność sceny). Inne ciekawe rozwiązanie zostało zaproponowane w pracy~\cite{TRAX}. Jak podnoszą sami autorzy ich system był prostszy w budowie niż ten, o którym wspomniano wcześniej, jednak eksplorował w znacznie większym stopniu wykorzystanie hierarchicznej sieci prostych procesorów arytmetycznych. Pojedynczy rdzeń~(tych w układzie można było umieszczać dowolne ilości) składał się z 32 wątków zdolnych wykonywać podstawowe operacje na liczbach całkowitych oraz zmiennopozycyjnych jednak w obrębie rdzenia współdzieliły one między siebie jednostki odpowiedzialne za obliczanie iloczynów czy odwrotności liczby. Takie postępowanie było uzasadnione obserwacją, iż w kodzie programu operacje te są wykonywane odpowiednio rzadko i nie ma potrzeby, by każdy z wątków posiadał własne jednostki do przeprowadzania operacji arytmetycznych tego typu.

Cechą wspólną obu przedstawionych systemów śledzenia promieni jest to, że polegają one w znacznym stopniu na wydajności pojedynczego podsystemu przetwarzania instrukcji, który na dodatek musi być odpowiednio niewielki~(używać niewiele zasobów FPGA) aby można było współbieżnie przetwarzać wiele promieni. Co więcej ich twórcy podkreślają rolę języków opisu sprzętu w swobodnym kreowaniu sposobu przepływu danych w ich systemach.

\subsubsection{Projekt układu procesorowego z użyciem Vivado HLS}
Niniejszy projekt układu procesorowego wykonano dla układu VC707 przy użyciu Vivado Design Suite 2017.2\footnote{Pliki projektu zostały umieszczone w repozytorium dostępnym pod adresem:
\url{https://bitbucket.org/rtMasters/simpipeline/src/FINAL_SPU/}.}. Stworzony moduł IP zaprojektowano w taki sposób, aby jego uruchomienie z dostarczoną listą instrukcji oraz opcjonalnymi danymi zewnętrznymi skutkowało zapisem wartości do bufora klatki obrazu o podanych rozmiarach, stąd dla każdego piksela w pętli z zastosowaną dyrektywą \texttt{DATAFLOW} najpierw następuje wygenerowanie promienia o odpowiednim punkcie początkowym i kierunku, odpowiadającym rzutowaniu perspektywicznemu~(\texttt{CreateRay()}), potem następuje przetworzenie ciągu instrukcji (\texttt{ProcessInstructions()}), zwieńczone zapisem obliczonej wartości do bufora koloru~(\texttt{PutColor()}). Dalszy opis będzie skoncentrowany tylko na zagadnieniach związanych z przetwarzaniem rozkazów przez \texttt{ProcessInstructions()}.
\paragraph{Rejestry procesora i architektura instrukcji}
Z uwagi na fakt, iż śledzenie promieni wymaga przetwarzania danych wektorowych podjęta została decyzja o tym by procesor miał do swojej dyspozycji 16 $[0:15]$ wektorowych rejestrów wewnętrznych, z których każdy składa się z 4 32-bitowych elementów, co pozwoliłoby na przechowywanie większości potrzebnych danych. Każda instrukcja natomiast składa się z 4 wykonywanych jednocześnie podinstrukcji, których wynikiem w przypadku działań arytmetycznych jest skalar, którego wartość może być zapisana  do dowolnego rejestru wektorowego, jednakże indeks zapisu w rejestrze wektorowym jest jednakowy z indeksem podinstrukcji. Każda podinstrukcja jest opisana za pomocą 32-bitowej wartości, której rozmieszczenie i znaczenie poszczególnych bitów, w zależności od typu podinstrukcji, zostało ukazane na poniższym rysunku:
\addimage{chapters/ch3/img/instruction.png}{scale=0.43}{Rozmieszczenie bitów danych opisujących podinstrukcję}{Rozmieszczenie bitów danych opisujących podinstrukcję}{ch3:img:instruction}
\begin{itemize}
\item[] $[31:28]$ - \texttt{it} - opisuje rodzaj podinstrukcji, która ma być wykonana,
\item[] $[27:23]$ - \texttt{wr} - indeks rejestru wektorowego, do którego zostanie zapisany rezultat~(indeks skalara w wektorze jest dedukowany na podstawie numeru podinstrukcji),
\item[] $[22:21]$ - \texttt{idx0} - indeks skalara pierwszego parametru~(inne znaczenie w przypadku skoku warunkowego, patrz tabela~\ref{ch3:tab:instructions}),
\item[] $[20:29]$ - \texttt{idx1} - indeks skalara drugiego parametru~(inne znaczenie w przypadku skoku warunkowego, patrz tabela~\ref{ch3:tab:instructions}),
\item[] $[15:8]$ - \texttt{r0} - wartość liczbowa ze znakiem, wskazująca na indeks rejestru wektorowego będącego pierwszym parametrem, jeśli wartość jest ujemna tzn. $[15]=1$ wartość tego rejestru wzięta do obliczeń zostanie zanegowana,
\item[] $[7:0]$ - \texttt{r1} - wartość liczbowa ze znakiem, wskazująca na indeks rejestru wektorowego będącego drugim parametrem, jeśli wartość jest ujemna tzn. $[7]=1$ wartość tego rejestru wzięta do obliczeń zostanie zanegowana,
\item[] $[18:0]$ - \texttt{val} - stała podawana przez użytkownika
\end{itemize}
Stworzony procesor potrafi przetwarzać 16 instrukcji zebranych i opisanych w tabeli~\ref{ch3:tab:instructions}. Chociaż przedstawiony zbiór instrukcji jest niewielki, procesor jest w stanie dokonywać obliczeń przecięcia promieni z obiektami oraz dokonywać obliczeń koloru danego piksela~(zwłaszcza po uwzględnieniu obecności instrukcji \textbf{PRE\_S} oraz \textbf{PRE\_D}, które dokonują inicjalizujących manipulacji na parametrach będących wstępem do obliczeń przybliżonych metodą Newtona-Raphsona). 
\input{chapters/ch3/instructions}
\paragraph{Działanie procesora} Schemat przetwarzania został ukazany na rysunku~\ref{ch3:img:processing_pipeline}. 
\addimage{chapters/ch3/img/processing_pipeline.png}{scale=0.4}{Potok przetwarzania w stworzonym procesorze. Wejście stanowi lista instrukcji oraz dane zewnętrzne. W pętli zoptymalizowanej dyrektywą \texttt{PIPELINE} następuje pobranie instrukcji, jej odkodowanie a następnie przetworzenie przez układy logiczne i/lub arytmetyczny~(ALU). Wyniki są zapisywane do odpowiednich rejestrów i przetwarzana jest kolejna instrukcja. Po wykonaniu wszystkich instrukcji pierwszy z rejestrów wektorowych jest przyjmowany za ten, którego zawartość stanowi kolor piksela}{Potok przetwarzania w stworzonym procesorze}{ch3:img:processing_pipeline}
Widać na nim (oraz co wynika z analizy dostępnych instrukcji), że jest to układ nieskomplikowany, pozbawiony pamięci podręcznej czy możliwości zwrotnego asynchronicznego zapisu wartości poza układ za to z licznymi ograniczeniami~(opisanymi w uwagach w tabeli~\ref{ch3:tab:instructions}). Rzecz w tym, że Vivado HLS nie umożliwiło jego dalszej komplikacji i to przez co najmniej kilka przyczyn. 
\begin{enumerate}
\item Z uwagi na występujące w procesorach sprzężenie zwrotne między rejestrami, Vivado HLS dobiera taki interwał pomiędzy przetwarzaniem kolejnych instrukcji, aby w każdym przypadku zapis wyniku do rejestru następował przed jego możliwym odczytem związanym z przetwarzaniem kolejnej instrukcji. Teoretycznie zachowanie się Vivado HLS w przypadku wykrycia przez nie zależności między danymi można modyfikować dzięki zastosowaniu dyrektywy \texttt{DEPENDENCE}, jednak w żaden sposób nie udało się tego wymusić, a czas syntezy HLS znacznie wzrastał (z kilku minut do kilku godzin). Gdyby ta optymalizacja działała, należałoby z teoretycznymi zależnościami między instrukcjami radzić sobie poprzez odpowiednie napisanie kodu (zmieniając kolejność instrukcji bez wpływu na algorytm czy wstawiając instrukcje puste \texttt{NOP}) jednak nie istniałoby sztywne ograniczenie szybkości przetwarzania. 

Poleganie jedynie na statycznym osądzie HLS co do zależności między danymi wymusiło, aby operacje wykonywane przez jednostkę arytmetyczną~(ALU) były wykonywane jak najszybciej. Zgodnie z informacjami zawartymi w tabeli~\ref{ch3:tab:op_type_util_time} nadawały się do tego jedynie typy liczbowe stałopozycyjne, dla których czas wykonania operacji dodawania i mnożenia zawiera się w jednym cyklu zegara. Przyjęto zatem, że elementy skalarne rejestrów wektorowych będą typu \texttt{ap\_fixed<32, 16>}, zaś wartości, które są wczytywane bezpośrednio z przekazanej podinstrukcji~(\texttt{val}) \texttt{ap\_fixed<19, 13>}. Mimo takich zabiegów Vivado HLS mógł jedynie zaoferować interwał równy 3~(opóźnienie iteracji pętli wyniosło 12) przy częstotliwości zegara~100~MHz. 

\item Z podobnych przyczyn jak powyżej nie udało się dokonać implementacji skoków między partiami wykonywanego programu (skoki są ważne wszędzie tam, gdzie dochodzi do warunkowego wykonania określonej porcji instrukcji). W większości procesorów, gdy następuje konieczność wykonania skoku następuje wyczyszczenie potoku przetwarzania~(tzn. wszystkie instrukcje, które rozpoczęły być przetwarzane zanim znaleziono polecenie skoku są dyskredytowane, a wskaźnik na kolejną instrukcję jest ustalony w nowym miejscu). W prezentowanym rozwiązaniu teoretycznie istnieją polecenia dokonujące skoku \texttt{JMP}, \texttt{JMP\_IF}, \texttt{JMP\_IFN} jednak ich efektem działania jest tylko to, że wyniki przetwarzanych \texttt{unsigned(val)} instrukcji nie są zapisywane~(nie można też przez to cofać się w wykonaniu instrukcji, co uniemożliwia tworzenie pętli). W rezultacie każda dodana instrukcja, na którą składają się 4 podinstrukcje, dodaje stały przyczynek do czasu wykonania równy interwałowi~(3 cykle zegara). 

\item Implementacja powyższego procesora w strukturze układu VC707 wymaga stosunkowo dużej ilości zasobów~(tabela~\ref{ch3:tab:spu_util}). 

\begin{table}[H]
\centering
\caption[Wykorzystanie zasobów sprzętowych przez procesor instrukcji]{Wykorzystanie zasobów sprzętowych przez procesor instrukcji~(\texttt{ProcessInstructions()}). Dolny wiersz przedstawia procentowe wykorzystanie zasobów układu VC707 raportowane po syntezie HLS}
\label{ch3:tab:spu_util}
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{BRAM}} & \multicolumn{1}{c|}{\textbf{DSP}} & \multicolumn{1}{c|}{\textbf{FF}} & \multicolumn{1}{c|}{\textbf{LUT}} \\ \hline
0                                   & 64                                & 41457                            & 17404                             \\ \hline\hline
0\%                                 & 2,29\%                            & 6,83\%                           & 5,73\%                            \\ \hline
\end{tabular}
\end{table}

W dużej mierze wynika to z przyjętego przetwarzania 4 podinstrukcji jednocześnie, gdzie każda z nich może odwoływać się do dwóch dowolnych rejestrów wektorowych. Układy BRAM, które implementują funkcjonalność tablic umożliwiają do dwóch operacji dostępu w jednym cyklu zegara. Mogłoby się wydawać, że w takim razie pamięć związaną z rejestrami można podzielić na 4 i wtedy każda podinstrukcja będzie wykorzystywała dostępne dla siebie 2 operacje odczytu. Nie jest to prawdą, gdyż nieznany jest schemat dostępu do danych~(instrukcje wymagane przez użytkownika mogą odwoływać się dowolnie do rejestrów) stąd konieczność użycia kompletnego podziału tablicy (dyrektywa \texttt{ARRAY\_PARTITION}) rejestrów na poszczególne składowe - okupione jest to znacznym wzrostem zapotrzebowania na LUT i FF. Pozornym rozwiązaniem tego problemu, byłoby przejście na tradycyjny model przetwarzania tylko jednego rozkazu przez jedną instrukcję. Takie działanie wydłużyłoby tylko listę rozkazów lecz powyższe 2 problemy by pozostały.

\end{enumerate}

W celu sprawdzenia poprawności działania układu procesorowego, jakości wyników oraz estymacji czasu wykonania w typowym zastosowaniu stworzono prosty program testowy, którego celem było znalezienie odległości od obserwatora $O$ znajdującego się w początku układu współrzędnych $\vec{p_o} = [0; 0; 0]$ ustawionego w kierunku $\vec{d_p} = [0; 0; -1]$ do najbliższego punktu znajdującej się przed nim sfery o promieniu $R = 1$ i środku $\vec{p_s} = [0; 0; -2,5]$. W ten sposób wynikiem, który się otrzymuje jest tzw. \textit{mapa głębokości}\footnote{Opisywany dalej algorytm został zapisany jako ciąg instrukcji tekstowych w pliku \url{src/CodeParser/program.asm} znajdujący się w repozytorium projektu. Instrukcje te następnie są transformowane do kodu bajtowego interpretowalnego przez procesor z użyciem \url{src/CodeParser/PYCodeParser.py}.}. Transformacja sfery w przestrzeni była opisana poprzez macierz jej przekształcenia $\mathbf{M}$, a obliczeń dokonywano w przestrzeni tego obiektu\footnote{Postępowanie takie umożliwia deformację obiektu za pomocą odpowiedniej macierzy. Dodatkowo równania przecięcia, które należy rozwiązać, aby uzyskać wartość $t$, będącą odległością między obserwatorem a obiektem wzdłuż promienia, ulega uproszczeniu z postaci:
\begin{equation*}
\sum_{i=0}^2\left(r_i - p_{s_i} \right)^2 = R^2
\end{equation*}
do:
\begin{equation*}
\sum_{i=0}^2 r_i'^2 = 1
\end{equation*}

}. Wymagało to, aby promienie $\vec{r} = \vec{p_o} + t\vec{d}$ były transformowane za pomocą macierzy odwrotnej $\mathbf{M^{-1}}$~($\mathbf{MM^{-1} = I}$) do przestrzeni sfery $\vec{r}' = \mathbf{M^{-1}}\vec{r} = \vec{p_o}' + t'\vec{d}'$. 

Rozwiązanie równania przecięcia promienia ze sferą wymaga rozwiązania równania kwadratowego, a w szczególności obliczenia wyróżnika~$\sqrt{\Delta}$. W tym celu posłużono się  dostępną instrukcją \texttt{PRE\_S}, po której wywołano dwukrotnie ciąg instrukcji obliczający dwie iteracje metodą Newtona-Raphsona. Następnie obliczane były odległość od obserwatora $t'$\footnote{Z uwagi na fakt, iż kula była poddana jedynie translacji $t = t'$.} w przestrzeni obiektu, normalna w punkcie zderzenia $\vec{n}'$ oraz punkt przecięcia w przestrzeni obiektu $\vec{h_p}'$.

Wszystkie wspomniane operacje udało się opisać za pomocą 20 instrukcji, przy czym tylko 43 podinstrukcje z 80 były różne od \texttt{NOP}. Związane jest to z faktem, iż iteracyjne obliczanie pierwiastka kwadratowego wymagało w tym przypadku w sumie 10 instrukcji, a każda z nich wykorzystuje nie więcej niż 2 podinstrukcje. 

Program ten wykorzystano do stworzenia mapy głębokości o rozdzielczości 100~x~100 pikseli~($10^4$ punktów obrazu), która została zaprezentowana na rysunku~\ref{ch3:img:depth_map_sphere}. Ogólny przebieg zależności jest zbieżny z oczekiwanym - sfera w najbliższym dla obserwatora miejscu jest oddalona o $x=1,5$ jednostki, a w najdalszym $x=2,5$~(gdy promień jest niemal styczny do powierzchni sfery). Niepokojąca jest jednak zauważalna nieciągłość wartości  w okolicach $x\approx 1,75$ od obserwatora, a związana z przyjętą precyzją obliczeń~(\texttt{ap\_fixed<32, 16>}) i wykorzystaniem obliczeń przybliżonych użytych do obliczenia wyróżnika~$\sqrt{\Delta}$~(na rysunku~\ref{ch3:img:depth_map_sphere_cut} ukazany został jeden z profili odległości przechodzący przez punkt najbliższy obserwatorowi). 

\addimage{chapters/ch3/img/depth_map_sphere.png}{scale=0.5}{Mapa głębokości wykonana na podstawie obliczonych przez procesor danych. Sfera o promieniu $R=1$ i środku w punkcie $\vec{p_s} = [0; 0; -2,5]$ w najbliższym obserwatorowi miejscu, zgodnie z oczekiwaniami jest oddalona o wartość $x=1.5$}{Mapa głębokości wykonana na podstawie obliczonych przez procesor danych}{ch3:img:depth_map_sphere}
\addimage{chapters/ch3/img/depth_map_sphere_cut.png}{scale=0.5}{Profil odległości sfery od obserwatora przechodzący przez punkt najbliższy obserwatorowi. Widoczne są nieciągłości dla odległości $x\approx 1,75$ wynikające z precyzji obliczeń. Uzyskany profil nie jest kolisty ze względu na zniekształcenie perspektywy obserwatora}{Profil odległości sfery od obserwatora przechodzący przez punkt najbliższy obserwatorowi}{ch3:img:depth_map_sphere_cut}

Zgodnie z tym, co powiedziano wcześniej stworzony program składał się z 20 instrukcji, gdzie każda z nich jest wykonywana z interwałem równym 3. Wykonanie takiego programu dla wspomnianej rozdzielczości~($10^4$ pikseli) z zegarem 100~MHz~(1~cykl zegara odpowiada okresowi 10~ns) zajmuje:
\begin{equation}
20\cdot 3 \cdot 10^4 \cdot 10\ \mathrm{ns} = 6\ \mathrm{ms}
\end{equation}
z użyciem jednego procesora. Jednakże:
\begin{enumerate}
\item Przedstawiony program dokonuje tylko testu z jednym obiektem. Dodanie kolejnych obiektów wiąże się z dalszymi liniami kodu, które wydłużają czas wykonania liniowo.
\item Obliczenia, jak pokazano nie charakteryzują się wysoką precyzją. Zastosowanie liczb stałopozycyjnych~(wymuszone przez brak oczekiwanego działania dyrektywy \texttt{DEPENDENCE}) nakłada warunki m. in. na skalę sceny tzn. wielkości obiektów i odległości między nimi musiałyby być porównywalne.
\item Należy zwrócić uwagę, iż program ten nie dokonuje obliczenia koloru obiektu w wyniku oddziaływania ze źródłami światła oraz rozproszeń~(odbicia i załamania światła).
\item Obliczenia zostały wykonane dla zaledwie 1\% rozdzielczości docelowej.
\end{enumerate}
Nawet jeśli w strukturze układu FPGA udałoby się realnie umieścić 10 takich procesorów przetwarzających odpowiednią partię sceny i każdy z nich działałby z częstotliwością 150~MHz~(taką wartość udało się uzyskać po implementacji procesora w układzie VC707), otrzymana wydajność nie pozwoliłaby na osiągnięcie zamierzonych celów związanych ze stworzeniem systemu śledzenia promieni działającego w czasie rzeczywistym. Oczywista porażka w tym przypadku wynika z poświęcenia części elastyczności, którą zapewniają języki opisu sprzętu, na rzecz łatwego w interpretacji zapisu algorytmicznego poddawanego translacji do RTL za pomocą Vivado HLS. Zgodnie z tym co przedstawiono, Vivado HLS nie nadaje się do budowy modułów wymagających dużej kontroli nad sposobem przepływu danych oraz wykonaniem algorytmu. Użycie kodu C/C++ nie pozwala również na stworzenie w jednym module zadań wykonywanych asynchronicznie - te wymagane są do implementacji pamięci podręcznej czy struktur akcelerujących przetwarzanie przecięć promieni z geometrią sceny.

Kończąc opis tego rozwiązania, należy mieć na względzie, iż możliwość stworzenia za pomocą Vivado HLS szybkiego i małego~(w sensie utylizacji zasobów układu FPGA) procesora geometrii była przez długi czas główną koncepcją, na jakiej oparty miał być system generowania obrazów metodą śledzenia promieni. Przedstawiony tutaj procesor jest najszybszym ze stworzonych, aczkolwiek wniosek ten jest prawdziwy tak długo jak do syntezy wykorzystywana jest wersja 2017.2 Vivado Design Suite. Ten sam procesor poddany syntezie z użyciem wersji 2016.2 tego narzędzia z syntezą o takich samych parametrach tworzył moduł o interwale 5, zatem wyraźnie wolniejszy. Z drugiej jednak strony nowsza wersja nie potrafiła poprawnie planować wykonania zadań w regionie objętym dyrektywą \texttt{DATAFLOW}~(przez co jej wykorzystanie nie dawało żadnych korzyści w postaci zmniejszenia czasu wykonania) oraz nie umożliwiała wykonania testów tworzonego modułu w środowisku C/C++\footnote{Wymuszało to postępowanie, takie że synteza HLS była przeprowadzana w wersji 2017.2 narzędzia, zaś testy wykonywano w wersji 2016.2.}. Z drugiej strony nowsze wersje środowiska tzn. 2017.3 i nowsze w ogóle nie potrafią przeprowadzić syntezy przygotowanego kodu~(głównie ze względu na zmianę interfejsów funkcji odpowiedzialnych za obsługę liczb stałopozycyjnych, na których projekt opiera swoje działanie). Przytoczone obserwacje pokazują, że Vivado HLS ulega zmianom, nie zawsze tylko wszystkie zmiany w nim zachodzące są pożądane i aktualnie istnieje duży problem związany z wyborem optymalnej jego wersji.

\subsection{Wyspecjalizowany akcelerator o ustalonej funkcjonalności}
Wiedza oraz doświadczenie zdobyte podczas prac nad stworzeniem modułu śledzenia promieni opartego o przetwarzanie zestawu instrukcji miały się jednak przydać podczas projektowania zupełnie innego rozwiązania, opartego o zestaw funkcjonalności na stałe zakodowany w module. W porównaniu z procesorem, rozwiązanie to ma taką zaletę, że już na etapie syntezy Vivado HLS wie, jakie działania składają się na wykonanie algorytmu, a przez to jest w stanie optymalnie szeregować wykonanie operacji dla jak największej wydajności - o ile tylko program jest napisany wystarczająco starannie tzn. twórca ma świadomość, że to, co jest reprezentowane przez linie kodu będzie docelowo stanowić alokację fizycznych zasobów sprzętowych układu FPGA. Stąd od razu widać, iż dodanie każdej nowej funkcjonalności do tworzonego akceleratora, będzie wiązało się z wykorzystaniem pewnej części układu. Są to dwa wzajemnie wykluczające się czynniki warunkujące rozwój tego typu akceleratora. Trzecim jest wydajność. Omówione na początku tego rozdziału założenia narzucają, by interwał między obliczeniem koloru kolejnych pikseli był nie większy niż 10 cykli zegara przy częstotliwości pracy 100~MHz. Taki efekt można uzyskać jedynie wtedy, gdy stworzony algorytm umożliwia zastosowanie dyrektyw \texttt{PIPELINE} i/lub \texttt{DATAFLOW} w odpowiednich miejscach programu. Im wymagania względem interwału pracy bloku kodu objętego dyrektywą \texttt{PIPELINE} są wyższe~(tzn. interwał dąży do jedności), tym  Vivado HLS ma mniejsze możliwości w zakresie użycia tych samych zasobów na kolejnych etapach przetwarzania danych, w efekcie wzrasta utylizacja elementów układu FPGA.
\addimage{chapters/ch3/img/fpga_triangle.png}{scale=0.3}{Trójkąt zależności między sprzecznymi ze sobą charakterystykami akceleratora: funkcjonalnością, wydajnością oraz utylizacją zasobów}{Trójkąt zależności między sprzecznymi ze sobą charakterystykami akceleratora}{ch3:img:fpga_triangle}

W wyniku przeprowadzonych prac badawczo-rozwojowych powstał \textsc{ViRay}, czyli modularny system generowania obrazów metodą śledzenia promieni, implementowalny i działający w czasie rzeczywistym z użyciem układów FPGA firmy Xilinx. Jego podstawowa wersja została zoptymalizowana pod kątem układu  Kintex UltraScale+ znajdującego się na płytce ewaluacyjnej KCU116, a do jego stworzenia wykorzystano Vivado Design Suite w wersji 2017.4\footnote{Nazwa systemu jest skrótowcem od ang. \textit{Virtex ray tracer}, który został wymyślony jeszcze na samym początku prac, kiedy do dyspozycji Autora był układ Virtex~7.}\footnote{Pliki projektu dostępne są pod adresem: \url{https://bitbucket.org/rtMasters/ffcore/src/Oren-Nayar_correct/}}.

\addimage{chapters/ch3/img/viray_scheme.png}{scale=0.5}{Ogólna zasada działania modułu \textsc{ViRay}.}{Ogólna zasada działania modułu \textsc{ViRay}}{ch3:img:viray_scheme}

Ogólna zasada działania stworzonego modułu z użyciem Vivado HLS została przedstawiona na rysunku~\ref{ch3:img:viray_scheme}. Na początku w funkcji głównej~(\texttt{Init()}) dokonywana jest inicjalizacja wewnętrznych struktur danych na podstawie parametrów dostarczonych do modułu, po czym następuje główna pętla przetwarzania~(\texttt{RenderScene*()}), w której przeprowadzane są obliczenia dotyczące wszystkich żądanych pikseli obrazu zgodnie z dostarczonym opisem sceny. Tutaj dla każdego nowo obliczanego piksela, najpierw tworzony jest promień pierwotny~(\texttt{CreatePrimaryRay()}), który jest następnie testowany na wypadek przecięcia z obiektami~(\texttt{VisibilityTest()}). Jeśli zderzenie nastąpi, obliczany jest kolor piksela~(\texttt{Shade()}) oraz generowany jest rozproszony promień wtórny względem pierwotnego~(\texttt{ray = ray'}). Ten staje się w kolejnej iteracji promieniem odpowiedzialnym za dostarczenie informacji o świetle rozproszonym. Ilość iteracji, a przez to głębokość śledzenia promieni związanych z kolorem danego piksela jest konfigurowalna. Finalny kolor piksela jest następnie zapisywany w buforze ramki~(\texttt{SaveColorToBuffer()}).

Modularność \textsc{ViRay}'a powoduje, że wiele kluczowych podsystemów biorących udział w tworzeniu finalnego obrazu może zostać ustalone za pomocą jednego pliku konfiguracyjnego~\texttt{typedefs.h}. Z jego pomocą można m. in.:
\begin{itemize}
\item określić pulę rodzajów i maksymalną ilość obiektów możliwych do renderowania przez system,
\item zmienić interwał między kolejnymi pikselami,
\item dostosować możliwości podsystemu odpowiedzialnego za teksturowanie obiektów lub całkowicie go wyłączyć,
\item wybrać, które z zaawansowanych modeli oświetlenia mają być dostępne w systemie,
\item usprawnić szybkość wykonania w środowisku testowym.
\end{itemize}
Każdy parametr jest osobną dyrektywą preprocesora~(\texttt{\#define}), a najważniejsze z nich zostały zebrane i opisane w tabeli~\ref{ch3:tab:typedefs}. Koncepcja modularności sprawia z jednej strony, iż kod programu jest dłuższy i bardziej skomplikowany poprzez zastosowanie konstrukcji typu:
\begin{lstlisting}
#ifdef DYREKTYWA
	a = 2;
#else
	a = 0.5;
#endif
\end{lstlisting}
jednak posiada niezrównaną zaletę, jaką jest możliwość łatwego dostosowania parametrów modułu do aktualnych potrzeb. Pozwala to na eksplorację najbardziej optymalnych rozwiązań pod kątem tego, co zilustrowane zostało na rysunku~\ref{ch3:img:fpga_triangle}. Na dodatek pozwala zastosować mniej wymagające algorytmy, jeśli implementacja napotyka problemy związane z wytworzeniem odpowiedniej sieci połączeń. Jest to też rozwiązanie przyszłościowe - dysponując nowszą generacją układów FPGA będzie można szybko ulepszyć charakterystykę systemu np. zmniejszając interwał czy zwiększając głębokość śledzenia promieni.

\input{chapters/ch3/typedefs}

\subsubsection{\textsc{ViRay} - najważniejsze komponenty modułu}
\begin{enumerate}
\item Inicjalizacja modułu

Wejście modułu \textsc{ViRay} stanowi zespół wskaźników na tablice danych i wartości, które w jednoznaczny sposób przechowują definicję sceny tzn.:
\begin{itemize}
\item określają transformacje oraz typy obiektów geometrycznych,
\item zawierają parametry mówiące o materiale, z jakiego obiekt jest wykonany tj. BRDF, dane tekstury,
\item ustanawiają parametry związane ze źródłami światła,
\item definiują położenie, orientację w przestrzeni i inne podstawowe parametry kamery~(obserwatora).
\end{itemize}
Dane te przychodzą do modułu w postaci 32 bitowych liczb~(zmiennopozycyjnych oraz całkowitoliczbowych). W przypadku tablic, dane przez nie zawierane są zlinearyzowane tzn. każda tablica przechowuje dane o $k$ wektorach. Każdy 32 bitowy element takiego wektora, zależnie od jego położenia w tym wektorze posiada odpowiednie znaczenie, które musi być odpowiednio zinterpretowane~(rysunek~\ref{ch3:img:decode}). Wymaga to zastosowania procedur, które na podstawie dostarczonych danych będą w stanie dokonać odpowiedniej inicjalizacji wewnętrznych struktur.
\addimage{chapters/ch3/img/decode.png}{scale=0.5}{Przykład zapisu danych w tablicach wejściowych. Elementy \texttt{a, b, c, d} niosą odpowiednie informacje o \texttt{i}-tym elemencie struktury danych odpowiedzialnej za jedną z części opisu sceny}{Przykład zapisu danych w tablicach wejściowych}{ch3:img:decode}
Alternatywnie, parametry wejściowe mogłyby zostać przekazane w formie tablic odpowiednich struktur, co uprościłoby proces inicjalizacji w module. W takiej sytuacji domyślnym zachowaniem Vivado HLS jest takie, że każdy element struktury staje się nowym portem danych.
\begin{lstlisting}
typedef struct{
	float s;
	float t;
}scale;
\end{lstlisting}
W sytuacji przedstawionej powyżej w wyniku syntezy zostaną utworzone oddzielne porty dla \texttt{s} oraz \texttt{t}. Jeśli \texttt{scale} jest tablicą, to \texttt{s}, \texttt{t} będą tak naprawdę portami odwołującymi się do tablic \texttt{s[]}, \texttt{t[]}. Stąd port odpowiadający \texttt{s[]} musiałby wskazywać na liniowy element przechowujący kolejne wartości \texttt{s} tablicy struktur \texttt{scale}. Takie rozwiązanie, choć działa, okazało się niepraktyczne w momencie obsługi modułu za pomocą mikrokontrolera. Zgodnie z dokumentacją Vivado HLS~\cite{UG902} możliwa jest jednak automatyczna linearyzacja struktur, skutkująca wygenerowaniem pojedynczego portu dla struktury za pomocą dyrektywy \texttt{DATA\_PACK}. Pomimo wielu testów, skuteczność tej dyrektywy nie została potwierdzona. Działa ona w przypadku, gdy struktura przechowuje dane całkowite oraz stałopozycyjne. Jeśli jednak zawarte są w niej wartości zmiennoprzecinkowe, odczytywane dane przez moduł nie są poprawne. 

W związku z powyższym, odkodowanie parametrów wejściowych jest dokonywane bezpośrednio przez algorytm, w sposób ręczny, gdyż tylko w taki sposób można zapewnić poprawność odczytu danych przy zachowaniu rozsądnej~(tj. możliwie niskiej) liczby portów.

\item Model kamery i parametry obrazu

Jedynym udostępnianym przez \textsc{ViRay} modelem kamery jest kamera perspektywiczna~(rysunek~\ref{ch3:img:camera_model}). Opisana jest ona poprzez następujące parametry:
\begin{itemize}
\item pozycję obserwatora (\texttt{eyePosition)} zadaną w globalnym układzie współrzędnych,
\item ortonormalną bazę wektorów $\vec{u}$, $\vec{v}$, $\vec{w}$ tworzących lokalny dla obserwatora prawoskrętny układ współrzędnych określający jego orientację w przestrzeni,
\item odległość rzutni (\texttt{nearPlane}) od obserwatora w kierunku $-\vec{w}$ definiującą szerokość pola widzenia,
\item parametr odpowiedzialny za powiększenie (\texttt{zoom}) - im jest on mniejszy, tym powiększenie większe.
\end{itemize}
Parametry rzutni tj. szerokość~(\texttt{WIDTH}) oraz wysokość~(\texttt{HEIGHT}) ramki obrazu muszą zostać podane w momencie syntezy HLS~(patrz tabela~\ref{ch3:tab:typedefs}). Kiedy rozpoczyna się przetwarzanie nowego piksela obrazu, wywoływana jest funkcja \texttt{GetCameraRayForPixel()}, która przyjmuje parametr zależny od współrzędnych piksela $[w; h] \in [0; \mathtt{WIDTH} - 1]\times[0; \mathtt{HEIGHT} - 1]$ - ten wpływa na kierunek propagacji nowego promienia pierwotnego.

\addimage{chapters/ch3/img/camera_model.png}{scale=0.5}{Kamera w module \textsc{ViRay}. Parametry kamery oraz położenie piksela w ramce obrazu~$[w;h]$ definiują początek oraz kierunek propagacji promienia pierwotnego}{Kamera w module \textsc{ViRay}}{ch3:img:camera_model}

\item Konstrukcja głównej pętli przetwarzania \texttt{RenderScene*()}

\texttt{ViRay} umożliwia wykorzystanie dwóch różnych konstrukcji głównej pętli przetwarzania, które ideowo przedstawiają się następująco:
\begin{enumerate}
\item {\color{white}a}

\begin{lstlisting}
for(unsigned h = 0; h < HEIGHT; ++h)
{
#pragma HLS DATAFLOW
	
	InnerLoop();
	memcpy();
}
void InnerLoop()
{
	...
	for(unsigned w = 0; w < WIDTH; ++w)
	{
	#pragma HLS PIPELINE
		...
	}
}
\end{lstlisting}
\item {\color{white}a}
\begin{lstlisting}
for(unsigned n = 0; n < NUM_OF_PIXELS; ++n)
{
#pragma HLS PIPELINE
	...
	memcpy();
}
\end{lstlisting}

\end{enumerate}
W przypadku (a) przetwarzanie pikseli obrazu zostało rozłożone na dwie pętle. Zewnętrzna dokonuje zmiany indeksu pionowego piksela \texttt{h}, zaś w wewnętrznej~(znajdującej się w funkcji \texttt{InnerLoop()}) z zastosowaną dyrektywą \texttt{PIPELINE} następuje obliczenie kolorów pełnego wiersza pikseli przy czym wszystkie piksele z wiersza zapisywane są do tymczasowego bufora pikseli, który jest w całości opróżniany do bufora ramki na koniec iteracji pętli zewnętrznej. Zachowanie takie pozwoliło wydzielić ciało zewnętrznej pętli jako region, który może zostać objęty dyrektywą \texttt{DATAFLOW}. Dane, czyli zawartość bufora tymczasowego, przepływają pomiędzy dwoma zadaniami tj.~obliczeniami, a zapisem do bufora ramki. Kiedy kończy się przetwarzanie danych w pętli wewnętrznej, dane przekazywane są do operacji zapisu \texttt{memcpy()} i w tym samym momencie wewnętrzna pętla może znowu rozpocząć pracę. Problem w takim przypadku, jest taki, iż kolejne obliczenia w pętli wewnętrznej nie stanowią kontynuacji dopiero co zakończonej funkcji \texttt{InnerLoop()} tzn. zanim zostanie wyliczony kolor pierwszego piksela w nowym wierszu minie czas równy opóźnieniu iteracji pętli wewnętrznej, który w finalnej wersji \textsc{ViRay}'a wynosi {\color{red}1331} cykli zegara. Biorąc pod uwagę, iż ramka obrazu w jakości Full HD ma wysokość równą 1080 daje to niemal $1,43\cdot 10^6$ nadmiarowych cykli zegara\footnote{Nadmiarowa ilość cykli wynikająca z każdorazowego rozpoczęcia funkcji \texttt{InnerLoop()} wynosi: 
\begin{equation}
1331 - \mathtt{DESIRED\_INNER\_LOOP\_II} = 1331 - 8 = 1323
\end{equation}
}. Przy standardowym okresie zegara równym 10~ns, czas tracony tylko z tego powodu to 14,3~ms. Twórcy Vivado HLS przewidzieli występowanie takich sytuacji w tego typu konstrukcjach wprowadzając modyfikator \texttt{rewind} do dyrektywy \texttt{PIPELINE} stosowanej w pętlach. W zamierzeniu sprawia on, że pętla wykonywać będzie się bez przerw na ponowne rozpoczęcie działania, jednak na etapie tworzenia \texttt{ViRay}'a nie udało się takiego zachowania wymusić.

Najprostsze możliwe rozwiązanie, które można włączyć poprzez niezdefiniowanie \texttt{RENDER\_DATAFLOW\_ENABLE} w pliku konfiguracyjnym \texttt{typedefs.h} zostało przedstawione ideowo w przykładzie~(b). Implementuje ono przetwarzanie pikseli w pojedynczej pętli, której ciało zostało objęte dyrektywą \texttt{PIPELINE}. Indeksy piksela w ramce obrazu $[w;h]$ są obliczane na podstawie aktualnej wartości iteratora \texttt{n}, a kolor obliczonego piksela jest zapisywany do bufora ramki bezpośrednio po jego obliczeniu. Eliminuje to nie tylko problem z wielokrotnym rozpoczęciem pętli, ale również usuwa konieczność przechowywania wartości kolorów pikseli w tymczasowym buforze oszczędzając elementy BRAM. 

Wyprzedzając w pewien sposób kolejność prezentacji poszczególnych elementów składowych pełnego systemu śledzenia promieni należy powiedzieć, iż rozwiązanie~(b) jest nieimplementowalne w układzie KCU116 z częstotliwością pracy uzasadniającą jego użycie\footnote{Rozwiązanie typu~(a) nawet pomimo nadmiarowych cykli zegara uzyskiwało znacznie krótsze czasy wykonania z uwagi na uzyskiwane wyższe częstotliwości pracy.}. 

W związku z powyższym zaproponowano, aby zmniejszyć częstość wywoływania \texttt{InnerLoop()} w przypadku~(a). Pętla wewnętrzna każdorazowo musiałaby przetwarzać więcej niż jeden wiersz bufora ramki, a wielkość bufora tymczasowego uległaby odpowiedniemu zwiększeniu. Ilość cykli zegara, które są potrzebne na przeprowadzenie obliczeń wszystkich pikseli ramki obrazu dana jest w przybliżeniu poniższą zależnością:
\begin{equation}
f(x) = \frac{\mathtt{HEIGHT}}{x}\left[IL + \left(\mathtt{WIDTH}\cdot x - 1 \right) \cdot c \right] + \mathtt{WIDTH}\cdot x = f_1(x) + f_2(x),
\label{ch3:eq:dataflow_latency}
\end{equation}
gdzie:
\begin{itemize}
\item[] $x$ - ilość wierszy obrazu obliczanych w jednym wywołaniu pętli wewnętrznej,
\item[] $IL$ - opóźnienie iteracji pętli wewnętrznej,
\item[] $c$ - interwał pętli wewnętrznej~(\texttt{DESIRED\_INNER\_LOOP\_II}).
\end{itemize}
Pierwszy składnik sumy $f_1(x)$ to przyczynek do całkowitego opóźnienia związany z obliczaniem pikseli obrazu, zaś $f_2(x)$ wyraża ilość cykli zegara wymaganą na zapis do bufora ramki ostatniej porcji danych przechowywanych w buforze tymczasowym~(wykorzystywany jest tryb seryjnego zapisu danych). Dla parametrów domyślnych systemu śledzenia promieni~(patrz tabela~\ref{ch3:tab:typedefs}) funkcja $f(x)$ prezentuje się następująco:

\addimage{chapters/ch3/img/dataflow_opt.png}{scale=0.5}{Zależność czasu wykonania głównej pętli algorytmu w funkcji ilości wierszy obrazu $x$ liczonych przy jednym wywołaniu pętli wewnętrznej \texttt{InnerLoop()}}{Optymalizacja czasu wykonania głównej pętli algorytmu}{ch3:img:dataflow_opt}

Z wykresu~\ref{ch3:img:dataflow_opt} widać, że znaczne oszczędności czasu wykonania można uzyskać już dla relatywnie niewielkich wartości $x$. Bezwzględne minimum można zaś wyliczyć z zależności:
\begin{align*}
\frac{\mathrm{d}f(x)}{\mathrm{d}x} &= -\frac{\mathtt{HEIGHT}\left(IL - c \right)}{x^2} + \mathtt{WIDTH} \equiv 0,\\
x &= \sqrt{\frac{\mathtt{HEIGHT}\left(IL - c \right)}{\mathtt{WIDTH}}} = 27,28\approx 27.
\end{align*}
Przyjęcie $x=27$ pozwala zaoszczędzić $1,326\cdot 10^6$ cykli zegara względem wersji niezoptymalizowanej~($x=1$). 

\end{enumerate}

\subsection{Przepływ danych przez akcelerator}
Zgrubne i bardziej szczegółowe opisanie funkcjonalności poszczególnych bloczków
\subsubsection{Optymalizacje czasu i powierzchni za pomocą dyrektyw}
DATAFLOW, ATAN2, ACOS

\subsection{Ograniczenia}
Brak MC, ograniczona ilość obiektów i świateł, brak obsługi przezroczystości, obrazy LDR, brak swobodnej orientacji (z uwagi na ograniczenia technologiczne)

\section{Implementacja w układzie}
\subsection{Przepływ danych}
\subsubsection{MicroBlaze}
\subsubsection{ADV7511}
Jaki max zegar udało się uzyskać???

\section{Oprogramowanie mikrokontrolera}
Inicjalizacja, obsługa kontrolera animacji, prezentacja przykładowej sceny i wydajności.
\section{WPADKI}
Małe zmiany w kodzie - ogromne w układzie: brak determinizmu i wynikające z tego problemy w poszukiwaniu optymalnych rozwiązań.
\begin{itemize}
\item Użycie Kintexa U+ podyktowane było nowocześniejszą technologią. VC707 posiada więcej elementów logicznych jednak starsza technologia wykonania nie pozwoliła zaimplementować symulacji odbić i cieni pierwszego rzędu. Z drugiej strony płytka z VC707 posiada pełne wyprowadzenie do ADV7511 i nie wymagane były specjalne dodatkowe zabiegi związane z kodowaniem koloru - artefaktów koloru nie było.
\item Nawet najmniejsza zmiana w kodzie może mieć wpływ na spełnienie wymagań czasowych podczas implementacji. Błąd znaleziony w obliczeniach współczynników Fresnela dla materiałów przewodzących, którego załatanie w C sprowadzało się do zmiany miejsca obliczania kwadratów amplitudowych współczynników odbicia w przypadku dielektryków, zmusiło do zmniejszenia zegara układu z 335MHz do 320MHz
\item Pomimo, iż w praktyce korzystniej byłoby dokonanie takiej implementacji, która pomija DATAFLOW i buforowanie wierszy pikseli tzn. użyty byłby potok PIPELINE(specjalny przełącznik w pliku konfiguracyjnym typedefs.h) i piksele zapisywane byłyby w każdej iteracji, bezpośrednio na zewnętrznej pętli renderowania to na etapie implementacji okazało się również, że jest to rozwiązanie nieimplementowalne przynajmniej z takim samym zegarem niż rozwiązanie buforowane przez co nie ma zysku netto czasu wykonania
\item Chociaż model Oren-Nayar oświetlenia powierzchni wydaje się stosunkowo prosty (porównywalny z Torrance-Sparrow) w implementacji w kodzie C sprawia on, że rozwiązanie staje się nieimplementowalne nawet po znacznym obniżeniu taktowania zegara. Użycie zasobów jest większe (w szczególności LUT wzrasta o 2\% dla Kintexa) niż zwykły model Lamberta jednak przeprowadzono zabiegi mające na celu redukcję rozmiaru układu jako całości poprzez zmniejszenie precyzji obliczeń w niekrytycznych miejscach układu (np. w module teksturującym) co przełożyło się na ok. 8\% zmniejszenie zapotrzebowania na LUT. W tym celu wykorzystano typ zmiennoprzecinkowy połówkowej precyzji (half). Implementacja wykazała, że zabieg ten nie wpłynął pozytywnie na implementowalność zatem należy sądzić, że Vivado napotyka trudności w implementacji nie z powodu rozmiaru całego układu a wskutek operacji wykonywanych w celu obliczenia współczynnika rozproszenia w modelu Oren-Nayar (przy obliczeniach ON wykorzystywano w głównej mierze typ połówkowy)

\end{itemize}