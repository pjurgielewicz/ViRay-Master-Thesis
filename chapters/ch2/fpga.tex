\chapter{Układy programowalne}
Kiedy w 1985 roku, dzięki szybko rozwijającej się litografii, wprowadzono pierwszy komercyjnie dostępny układ typu FPGA~(ang. \textit{Field Programmable Gate Array}) - układ XC2064 - bardzo szybko doceniono jego zalety wszędzie tam, gdzie wymagana jest łatwa zmiana funkcjonalności systemu przetwarzania danych. Głównym motorem rozwoju, szczególnie na początku, było powstanie i gwałtowna ekspansja Internetu i konieczność łatwego prototypowania oraz wdrażania nowych rozwiązań zwłaszcza jeśli chodzi o tworzenie przełączników i ruterów~\cite{Designing_with_Xilinx}.

Tak duże zainteresowanie tymi układami bierze się z faktu, iż są one w łatwy sposób rekonfigurowalne, a przez to mogą realizować dowolne funkcje logiczne. W przeciwieństwie do ogólnodostępnych układów typu CPU~(ang. \textit{Central Processing Unit}), których działanie opiera się na sekwencyjnym przetwarzaniu listy rozkazów w obrębie przewidzianej przez producenta \textit{architektury instrukcji}~(ang.~\textit{Instruction Set Architecture}, ISA)~\cite{INTEL_ISA} układy FPGA są konfigurowalne na poziomie sprzętowym a nie programowane. Zakupiony od producenta procesor po podaniu mu danych oraz listy instrukcji~(programu) będzie je przetwarzał i na wyjściu otrzyma się oczekiwaną wartość. Układ FPGA nie zrealizuje żadnej operacji mimo podania konkretnych danych wejściowych, jeśli nie zostanie skonfigurowany\footnote{Rozróżnienie pomiędzy konfiguracją a programowaniem powinno wybrzmieć dostatecznie mocno. Na dalszych kartach tej pracy terminy te będą używane zamiennie w kontekście układów FPGA, co jest podyktowane technologią użytą do wykonania projektu magisterskiego.}.

Na konfigurowalność układów FPGA składają się wspólnie dwa czynniki - obecność \textit{bloków logicznych}~(ang.~\textit{logic blocks}) oraz elastycznej~(tzn. konfigurowalnej) sieci połączeń między nimi~(ang. \textit{routing}) zdolnej teoretycznie wytworzyć połączenie pomiędzy dowolnymi blokami.
\addimage{chapters/ch2/img/fpgaBigPicture.png}{scale=0.4}{Schemat ideowy budowy układu FPGA. Bloki logiczne (LB) połączone są między sobą oraz z blokami wejścia-wyjścia~(IOB) za pomocą gęstej sieci konfigurowalnych połączeń. Bloki wejścia-wyjścia służą do ustanowienia komunikacji z urządzeniami peryferyjnymi takimi jak moduł pamięci RAM czy klawiatura}{Schemat ideowy budowy układu FPGA}{ch2:img:fpgaBigPicture}
Każdy blok logiczny składa się minimalnie z trzech elementów:
\begin{itemize}
\item n-wejściowej konfigurowalnej \textit{tablicy przeglądowej}~(ang. \textit{LookUp Table}, LUT), której zadaniem jest realizacja n-parametrowej funkcji logicznej np. $(\bar{A}\vee B) \wedge C$ jest 3-parametrową funkcją logiczną,
\item \textit{przerzutnika}~(ang. \textit{flip-flop}, FF) działającego jako pamięć,
\item \textit{multipleksera}~(ang. \textit{multiplexer}, MUX/MX), który dokonuje wyboru źródła sygnału, który ma zostać przekazany na wyjście bloku logicznego.
\end{itemize}
\addimage{chapters/ch2/img/fpgaLB}{scale=0.35}{Budowa podstawowego bloku logicznego w układzie FPGA. 4-wejściowy LUT realizuje ustaloną funkcję logiczną, której wynik, zależny od kombinacji sygnałów (I[0]:I[3]), przekazywany jest do przerzutnika (FF) w celu zapamiętania. Przerzutnik działa synchronicznie z doprowadzonym sygnałem zegarowym~(CLK) a jego zawartość może być zresetowana~(RST). O tym, jaka wartość~(O) zostanie podana na wyjściu bloku logicznego decyduje parametr~(S) sterujący wyborem multipleksera~(MX) pomiędzy nowym a zapamiętanym uprzednio wynikiem działania.}{Budowa podstawowego bloku logicznego w układzie FGPA}{ch2:img:fpgaLB}
Pojedynczy blok logiczny sam w sobie jest dość prymitywnym elementem i samodzielnie nie jest w stanie realizować funkcji, której liczba parametrów wejściowych przekracza ilość wejść do LUT. Jednak dzięki występującej sieci połączeń\footnote{W literaturze często wspomina się o blokach logicznych zanurzonych w morzu połączeń.} wyjście jednego bloku logicznego może stanowić wejście drugiego. W ten sposób tworzone są znacznie bardziej rozbudowane funkcje logiczne. Wynika też z tego, że im więcej i im bardziej rozbudowane są bloki logiczne tym możliwości w zakresie komponowania funkcjonalności są szersze~(wtedy jednak pojawiają się dodatkowe wyzwania konstruktorskie związane z optymalnym projektem sieci połączeń~\cite{FPGA_ARCHITECTURE}).
\addimage{chapters/ch2/img/fpgaSizeCost.png}{scale=0.4}{Rozwój układów FPGA od momentu ich konstrukcji do dziś. Wartości podane na wykresie są liczone względem pierwotnego układu XC2064, który posiadał 64 programowalne bloki logiczne. Kwadratami oznaczono względną pojemność układu rozumianą poprzez ilość elementów logicznych, zamalowane koła osiągalne częstotliwości, ciągła gruba linia to cena, a linia z krzyżykami to pobierana moc. Widoczny jest znaczny postęp, który dokonał się na przestrzeni ostatnich lat~\cite{Designing_with_Xilinx}}{Rozwój układów FPGA od momentu ich konstrukcji do dziś}{ch2:img:fpgaSizeCost}

Lata rozwoju układów FPGA połączone z analizą często wykorzystywanych algorytmów doprowadziły do implementacji dodatkowych elementów wchodzących w skład bloków logicznych. Są to jednostki bardziej wyspecjalizowane niż LUT, których użycie sprawia, że dany typ zadania może być wykonany znacznie szybciej i/lub jest bardziej ekonomiczne pod względem wykorzystania powierzchni układu. Tak powstały m. in:
\begin{itemize}
\item pamięci o niewielkiej pojemności LUTRAM,
\item pamięci blokowe~(ang. \textit{block RAM, BRAM}), zdolne do przechowywania porcji danych rzędu 18~kb i wykonania do dwóch operacji dostępu w jednym cyklu zegara,
\item moduły DSP dedykowane szybkiemu przetwarzaniu operacji dodawania i mnożenia.
\end{itemize}
Znajomość liczby, typu elementów składających się na układ FPGA oraz wymagań stawianych na etapie projektowania algorytmów pozwala dobrać odpowiedni układ do danych zastosowań, a przez to zoptymalizować koszty, które generowane byłyby przez elementy niewykorzystane. Producenci, chcąc sprostać oczekiwaniom rynkowym dostarczają całe gamy produktów, których wielkość mierzona za pomocą ilości bloków logicznych może zaczynać się na ok. 1000 bloków a kończyć na paru milionach~\cite{XILINX_PRODUCT_TABLE}.

Elastyczność w zakresie budowania funkcji logicznych posiada jednakże pewną niedogodność związaną z maksymalnymi osiągalnymi częstotliwościami pracy układów. W części przypadków~(w tym omawianego systemu śledzenia promieni) samo przetworzenie sygnałów w bloku logicznym może trwać zaledwie 20-30\% budżetu czasowego wynikającego z okresu zadanego zegara. Pozostały czas jest czasem potrzebnym na propagację wyniku do kolejnego bloku logicznego poprzez dostępną w układzie konfigurowalną sieć połączeń. W efekcie uzyskiwane maksymalne częstotliwości zegara dla specyficznych zastosowań przetwarzania sygnałów~(ang. \textit{Digital Signal Processing, DSP}) mogą przekraczać 500~MHz\footnote{Tak wysokie częstotliwości, jak na układy FPGA są możliwe do uzyskania tylko dzięki obecności dedykowanych bloków DSP w strukturze układu FPGA.}, a w typowych zastosowaniach są to wartości pomiędzy 200 a 400 MHz~(wartości te zależą oczywiście od technologii wykonania układu FPGA, akcelerowanego algorytmu i jakości kodu). W porównaniu do obecnych dzisiaj procesorów CPU działających coraz częściej z częstotliwościami sięgającymi 4 GHz są to wartości 10- 20-krotnie niższe. Wydawać mogłoby się zatem~(tylko na podstawie porównania osiąganych częstotliwości), że nie można oczekiwać zbliżonej i wyższej wydajności od układu FPGA realizującego identyczny algorytm co odpowiadający mu procesor CPU. Nie musi być to prawdą. Zależnie od typu rozwiązywanego problemu jak i umiejętności projektanta, algorytmy mogą być wykonywane o całe rzędy wielkości szybciej niż ich odpowiedniki opisane listą rozkazów CPU przy niższym zegarze oraz niższej konsumpcji energii elektrycznej. Kluczowa jest tu świadomość, iż projektant ma bezpośredni wpływ na to, jak układ zostanie skonfigurowany. Ta dowolność nierozerwalnie wiąże się z dużą odpowiedzialnością oraz stopniem doświadczenia wymaganego od projektanta.

\section{Konfiguracja i języki opisu sprzętu}
Pierwsze wytworzone \textit{układy scalone}~(ang. \textit{integrated circuit}, IC) posiadały małą złożoność, liczoną w setkach bramek logicznych, przez to charakteryzowały się niewielkim stopniem komplikacji (w rozumieniu realizowanej funkcjonalności). W tamtych czasach odpowiedzialność za projekt i testy takiego układu leżały w gestii doświadczonego projektanta. Musiał on nie tylko w sposób ręczny wykonać projekt realizujący zadaną funkcjonalność, ale również zadbać o to, by sygnały propagujące się w układzie dochodziły do kolejnych etapów przetwarzania, wtedy gdy będą potrzebne\footnote{Prędkość propagacji sygnałów jest skończona i wynika między innymi z wykorzystywanej technologii.}. Wraz z postępem technologicznym ilość bramek logicznych, która mogła znaleźć się w pojedynczym układzie rosła, w wyniku czego pojawiła się potrzeba stworzenia narzędzi, które mogłyby wspomagać pracę na kolejnych etapach tworzenia układu elektronicznego tj.:
\begin{itemize}
\item tworzenia funkcjonalności,
\item testów, 
\item syntezy,
\item implementacji. 
\end{itemize}
W tym czasie języki programowania takie jak Pascal i C były powszechnie używane do tworzenia programów wykonywanych sekwencyjnie przez procesory zdolne do realizowania określonego zbioru instrukcji. Języki te jednakże nie mogły zostać zaadaptowane do celów opisu funkcjonalności połączonych ze sobą elementów elektronicznych (pojedynczych bramek, bloków DSP czy LUT) właśnie przez ich sekwencyjną naturę. Zintegrowane układy elektroniczne w swoim założeniu przetwarzają jednocześnie wiele sygnałów dla optymalnej efektywności. Dla przykładu, jeżeli rozwiązywany problem wymaga wykonania $n$ niezależnych od siebie operacji dodawania, najefektywniej jest zaprojektować układ tak, by na tym etapie przetwarzania znajdowało się $n$ niezależnych od siebie sumatorów. Potrzeba kreowania tego typu zachowań w układach elektronicznych doprowadziła do powstania \textit{języków opisu sprzętu}~(ang. \textit{Hardware Description Languages}, HDL). Pozwoliły one nie tylko na modelowanie funkcjonalności układów elektronicznych, ale również na przeprowadzanie wnikliwych testów poprawności wykonania zgodnie z założeniami projektowymi dzięki środowiskom symulacyjnym. Języki te, najpopularniejsze wśród nich to Verilog oraz VHDL, zaoferowały możliwość opisu układów cyfrowych na poziomie przepływu danych pomiędzy kolejnymi rejestrami~(ang. \textit{register transfer level}, RTL). Odrębne narzędzia zaś na podstawie tego opisu~(RTL) mogą dokonać ekstrakcji wymaganych elementów logicznych i połączeń między nimi~\cite{VERILOG_BIBLE}. W zależności od tego, jakiego typu układ jest projektowany: czy jest to \textit{wyspecjalizowany układ scalony}~(ang. \textit{application-specific integrated circuit}, ASIC) czy układ FPGA, zespół wyekstrahowanych elementów logicznych i połączeń między nimi tzw. \textit{netlista}~(ang. \textit{netlist}) na etapie syntezy będzie inny, ale funkcjonalność zostanie zachowana. Właśnie ta cecha jest często eksploatowana przy tworzeniu układów typu ASIC, gdzie etapem pośrednim jest implementacja funkcjonalności w układzie FPGA, co pozwala przetestować w realnych zastosowaniach nowo tworzony układ, zanim ten zostanie wysłany do~(kosztownej) produkcji w finalne postaci{\color{red}CYTOWANIE}. 

Implementacja w układzie FPGA jest zautomatyzowanym procesem zaczynającym się od optymalizacji wygenerowanej netlisty, po to aby ta zajmowała jak najmniej bloków logicznych. Ma to na celu zmniejszenie opóźnień związanych z propagacją danych, dzięki czemu możliwe jest użycie wyższych częstotliwości zegarów. Następnie bloki te łączone są ze sobą w klastry w fizycznym układzie w taki sposób, by uzyskać ich optymalny rozkład w przestrzeni układu~(unikając tzw. \textit{stłoczenia}~ ang. \textit{congestion}, czyli lokalnego przeciążenia sieci połączeń) z zachowaniem jak najkrótszych odległości między nimi. 

Naturalnym problemem, który tutaj występuje jest pytanie o to czy rezultaty uzyskane na drodze syntezy i implementacji są najlepsze z możliwych dla danego układu FPGA i opisu za pomocą RTL. W istocie dla dzisiejszych układów, których ilość bloków logicznych przekracza milion, a ilość dostępnych połączeń w sieci jest dziesięciokrotnie wyższa rozpatrzenie wszelkich możliwych kombinacji jest niemożliwe~\cite{FPGA_SD}. W związku z tym narzędzia muszą posługiwać się przybliżonymi algorytmami heurystycznymi sterowanymi za pomocą dziesiątek parametrów a i tak czas oczekiwania na finalny plik konfiguracyjny tzw. \textit{bitstream} może przekroczyć 24 godziny~(w zależności od stopnia skomplikowania RTL). Co więcej nie ma gwarancji, że narzędzie znajdzie rozwiązanie, które spełnia wymagania czasowe dotyczące transferu sygnałów pomiędzy kolejnymi blokami - bez tego układ na pewno nie będzie działał poprawnie\footnote{Narzędzia dokonujące wyliczeń opóźnień między blokami z natury są konserwatywne, czyli ich estymacje wynikają z symulacji najgorszego możliwego przypadku. Znane są jednak przypadki, gdy narzędzia te raportowały pozytywne przejście testów opóźnień, jednak pracujące urządzenie po pewnym czasie zaczynało pracować w sposób nieprzewidywalny. Błędy te najprawdopodobniej związane są ze zwiększonym szumem termicznym występującym w pracującym układzie. }. Na dodatek wpływ dwóch dowolnych parametrów sterujących syntezą i implementacją nie musi być od siebie niezależny. Dlatego producenci tych narzędzi dostarczają przeważnie zestawy predefiniowanych ustawień, które według ich zapewnień powinny działać najbardziej optymalnie. Ustawienia te można podzielić na dwie główne i z założenia wykluczające się grupy: optymalizujące projekt pod względem osiąganych częstotliwości zegara oraz ilości użytych bloków logicznych. Jednak każdy projekt, a zwłaszcza te o dużym stopniu utylizacji zasobów układu, należy traktować indywidualnie. Samodzielne poszukiwanie optymalnych parametrów przy ustalonym RTL, gdy predefiniowane ustawienia nie dają oczekiwanych rezultatów wymaga nie tylko doświadczenia, ale również szczęścia. InTime, czyli komercyjne narzędzie dostępne na rynku i rozwijane od kilku lat, pozwala poprzez użycie technik uczenia maszynowego rozwiązać większość tych problemów. Jest ono tak zaprojektowane, iż jest w stanie dokonać predykcji optymalnych parametrów syntezy i implementacji każdego projektu dla narzędzi dostarczanych przez najważniejszych producentów układów FPGA~\cite{InTime1}\cite{InTime2}\cite{InTime3}. 

Z drugiej zaś strony, istnieje możliwość, iż stworzony opis sprzętu jest nieoptymalny dla danej architektury układu FPGA. Konieczne mogą okazać się znaczne zmiany projektowe po to, aby zmniejszyć konsumpcję zasobów~(elementów składowych bloków logicznych) i/lub móc osiągnąć wymaganą częstotliwość zegara. 

W związku z tym projektowanie funkcjonalności realizowanej dzięki układom FPGA jawi się jako proces o dużym stopniu komplikacji, gdzie nawet najmniejsza zmiana na którymkolwiek etapie może wpływać na jakość rezultatu końcowego~(ang. \textit{Quality of Results}, QoR) tj. wydajność i zużycie zasobów. To czy dana implementacja jest satysfakcjonująca zależy zaś od postawionych lub narzuconych z zewnątrz wymagań. 

\section{Nowoczesne podejście do tworzenia funkcjonalnych układów elektronicznych}
W poprzednim podrozdziale wspomniano o językach opisu sprzętu, jako o narzędziu służącym do projektowania zachowania układów elektronicznych, które z natury rzeczy przetwarzają współbieżnie porcje danych. Języki te współistniały i były rozwijane równolegle z językami sekwencyjnymi służącymi do programowania procesorów, jednak z uwagi na powszechniejszy dostęp do układów typu CPU~(ang. \textit{Central Processing Unit}) znacznie bardziej rozpowszechnione zostały języki takie jak FORTRAN czy C, pozostawiając znajomość Verilog, VHDL i ich pochodne tylko dla wąskiego grona posługujących się nimi specjalistów.

W społeczności akademickiej oraz u producentów układów FPGA zrodziło się pytanie czy można udostępnić szerokiemu gronu odbiorców język, którego składnia nie odbiegałaby w znaczący sposób od znanych języków sekwencyjnych a pozwalający na przetwarzanie masowo równoległe~(ang. \textit{massively parallel}) podobnie, jak robią to HDL. Narzędzie dokonujące translacji kodu podobnego do C do jego ekwiwalentu w HDL, pozwoliłoby dotrzeć producentom układów FPGA do nowych odbiorców w znacznie prostszy sposób, a przez to zwiększyć swój zasięg i zyski. Mimo że próby stworzenia możliwie uniwersalnego narzędzia tego typu trwają już ponad 25 lat~\cite{C_VHDL}, dopiero niedawno stały się one wystarczająco użyteczne w realizacji postawionego im celu. 

\subsection{Synteza wysokiego poziomu}
Proces konwersji algorytmu~(rozumianego jako ciąg operacji koniecznych do wykonania w celu otrzymania żądanego wyniku na podstawie dostarczonych danych) opisanego w języku wysokiego poziomu do jego specyfikacji na poziomie RTL nazywany jest \textit{syntezą wysokiego poziomu}~(ang. \textit{high level synthesis}, HLS). Dokonuje ona analizy, kiedy żądane operacje mają być wykonane i wybiera odpowiednie bloki znajdujące się w układzie~(pamięć, moduły DSP, przerzutniki, LUT i inne), które te operacje będą wykonywać~(rysunek~\ref{ch2:img:HLS_schedule}). 
\addimage{chapters/ch2/img/HLS_schedule.png}{scale=0.30}{Przykład optymalizacji wykonania iloczynu skalarnego $\sum_{i = 0}^3 a_ib_i$ za pomocą HLS. Iloczyn skalarny 4-elementowych wektorów wymaga wykonania 4 operacji mnożenia i 3 dodawania przy czym część operacji może zostać wykonana współbieżnie. W pierwszym kroku HLS dokona alokacji 4 operatorów mnożenia~(I), następnie wykonane zostaną 2 sumy cząstkowe~(II) oraz suma końcowa~(III). Takie rozłożenie wykonania operacji w czasie zapewnia maksymalną wydajność, co wiąże się również z największym zużyciem zasobów znajdujących się w układzie. Narzędzia HLS umożliwiają również takie rozłożenie operacji w czasie, by kosztem zmniejszonej wydajności oszczędzić część zasobów logicznych}{Przykład optymalizacji wykonania iloczynu skalarnego za pomocą HLS}{ch2:img:HLS_schedule}
Wynikowy projekt zapisany w postaci RTL opisuje dla każdego kroku przepływ danych pomiędzy rejestrami, który realizuje funkcjonalność opisaną w prosty i zrozumiały sposób za pomocą języka wysokiego poziomu. Projektant/programista za cenę utraty kontroli nad formą RTL zdaje się w momencie konwersji na ciąg automatycznych procesów przewidzianych przez twórcę danego HLS\footnote{Szczegółowy opis tego, w jaki sposób dokonywana jest analiza algorytmu i jego konwersja do reprezentacji w postaci RTL można znaleźć w rozdziale 2~\cite{FPGA_SD}.}. W większości przypadków jednak samo wykrywanie operacji niezależnych, mogących być wykonanych jednocześnie w układzie jest niewystarczające, by wykorzystać pełen potencjał, jaki dają układy FPGA. Dlatego każdy HLS posiada w swojej składni pewien zestaw poleceń stanowiących wskazówkę dla procesu syntezy, w jaki sposób należy poddać konwersji daną partię kodu dla uzyskania optymalnych w danych warunkach rezultatów.

\section{Xilinx i Vivado HLS}
Kluczem do stworzenia narzędzia HLS, które stanie się chętnie wykorzystywane przez projektantów układów elektronicznych jest spełnienie dwóch warunków:
\begin{enumerate}
\item Bazowanie na dobrze znanym języku programowania jak np. C, tak aby wprowadzić jak najmniejszą ilość restrykcji w jego składni, które mogłyby stanowić ograniczenia w zakresie tworzenia funkcjonalności.
\item Dostarczenie odpowiednich rozszerzeń do języka bazowego, które udostępniałyby dostęp do optymalizacji wynikających wprost z możliwości używanego sprzętu.
\end{enumerate}
Narzędziem, które spełnia oba te założenia jest rozwijany przez firmę Xilinx (twórców pierwszego układu FPGA XC2064) Vivado HLS wchodzący w skład pakietu do tworzenia funkcjonalności w oparciu o układy FPGA tego producenta: Vivado Design Suite{\color{red}CYTOWANIE}. Vivado HLS na podstawie kodu C/C++\footnote{Możliwe jest również wykorzystanie SystemC oraz OpenCL~(Open Computing Language).} oraz informacji o żądanych przez użytkownika optymalizacjach, mających głównie na celu zwiększenie wydajności przetwarzania danych przez algorytm, dokonuje syntezy projektu do jego reprezentacji w VHDL i Verilog. Końcowym produktem syntezy jest \textit{moduł IP}~(ang. \textit{Intellectual Property core}), który może stać się częścią systemu przetwarzania danych za pomocą układu FPGA firmy Xilinx.

\subsection{Podstawowe informacje związane z Vivado HLS}
Firma Xilinx udostępniając użytkownikom swoich rozwiązań technologicznych Vivado HLS ułatwiła pracę projektantów/programistów. Tworzenie algorytmu za pomocą języka C/C++ jest nie tylko łatwiejsze niż tworzenie opisu RTL, ale również powstający kod jest w zamierzeniu znacznie bardziej czytelny. Co więcej, testowanie przygotowywanych algorytmów odbywa się również w środowisku C/C++, a co za tym idzie można wykorzystywać tradycyjne narzędzia do sprawdzania funkcjonalnej poprawności~(\textit{debugowania}) algorytmów na dowolnym etapie. Na dodatek Vivado HLS bierze pod uwagę, dla jakiego konkretnego układu FPGA firmy Xilinx przeprowadzana jest synteza oraz przy jakiej częstotliwości pracy. Dzięki temu narzędzie to na podstawie znanej mu szybkości wykonywania operacji dla danego FPGA dokonuje oceny, które operacje mogą zostać wykonane w tym samym cyklu zegara, a które muszą zostać rozłożone na kilka takich cykli - bardziej zaawansowane technologicznie układy będą w stanie wykonać dany algorytm szybciej i/lub z użyciem mniejszej liczby zasobów sprzętowych\footnote{Oczywistą ceną za dostęp do tego typu optymalizacji jest ograniczenie stosowalności Vivado HLS tylko do układów wyprodukowanych przez firmę Xilinx.}.

Atrakcyjność rozwiązania jakim jest Vivado HLS polega głównie na tym, że na pierwszy rzut oka jego składnia niewiele różni się od tej znanej z języków C/C++. Należy stworzyć funkcję główną, która zazwyczaj będzie przyjmować pewien zbiór argumentów oraz zwracać wyniki na zewnątrz modułu~(argumenty te na drodze syntezy staną się portami wejścia/wyjścia tworzonego IP). Funkcja główna będzie realizować pewien algorytm wykorzystując odpowiednie konstrukcje wynikające ze składni języka bazowego i może się odwoływać do innych funkcji pomocniczych. W rzeczywistości Vivado HLS implementuje dużą część standardowych konstrukcji języków C/C++ oraz typów danych, jednak istnieją pewne ograniczenia, wśród których najważniejsze to\footnote{Spisane tutaj ograniczenia mają zastosowanie tylko i wyłącznie do ciała funkcji głównej i wszystkich funkcji wywoływanych przez nią, która zostaje poddana syntezie do RTL. W środowisku testowym ograniczenia te nie występują. }{\color{red}ODNOSNIKI}:
\begin{itemize}
\item Brak wsparcia dla dynamicznego zarządzania pamięcią (polecenia \texttt{new/delete} oraz \texttt{malloc()/free()}), wynikający wprost z faktu, iż układ FPGA dysponuje ustalonymi zasobami sprzętowymi. Użycie tych zasobów musi być konkretne i znane na etapie implementacji funkcjonalności w układzie, by móc dokonać odpowiednich połączeń pomiędzy kolejnymi elementami logicznymi. O ile w przypadku tablic danych wystarczające może się okazać przyjęcie takiego rozmiaru by w danym momencie mieściły się w niej wszystkie potrzebne wartości, o tyle programiści przyzwyczajeni do \textit{programowania zorientowanego obiektowo}~(ang. \textit{object-oriented programming}) szybko natkną się na problemy z uwagi na:
\begin{itemize}
\item brak obsługi generycznych typów danych~(C++ STL) takich jak: \texttt{vector}, \texttt{map} czy \texttt{queue},
\item ograniczone wsparcie dla polimorfizmu, które jest dopuszczalne tylko jeśli typy danych można określić w sposób statyczny (na etapie kompilacji),
\item niepełną obsługę funkcjonalności związaną z użyciem wskaźników, w szczególności możliwe jest tylko rzutowanie wskaźników pomiędzy natywnymi typami języka bazowego.
\end{itemize}
\item Niedopuszczalne jest aby IP dokonywało odwołań do jakichkolwiek funkcji systemowych. Funkcjonalność realizowana poprzez stworzone IP jest sterowana tylko poprzez dane, które jest on w stanie odczytać z portów wejścia i nie posiada ono wiedzy na temat niczego innego~(włączając w to inne IP, które mogą działać równolegle z nim na tym samym układzie FPGA). Stąd też np. użycie funkcji \texttt{time()} przez IP jest niedopuszczalne, można jednak stworzyć port wejściowy, przez który będzie przekazywana odpowiednia wartość z zewnątrz. 
\item Niemożliwe jest stosowanie funkcji rekurencyjnych~(tzn. odwołujących się same do siebie) wprost\footnote{Omawiany problem implementacji śledzenia promieni z użyciem ukaładu FPGA z natury rzeczy jest problemem rekurencyjnym, gdzie promienie padające na powierzchnię obiektu dzielą się na promienie odbite i załamane.}. W miarę możliwości należy dążyć do przekształcenia algorytmu w taki sposób, aby dało się go opisać za pomocą pętli. Alternatywnie można podjąć się emulacji tego, w jaki sposób CPU radzi sobie z przetwarzaniem rekurencyjnym z użyciem stosu~\cite{HLS_RECURSIVE}.
\end{itemize} 
Powyższe ograniczenia, a zwłaszcza te dotyczące zarządzania pamięcią oraz przetwarzania rekurencyjnego, w wielu przypadkach prowadzić będą do stworzenia od podstaw istniejących już algorytmów tradycyjnie wykonywanych przez CPU. Przy tego typu konwersji należy również przemyśleć możliwości wykorzystania potencjału przetwarzania równoległego, który może zapewnić sprzęt.

Z drugiej jednak strony producent Vivado HLS dostarcza zbiór bibliotek, które są zoptymalizowane pod kątem czasu wykonania i implementacji w układach FPGA. Ma to szczególne znaczenie w przypadku odwoływania się do funkcji zawartych w bibliotekach matematycznych, gdzie udostępnione są nie tylko implementacje podstawowych funkcji takich jak np. \texttt{sin()}, \texttt{sqrt()}, ale również bardziej zaawansowanych jak \texttt{fft()}~(szybka transformata Fouriera). 

Użycie układów FPGA sprawia również, że programista ma dowolność w doborze i wykorzystaniu typów danych. Oprócz tradycyjnych typów jak \texttt{int}, \texttt{char}, \texttt{float} czy \texttt{double}, przechowujących standardowo 32, 8, 32 i 64 bity może on skorzystać z typów danych o dowolnej długości dla typów całkowitoliczbowych i stałopozycyjnych, jeśli tylko uzna, że takie postępowanie będzie uzasadnione - operacje arytmetyczne na mniejszych typach danych będą zwykle przeprowadzane szybciej a wykorzystanie bloków logicznych układu będzie niższe. Stałopozycyjne typy liczbowe zdefiniowane są poprzez:
\begin{itemize}
\item całkowitą ilość bitów, jaką zajmować będzie zmienna,
\item ilość bitów przypadającą na opis całkowitej części zmiennej z uwzględnieniem bitu znaku,
\item zachowanie określające sposób, w jaki dokonywane będzie zaokrąglanie,
\item zachowanie w przypadku przepełnienia (czyli co się stanie, gdy wynik działania arytmetycznego nie daje się zapisać przy pomocy zadanej liczby bitów).
\end{itemize}
Typy całkowitoliczbowe o dowolnej precyzji opisane są tylko poprzez ich długość bitową wyrażoną dodatnią liczbą całkowitą. Oba rodzaje typów liczbowych o zadanej precyzji występują w wersji z i bez znaku.

W obliczu operowania typami stałopozycyjnymi o dowolnej długości dużą niedogodnością jest fakt, iż jak dotąd (stan na wersję Vivado Design Suite 2018.1) nie zostały udostępnione użytkownikom Vivado HLS zmiennoprzecinkowe typy o dowolnej precyzji, mimo iż narzędzie \texttt{System Generator}~(również wchodzące w skład Vivado Design Suite) będące rozszerzeniem do środowiska \texttt{Simulink} oferuje taką funkcjonalność pozwalając dostosować według potrzeb ilość bitów danych przypadających na eksponentę oraz mantysę~\cite{Designing_with_Xilinx}\footnote{Jak się okaże własność ta będzie miała wpływ na końcowy projekt systemu śledzenia promieni.}. W ręce programistów Vivado HLS zostały oddane jedynie zmiennoprzecinkowe typy zgodne ze standardem IEEE-754~\cite{IEEE_754}:
\begin{itemize}
\item \texttt{half}: 1 bit znaku, 5 bitów eksponenty oraz 10 bitów mantysy,
\item \texttt{float}: 1 bit znaku, 8 bitów eksponenty oraz 23 bity mantysy,
\item \texttt{double}: 1 bit znaku, 11 bitów eksponenty oraz 52 bity mantysy.
\end{itemize}

Jeśli tylko stworzony moduł jest zgodny z obowiązującą składnią HLS, narzędzie dokonuje optymalnej implementacji dla ustalonego układu FPGA z uwzględnieniem optymalizacji zadanych przez użytkownika. Optymalizacje te, zwane w HLS \textit{dyrektywami}~(ang. \textit{optimization directives}), pozwalają na modyfikację, a przez to kontrolę nad domyślnym sposobem syntezy poszczególnych partii algorytmu jak i portów wejścia/wyjścia. Wpływ wymuszenia danej dyrektywy na odpowiednie \textit{metryki} można sprawdzić analizując informacje zawarte w wygenerowanym raporcie syntezy.
\begin{itemize}
\item Wykorzystanie zasobów~(ang. \textit{area}) to konserwatywne, czyli w najgorszym możliwym przypadku, zestawienie użycia zasobów sprzętowych (przerzutniki, LUT, BRAM, moduły DSP) koniecznych do realizacji zadanej w module funkcjonalności\footnote{Na etapie syntezy netlisty oraz implementacji w układzie dokonywana jest seria optymalizacji, mająca na celu m. in. zmniejszenie wykorzystania zasobów.}. 
\item Opóźnienie~(ang. \textit{latency}), czyli ilość cykli zegara wymaganych do przeprowadzenia wszystkich obliczeń. W przypadku pętli jest to ilość cykli zegara, aby przetworzyć wszystkie jej iteracje.
\item Opóźnienie iteracji pętli~(ang. \textit{loop iteration latency}) to ilość cykli zegara do ukończenia jednej iteracji pętli.
\item Interwał~(ang. \textit{initiation interval}, II) wyraża ilość cykli zegara, jaka upłynie zanim:
\begin{itemize}
\item funkcja będzie mogła przetworzyć kolejną porcję danych,
\item pętla będzie mogła przetworzyć dane w kolejnej iteracji.
\end{itemize} 
\end{itemize}
Przemyślany zapis algorytmiczny rozwiązywanego problemu w połączeniu z kombinacją odpowiednich dyrektyw i analizą raportów syntezy pozwala stworzyć moduł IP o optymalnych metrykach, które uzasadniałyby wykorzystanie układu FPGA i jednocześnie, na podstawie użycia zasobów, wskazywałyby na możliwość implementacji w układzie. Należy jednak podkreślić, że Vivado HLS jedynie dokonuje transformacji algorytmu do jego reprezentacji poprzez RTL i przez to nie daje gwarancji, że proces implementacji (przeprowadzany przez odrębne narzędzie) zakończy się sukcesem tj. wygenerowaniem pliku konfiguracyjnego działającego układu.

\subsection{Wykorzystanie dyrektyw}
Dyrektywy w Vivado HLS zmieniające domyślne parametry syntezy mają zastosowanie do:
\begin{itemize}
\item portów wejścia/wyjścia z głównej funkcji modułu,
\item funkcji,
\item pętli,
\item regionów, czyli porcji kodu zawartej pomiędzy parą odpowiadających sobie nawiasów klamrowych,
\item tablic
\end{itemize}
i mogą zostać zapisane bezpośrednio w kodzie programu w postaci:
\begin{lstlisting}
#pragma HLS <DYREKTYWA> <PARAMETRY_DYREKTYWY>
\end{lstlisting}
jak i w oddzielnym pliku \texttt{directives.tcl}. Nie ma przy tym znaczenia z punktu widzenia syntezy, który sposób definiowania dyrektyw zostanie przyjęty przez programistę~(można nawet mieszać ze sobą oba sposoby). Należy tylko mieć na uwadze, że dyrektywy zapisane w kodzie mogą sprawiać problemy~(tzn. niepożądane optymalizacje), gdy dany kod jest współużytkowany przez kilka osób i w różnych projektach.

\begin{itemize}
\item \texttt{INTERFACE}

Projekty opisywane poprzez HDL, w celu wykonywania operacji wejścia/wyjścia, wymagają posiadania tzw. portów, które działają zazwyczaj w oparciu o pewien protokół transmisji danych, który można zdefiniować używając dyrektywy \texttt{INTERFACE}. W zależności od typu danych~(pojedyncza wartość, tablica, wskaźnik) oraz sposobu dostępu~(wejście, wyjście, wejście/wyjście) Vivado HLS udostępnia odpowiednie protokoły transmisji. Ich dokładna dyskusja znajduje się w~\cite{UG902} w rozdziale \textit{Managing Interfaces} tutaj wspomniane zostaną dwa z nich.
\begin{itemize}
\item \texttt{AXI4-Lite} jest interfejsem, który pozwala na to, aby moduł mógł być kontrolowany poprzez CPU lub mikrokontroler. Dzięki niemu jeden interfejs może zostać wykorzystany do połączenia w grupę kilku portów~(mogą to być wartości, wskaźniki, tablice), które mogą w następstwie syntezy być kontrolowane przy pomocy stworzonego sterownika~(ang. \textit{C driver}). 
\begin{lstlisting}[caption=Przykład użycia interfejsu AXI4-Lite]
int fun(int* a, int* b)
{
	#pragma HLS INTERFACE s_axilite port=return bundle=BUS_A
	#pragma HLS INTERFACE s_axilite port=a 		bundle=BUS_A
	#pragma HLS INTERFACE s_axilite port=b 		bundle=BUS_A
	return *a + *b;
}
\end{lstlisting}
W powyższym przykładzie wartości wskazywane \texttt{a}, \texttt{b} oraz wartość zwracana są obsługiwane przez ten sam interfejs AXI4-Lite o nazwie \texttt{BUS\_A}. Wygenerowany sterownik pozwoli przy pomocy odrębnego mikrokontrolera m. in. na:
\begin{itemize}
\item inicjalizację modułu,
\item dostarczenie informacji dla IP, gdzie w przestrzeni adresowej znajdują się wartości, na które wskazują \texttt{a} i \texttt{b},
\item uruchomienie modułu i sprawdzenie czy ten zakończył swoje działanie,
\item odczyt wyniku działania stworzonego IP.
\end{itemize}
\item \texttt{AXI4 Master}

Interfejs tego typu może zostać przypisany do portów będących tablicami i wskaźnikami, a jego cechą jest to, że pozwala dokonywać indywidualnych jak i seryjnych~(ang. \textit{burst}) transferów danych. W tym drugim przypadku wydajność transferu danych jest znacznie wyższa z uwagi na sekwencyjny odczyt/zapis względem zadanego adresu początkowego.
\begin{lstlisting}[caption=Przykład użycia interfejsu AXI4 Master z seryjnym dostępem do danych. Zmiana adresów wskazywanych umożliwiona została poprzez interfejs AXI4-Lite]
void fun(int* a, int* b)
{
	#pragma HLS INTERFACE s_axilite port=return bundle=BUS_A
	#pragma HLS INTERFACE m_axi port=a 		bundle=MAXI_DATA
	#pragma HLS INTERFACE m_axi port=b 		bundle=MAXI_DATA

	#pragma HLS INTERFACE s_axilite port=a 		bundle=BUS_A
	#pragma HLS INTERFACE s_axilite port=b 		bundle=BUS_A

	const unsigned n = 100;
	int loc_a[n];

	// Wykonaj kopie danych z uzyciem dostepu seryjnego
	// SPOSOB 1
	memcpy(loc_a, a, n * sizeof(int));

	Obliczenia: for (int i = 0; i < n - 1; ++i)
	{
		loc_a[i] = loc_a[i] * loc_a[i + 1];
//		loc_a[i] = a[i] * a[i + 1];
	}

	// Zapisz nowe dane do b (rowniez seryjnie)
	// SPOSOB 2
	Zapis: for (int i = 0; i < n; ++i)
	{
	#pragma HLS PIPELINE
		b[i] = loc_a[i];
	}
}
\end{lstlisting}
W powyższym przykładzie portom \texttt{a} i \texttt{b} nakazano zachowanie zgodne z protokołem AXI4 Master oraz poprzez interfejs AXI4-Lite umożliwiono sterowanie nimi z poziomu zewnętrznego mikrokontrolera. Najpierw do tablicy \texttt{loc\_a} przepisana zostaje zawartość \texttt{n=50} kolejnych wartości wskazywanych przez \texttt{a} za pomocą funkcji \texttt{memcpy()}~(i tylko w takim kontekście Vivado HLS umożliwia jej użycie). Następnie dokonywane są pewne operacje na tych wartościach, by następnie zostać przepisane pod adres wskazywany przez \texttt{b}. Co ważne, również operacja zapisu wykonywana jest w trybie seryjnym - bez użycia \texttt{memcpy()} - za to jako pętla z nadaną dyrektywą \texttt{PIPELINE}, gdzie dostęp do adresów następuje bezwarunkowo~(dostęp do pamięci nie jest poprzedzony warunkiem logicznym) w kolejności rosnącej.

Opóźnienie takiego kodu, jak w powyższym przykładzie obliczone przez Vivado HLS 2017.4 dla układu KCU116 wynosi 416 cykli (ze standardowym zegarem 100 MHz). Wystarczy jednak pominąć instrukcję transferu danych do \texttt{loc\_a} i bezpośrednio w pętli \texttt{Obliczenia} odwoływać się do zawartości \texttt{a} aby dostęp do danych przestał być sekwencyjny a opóźnienie wzrosło do 1197 cykli zegara. 
\end{itemize}

\item \texttt{PIPELINE}

Jest to podstawowa optymalizacja mająca zastosowanie do funkcji i pętli umożliwiająca naturalną eksplorację równoległego przetwarzania z wykorzystaniem układu FPGA.  Wykorzystywany jest tutaj fakt, że jeśli przetwarzanie w danej funkcji czy ciele pętli składa się z kilku następujących po sobie etapów tak jak w poniższym kodzie przykładowym, to z każdym z nich wiąże się alokacja pewnych zasobów sprzętowych.
\begin{lstlisting}[caption=Kod ilustrujący zastosowania dyrektywy PIPELINE]
void fun(...)
{
//#pragma HLS PIPELINE
	Op1;
	Op2;
	Op3;
}
\end{lstlisting}
Zakładając, że każda z operacji trwa 1 cykl zegara, opóźnienie pojedynczego wywołania to 3 cykle. W tym miejscu należy zauważyć, iż w momencie, gdy \texttt{Op1} przekaże wywołanie do \texttt{Op2} zasoby sprzętowe odpowiedzialne za realizację \texttt{Op1} stają się bezczynne, podczas gdy mogłyby zacząć przetwarzać kolejną porcję danych. W ten sposób opóźnienie wykonania $n$-krotnie tej funkcji zamiast $3n$ cykli wyniosłoby tylko $n + 2$~(interwał zoptymalizowanej wersji tej funkcji to 1 cykl).
\addimage{chapters/ch2/img/pipeline.png}{scale=0.5}{Przykład działania dyrektywy \texttt{PIPELINE}. Niepoddana optymalizacji funkcja a) może być wywołana dopiero gdy poprzednie jej wywołanie zostanie ukończone~(wykona się \texttt{Op3}). Użycie \texttt{PIPELINE} powoduje, że funkcja jest gotowa do przetwarzania danych w momencie gdy \texttt{Op1} z poprzedniego wywołania przekaże działanie dalej - efektem jest znaczne zwiększenie przepustowości przetwarzania}{Przykład działania dyrektywy \texttt{PIPELINE}}{ch2:img:pipeline}
Jeśli funkcja lub pętla, którą użytkownik zamierza zoptymalizować stosując \texttt{PIPELINE} zawiera w swoim ciele inną pętlę lub jej hierarchię, ilość ich iteracji musi być znana w momencie kompilacji - w przeciwnym razie HLS nie będzie w stanie zastosować tej optymalizacji~(patrz dyrektywa \texttt{UNROLL}).

\item \texttt{ARRAY\_PARTITION}

Efektywność zastosowania dyrektywy \texttt{PIPELINE} do danej funkcji czy pętli okazuje się być często ograniczona poprzez intensywny dostęp do pamięci, w której zapisane są tablice danych. Gdy dany algorytm próbuje odwoływać się do tej samej tablicy więcej niż 2 razy należy się zastanowić nad przeprojektowaniem algorytmu stanowiącego ograniczenia, gdyż układy BRAM implementujące funkcjonalność tablic umożliwiają wykonanie do dwóch operacji zapisu/odczytu danych w pojedynczym cyklu zegara. W przypadku gdy taka zmiana nie jest możliwa można się posłużyć dyrektywą \texttt{ARRAY\_PARTITION} do podziału tablicy stanowiącej ograniczenie przepustowości. Można tego dokonać na 3 sposoby zilustrowane poniższym schematem - wybór optymalnej wersji zależy od wzoru dostępu do danych znajdujących się w partycjonowanej tablicy.
\addimage{chapters/ch2/img/array_partition.png}{scale=0.6}{Sposoby podziału tablicy na mniejsze elementy. W przypadku a) pierwotna tablica zostaje podzielona na $f=2$ równych elementów - pierwsza otrzymuje elementy o mniejszych, a druga o większych indeksach~(podział blokowy ang. \textit{block}). Przykład b) rozmieszcza co $f=2$ element pierwotnej tablicy w mniejszych tablicach~(podział cykliczny ang. \textit{cyclic}). Przykład c) odpowiada rozbiciu tablicy na poszczególne rejestry~(podział całkowity ang. \textit{complete})}{Sposoby podziału tablicy na mniejsze elementy}{ch2:img:array_partition}

\item \texttt{UNROLL}

Domyślne parametry Vivado HLS dokonują syntezy pętli w taki sposób, że istnieje tylko jeden zespół bloków logicznych odwzorowujących algorytm wykonywany przez ciało pętli, który jest używany przez wszystkie jej iteracje. Za pomocą dyrektywy \texttt{UNROLL} możliwa jest zmiana tego zachowania:
\begin{itemize}
\item dokonanie częściowego rozwinięcia pętli, które dokona $f$-krotnej replikacji logiki odpowiedzialnej za ciało pętli,
\item pełne rozwinięcie wszystkich $n$ iteracji pętli (ilość iteracji musi być znana w momencie kompilacji kodu).  
\end{itemize}
W obu przypadkach rozwinięcia pętli, wszystkie zreplikowane bloki będą przetwarzać dane jednocześnie dla maksymalnej wydajności (o ile nie występują ograniczenia związane z dostępem do tablic oraz nie istnieją zależności pomiędzy wartościami występującymi w różnych iteracjach) kosztem zwiększonej konsumpcji zasobów. Należy pamiętać, że pełne rozwinięcie pętli jest narzucane automatycznie w przypadku, gdy funkcja bądź pętla nadrzędna zostanie poddana działaniu dyrektywy \texttt{PIPELINE}. Jeśli ilość iteracji (a przez to ilość zreplikowanych bloków) nie będzie znana w momencie kompilacji proces optymalizacji tego kodu zakończy się niepowodzeniem.

\item \texttt{DATAFLOW}


\item \texttt{LOOP\_MERGE}


\item \texttt{INLINE}
\item \texttt{DEPENEDENCE}
\end{itemize}

\subsection{Dobór układu w projekcie}

\section{Sytnteza układu oraz implementacja w FPGA}
\subsection{Vivado IP Integrator \& Processor Options}

