\chapter{Układy programowalne}
Kiedy w 1985 roku, dzięki szybko rozwijającej się litografii, wprowadzono pierwszy komercyjnie dostępny układ typu FPGA~(ang. \textit{Field Programmable Gate Array}) - układ XC2064 - bardzo szybko doceniono jego zalety wszędzie tam, gdzie wymagana jest łatwa zmiana funkcjonalności systemu przetwarzania danych. Głównym motorem rozwoju, szczególnie na początku, było powstanie i gwałtowna ekspansja Internetu i konieczność łatwego prototypowania oraz wdrażania nowych rozwiązań zwłaszcza jeśli chodzi o tworzenie przełączników i ruterów~\cite{Designing_with_Xilinx}.

Tak duże zainteresowanie tymi układami bierze się z faktu, iż są one w łatwy sposób rekonfigurowalne, a przez to mogą realizować dowolne funkcje logiczne. W przeciwieństwie do ogólnodostępnych układów typu CPU~(ang. \textit{Central Processing Unit}), których działanie opiera się na sekwencyjnym przetwarzaniu listy rozkazów w obrębie przewidzianej przez producenta \textit{architektury instrukcji}~(ang.~\textit{Instruction Set Architecture}, ISA)~\cite{INTEL_ISA} układy FPGA są konfigurowalne na poziomie sprzętowym a nie programowane. Zakupiony od producenta procesor po podaniu mu danych oraz listy instrukcji~(programu) będzie je przetwarzał i na wyjściu otrzyma się oczekiwaną wartość. Układ FPGA nie zrealizuje żadnej operacji mimo podania konkretnych danych wejściowych, jeśli nie zostanie skonfigurowany\footnote{Rozróżnienie pomiędzy konfiguracją a programowaniem powinno wybrzmieć dostatecznie mocno. Na dalszych kartach tej pracy terminy te będą używane zamiennie w kontekście układów FPGA, co jest podyktowane technologią użytą do wykonania omawianego projektu.}.

Na konfigurowalność układów FPGA składają się wspólnie dwa czynniki - obecność \textit{bloków logicznych}~(ang.~\textit{logic blocks}) oraz elastycznej~(tzn. konfigurowalnej) sieci połączeń między nimi~(ang. \textit{routing}) zdolnej teoretycznie wytworzyć połączenie pomiędzy dowolnymi blokami.
\addimage{chapters/ch2/img/fpgaBigPicture.png}{scale=0.4}{Schemat ideowy budowy układu FPGA. Bloki logiczne (LB) połączone są między sobą oraz z blokami wejścia-wyjścia~(IOB) za pomocą gęstej sieci konfigurowalnych połączeń. Bloki wejścia-wyjścia służą do ustanowienia komunikacji z urządzeniami peryferyjnymi takimi jak moduł pamięci RAM czy klawiatura}{Schemat ideowy budowy układu FPGA}{ch2:img:fpgaBigPicture}
Każdy blok logiczny składa się minimalnie z trzech elementów:
\begin{itemize}
\item $n$-wejściowej konfigurowalnej \textit{tablicy przeglądowej}~(ang. \textit{LookUp Table}, LUT), której zadaniem jest realizacja $n$-parametrowej funkcji logicznej np. $(\bar{A}\vee B) \wedge C$ jest 3-parametrową funkcją logiczną,
\item \textit{przerzutnika}~(ang. \textit{flip-flop}, FF) działającego jako pamięć,
\item \textit{multipleksera}~(ang. \textit{multiplexer}, MUX/MX), który dokonuje wyboru źródła sygnału, który ma zostać przekazany na wyjście bloku logicznego.
\end{itemize}
\addimage{chapters/ch2/img/fpgaLB}{scale=0.35}{Budowa podstawowego bloku logicznego w układzie FPGA. 4-wejściowy LUT realizuje ustaloną funkcję logiczną, której wynik, zależny od kombinacji sygnałów (I[0]:I[3]), przekazywany jest do przerzutnika (FF) w celu zapamiętania. Przerzutnik działa synchronicznie z doprowadzonym sygnałem zegarowym~(CLK) a jego zawartość może być zresetowana~(RST). O tym, jaka wartość~(O) zostanie podana na wyjściu bloku logicznego decyduje parametr~(S) sterujący wyborem multipleksera~(MX) pomiędzy nowym a zapamiętanym uprzednio wynikiem działania.}{Budowa podstawowego bloku logicznego w układzie FPGA}{ch2:img:fpgaLB}
Pojedynczy blok logiczny sam w sobie jest dość prymitywnym elementem i samodzielnie nie jest w stanie realizować funkcji, której liczba parametrów wejściowych przekracza ilość wejść do LUT. Jednak dzięki występującej sieci połączeń\footnote{W literaturze często wspomina się o blokach logicznych zanurzonych w morzu połączeń.} wyjście jednego bloku logicznego może stanowić wejście drugiego. W ten sposób tworzone są znacznie bardziej rozbudowane funkcje logiczne. Wynika też z tego, że im więcej i im bardziej rozbudowane są bloki logiczne tym możliwości w zakresie komponowania funkcjonalności są szersze~(wtedy jednak pojawiają się dodatkowe wyzwania konstruktorskie związane z optymalnym projektem sieci połączeń~\cite{FPGA_ARCHITECTURE}).
\addimage{chapters/ch2/img/fpgaSizeCost.png}{scale=0.4}{Rozwój układów FPGA od momentu ich konstrukcji do dziś. Wartości podane na wykresie są liczone względem pierwotnego układu XC2064, który posiadał 64 programowalne bloki logiczne. Kwadratami oznaczono względną pojemność układu rozumianą poprzez ilość elementów logicznych, zamalowane koła osiągalne częstotliwości, ciągła gruba linia to cena, a linia z krzyżykami to pobierana moc. Widoczny jest znaczny postęp, który dokonał się na przestrzeni ostatnich lat~\cite{Designing_with_Xilinx}}{Rozwój układów FPGA od momentu ich konstrukcji do dziś}{ch2:img:fpgaSizeCost}

Lata rozwoju układów FPGA połączone z analizą często wykorzystywanych algorytmów doprowadziły do implementacji dodatkowych elementów wchodzących w skład bloków logicznych. Są to jednostki bardziej wyspecjalizowane niż LUT, których użycie sprawia, że dany typ zadania może być wykonany znacznie szybciej i/lub jest bardziej ekonomiczne pod względem wykorzystania powierzchni układu. Tak powstały m. in:
\begin{itemize}
\item pamięci o niewielkiej pojemności LUTRAM,
\item pamięci blokowe~(ang. \textit{block RAM, BRAM}), zdolne do przechowywania porcji danych rzędu 18~kb i wykonania do dwóch operacji dostępu w jednym cyklu zegara,
\item moduły DSP dedykowane szybkiemu przetwarzaniu operacji dodawania i mnożenia.
\end{itemize}
Znajomość liczby, typu elementów składających się na układ FPGA oraz wymagań stawianych na etapie projektowania algorytmów pozwala dobrać odpowiedni układ do danych zastosowań, a przez to zoptymalizować koszty, które generowane byłyby przez elementy niewykorzystane. Producenci, chcąc sprostać oczekiwaniom rynkowym dostarczają całe gamy produktów, których wielkość mierzona za pomocą ilości bloków logicznych może zaczynać się na ok. 1000 bloków a kończyć na paru milionach~\cite{XILINX_PRODUCT_TABLE}.

Elastyczność w zakresie budowania funkcji logicznych posiada jednakże pewną niedogodność związaną z maksymalnymi osiągalnymi częstotliwościami pracy układów. W części przypadków~(w tym omawianego systemu śledzenia promieni) samo przetworzenie sygnałów w bloku logicznym może trwać zaledwie 20-30\% budżetu czasowego wynikającego z okresu zadanego zegara. Pozostały czas jest czasem potrzebnym na propagację wyniku do kolejnego bloku logicznego poprzez dostępną w układzie konfigurowalną sieć połączeń. W efekcie uzyskiwane maksymalne częstotliwości zegara dla specyficznych zastosowań przetwarzania sygnałów~(ang. \textit{Digital Signal Processing, DSP}) mogą przekraczać 500~MHz\footnote{Tak wysokie częstotliwości, jak na układy FPGA są możliwe do uzyskania tylko dzięki obecności dedykowanych bloków DSP w strukturze układu FPGA.}, a w typowych zastosowaniach są to wartości pomiędzy 200 a 400 MHz~(wartości te zależą oczywiście od technologii wykonania układu FPGA, akcelerowanego algorytmu i jakości kodu). W porównaniu do obecnych dzisiaj procesorów CPU działających coraz częściej z częstotliwościami sięgającymi 4 GHz są to wartości 10- 20-krotnie niższe. Wydawać mogłoby się zatem~(tylko na podstawie porównania osiąganych częstotliwości), że nie można oczekiwać zbliżonej i wyższej wydajności od układu FPGA realizującego identyczny algorytm co odpowiadający mu procesor CPU. Nie musi być to prawdą. Zależnie od typu rozwiązywanego problemu jak i umiejętności projektanta, algorytmy mogą być wykonywane o całe rzędy wielkości szybciej niż ich odpowiedniki opisane listą rozkazów CPU przy niższym zegarze oraz niższej konsumpcji energii elektrycznej. Kluczowa jest tu świadomość, iż projektant ma bezpośredni wpływ na to, jak układ zostanie skonfigurowany. Ta dowolność nierozerwalnie wiąże się z dużą odpowiedzialnością oraz stopniem doświadczenia wymaganego od projektanta.

\section{Konfiguracja i języki opisu sprzętu}
Pierwsze wytworzone \textit{układy scalone}~(ang. \textit{integrated circuit}, IC) posiadały małą złożoność, liczoną w setkach bramek logicznych, przez to charakteryzowały się niewielkim stopniem komplikacji (w rozumieniu realizowanej funkcjonalności). W tamtych czasach odpowiedzialność za projekt i testy takiego układu leżały w gestii doświadczonego projektanta. Musiał on nie tylko w sposób ręczny wykonać projekt realizujący zadaną funkcjonalność, ale również zadbać o to, by sygnały propagujące się w układzie dochodziły do kolejnych etapów przetwarzania, wtedy gdy będą potrzebne\footnote{Prędkość propagacji sygnałów jest skończona i wynika między innymi z wykorzystywanej technologii.}. Wraz z postępem technologicznym ilość bramek logicznych, która mogła znaleźć się w pojedynczym układzie rosła, w wyniku czego pojawiła się potrzeba stworzenia narzędzi, które mogłyby wspomagać pracę na kolejnych etapach tworzenia układu elektronicznego tj.:
\begin{itemize}
\item tworzenia funkcjonalności,
\item testów, 
\item syntezy,
\item implementacji. 
\end{itemize}
W tym czasie języki programowania takie jak Pascal i C były powszechnie używane do tworzenia programów wykonywanych sekwencyjnie przez procesory zdolne do realizowania określonego zbioru instrukcji. Języki te jednakże nie mogły zostać zaadaptowane do celów opisu funkcjonalności połączonych ze sobą elementów elektronicznych (pojedynczych bramek, bloków DSP czy LUT) właśnie przez ich sekwencyjną naturę. Zintegrowane układy elektroniczne w swoim założeniu przetwarzają jednocześnie wiele sygnałów dla optymalnej efektywności. Dla przykładu, jeżeli rozwiązywany problem wymaga wykonania $n$ niezależnych od siebie operacji dodawania, najefektywniej jest zaprojektować układ tak, by na tym etapie przetwarzania znajdowało się $n$ niezależnych od siebie sumatorów. Potrzeba kreowania tego typu zachowań w układach elektronicznych doprowadziła do powstania \textit{języków opisu sprzętu}~(ang. \textit{Hardware Description Languages}, HDL). Pozwoliły one nie tylko na modelowanie funkcjonalności układów elektronicznych, ale również na przeprowadzanie wnikliwych testów poprawności wykonania zgodnie z założeniami projektowymi dzięki środowiskom symulacyjnym. Języki te, najpopularniejsze wśród nich to Verilog oraz VHDL, zaoferowały możliwość opisu układów cyfrowych na poziomie przepływu danych pomiędzy kolejnymi rejestrami~(ang. \textit{register transfer level}, RTL). Odrębne narzędzia zaś na podstawie tego opisu~(RTL) mogą dokonać ekstrakcji wymaganych elementów logicznych i połączeń między nimi~\cite{VERILOG_BIBLE}. W zależności od tego, jakiego typu układ jest projektowany: czy jest to \textit{wyspecjalizowany układ scalony}~(ang. \textit{application-specific integrated circuit}, ASIC) czy układ FPGA, zespół wyekstrahowanych elementów logicznych i połączeń między nimi tzw. \textit{netlista}~(ang. \textit{netlist}) na etapie syntezy będzie inny, ale funkcjonalność zostanie zachowana. Właśnie ta cecha jest często eksploatowana przy tworzeniu układów typu ASIC, gdzie etapem pośrednim jest implementacja funkcjonalności w układzie FPGA, co pozwala przetestować w realnych zastosowaniach nowo tworzony układ, zanim ten zostanie wysłany do~(kosztownej) produkcji w finalne postaci. 

Implementacja w układzie FPGA jest zautomatyzowanym procesem zaczynającym się od optymalizacji wygenerowanej netlisty po to, aby realizacja zadanej funkcjonalności wymagała jak najmniej bloków logicznych z uwzględnieniem optymalizacji wpływających na szybkość przetwarzania. Ma to na celu zmniejszenie opóźnień związanych z propagacją danych, dzięki czemu możliwe jest użycie wyższych częstotliwości zegarów. Następnie bloki te łączone są ze sobą w klastry w fizycznym układzie w taki sposób, by uzyskać ich optymalny rozkład w przestrzeni układu~(unikając tzw. \textit{stłoczenia}~ ang. \textit{congestion}, czyli lokalnego przeciążenia sieci połączeń) z zachowaniem jak najkrótszych odległości między nimi. 

Naturalnym problemem, który tutaj występuje jest pytanie o to czy rezultaty uzyskane na drodze syntezy i implementacji są najlepsze z możliwych dla danego układu FPGA i opisu za pomocą RTL. W istocie dla dzisiejszych układów, których ilość bloków logicznych przekracza milion, a ilość dostępnych połączeń w sieci jest dziesięciokrotnie wyższa rozpatrzenie wszelkich możliwych kombinacji jest niemożliwe~\cite{FPGA_SD}. W związku z tym narzędzia muszą posługiwać się przybliżonymi algorytmami heurystycznymi sterowanymi za pomocą dziesiątek parametrów a i tak czas oczekiwania na finalny plik konfiguracyjny tzw. \textit{bitstream} może przekroczyć 24 godziny~(w zależności od stopnia skomplikowania RTL). Co więcej nie ma gwarancji, że narzędzie znajdzie rozwiązanie, które spełnia wymagania czasowe dotyczące transferu sygnałów pomiędzy kolejnymi blokami - bez tego układ na pewno nie będzie działał poprawnie\footnote{Narzędzia dokonujące wyliczeń opóźnień między blokami z natury są konserwatywne, czyli ich estymacje wynikają z symulacji najgorszego możliwego przypadku. Znane są jednak przypadki, gdy narzędzia te raportowały pozytywne przejście testów opóźnień, jednak pracujące urządzenie po pewnym czasie zaczynało zachowywać się w sposób nieprzewidywalny. Błędy te najprawdopodobniej związane są ze zwiększonym szumem termicznym występującym w pracującym i rozgrzanym układzie. }. Na dodatek wpływ dwóch dowolnych parametrów sterujących syntezą i implementacją nie musi być od siebie niezależny. Dlatego producenci tych narzędzi dostarczają przeważnie zestawy predefiniowanych ustawień, które według ich zapewnień powinny działać najbardziej optymalnie. Ustawienia te można podzielić na dwie główne i z założenia wykluczające się grupy: optymalizujące projekt pod względem osiąganych częstotliwości zegara oraz ilości użytych bloków logicznych. Jednak każdy projekt, a zwłaszcza te o dużym stopniu utylizacji zasobów układu, należy traktować indywidualnie. Samodzielne poszukiwanie optymalnych parametrów przy ustalonym RTL, gdy predefiniowane ustawienia nie dają oczekiwanych rezultatów wymaga nie tylko doświadczenia, ale również szczęścia. InTime, czyli komercyjne narzędzie dostępne na rynku i rozwijane od kilku lat, pozwala poprzez użycie technik uczenia maszynowego rozwiązać większość tych problemów. Jest ono tak zaprojektowane, iż jest w stanie dokonać predykcji optymalnych parametrów syntezy i implementacji każdego projektu dla narzędzi dostarczanych przez najważniejszych producentów układów FPGA~\cite{InTime1}\cite{InTime2}\cite{InTime3}. 

Z drugiej zaś strony, istnieje możliwość, iż stworzony opis sprzętu jest nieoptymalny dla danej architektury układu FPGA. Konieczne mogą okazać się znaczne zmiany projektowe po to, aby zmniejszyć konsumpcję zasobów~(elementów składowych bloków logicznych) i/lub móc osiągnąć wymaganą częstotliwość zegara. 

W związku z tym projektowanie funkcjonalności realizowanej dzięki układom FPGA jawi się jako proces o dużym stopniu komplikacji, gdzie nawet najmniejsza zmiana na którymkolwiek etapie może wpływać na jakość rezultatu końcowego~(ang. \textit{Quality of Results}, QoR) tj. wydajność i zużycie zasobów. To czy dana implementacja jest satysfakcjonująca zależy zaś od postawionych lub narzuconych z zewnątrz wymagań. 

\section{Nowoczesne podejście do tworzenia funkcjonalnych układów elektronicznych}
W poprzednim podrozdziale wspomniano o językach opisu sprzętu, jako o narzędziu służącym do projektowania zachowania układów elektronicznych, które z natury rzeczy przetwarzają współbieżnie porcje danych. Języki te współistniały i były rozwijane równolegle z językami sekwencyjnymi służącymi do programowania procesorów, jednak z uwagi na powszechniejszy dostęp do układów typu CPU~(ang. \textit{Central Processing Unit}) znacznie bardziej rozpowszechnione zostały języki takie jak FORTRAN czy C, pozostawiając znajomość Verilog, VHDL i ich pochodne tylko dla wąskiego grona posługujących się nimi specjalistów.

W społeczności akademickiej oraz u producentów układów FPGA zrodziło się pytanie czy można udostępnić szerokiemu gronu odbiorców język, którego składnia nie odbiegałaby w znaczący sposób od znanych języków sekwencyjnych a pozwalający na przetwarzanie masowo równoległe~(ang. \textit{massively parallel}) podobnie, jak robią to HDL. Narzędzie dokonujące translacji kodu podobnego do C do jego ekwiwalentu w HDL, pozwoliłoby dotrzeć producentom układów FPGA do nowych odbiorców w znacznie prostszy sposób, a przez to zwiększyć swój zasięg i zyski. Mimo że próby stworzenia możliwie uniwersalnego narzędzia tego typu trwają już ponad 25 lat~\cite{C_VHDL}, dopiero niedawno stały się one wystarczająco użyteczne w realizacji postawionego im celu. 

\subsection{Synteza wysokiego poziomu}
Proces konwersji algorytmu~(rozumianego jako ciąg operacji koniecznych do wykonania w celu otrzymania żądanego wyniku na podstawie dostarczonych danych) opisanego w języku wysokiego poziomu do jego specyfikacji na poziomie RTL nazywany jest \textit{syntezą wysokiego poziomu}~(ang. \textit{high level synthesis}, HLS). Dokonuje ona analizy, kiedy żądane operacje mają być wykonane i wybiera odpowiednie bloki znajdujące się w układzie~(pamięć, moduły DSP, przerzutniki, LUT i inne), które te operacje będą wykonywać~(rysunek~\ref{ch2:img:HLS_schedule}). 
\addimage{chapters/ch2/img/HLS_schedule.png}{scale=0.30}{Przykład optymalizacji wykonania iloczynu skalarnego $\sum_{i = 0}^3 a_ib_i$ za pomocą HLS. Iloczyn skalarny 4-elementowych wektorów wymaga wykonania 4 operacji mnożenia i 3 dodawania przy czym część operacji może zostać wykonana współbieżnie. W pierwszym kroku HLS dokona alokacji 4 operatorów mnożenia~(I), następnie wykonane zostaną 2 sumy cząstkowe~(II) oraz suma końcowa~(III). Takie rozłożenie wykonania operacji w czasie zapewnia maksymalną wydajność, co wiąże się również z największym zużyciem zasobów znajdujących się w układzie. Narzędzia HLS umożliwiają również takie rozłożenie operacji w czasie, by kosztem zmniejszonej wydajności oszczędzić część zasobów logicznych}{Przykład optymalizacji wykonania iloczynu skalarnego za pomocą HLS}{ch2:img:HLS_schedule}
Wynikowy projekt zapisany w postaci RTL opisuje dla każdego kroku przepływ danych pomiędzy rejestrami, który realizuje funkcjonalność opisaną w prosty i zrozumiały sposób za pomocą języka wysokiego poziomu. Projektant/programista za cenę utraty kontroli nad formą RTL zdaje się w momencie konwersji na ciąg automatycznych procesów przewidzianych przez twórcę danego HLS\footnote{Szczegółowy opis tego, w jaki sposób dokonywana jest analiza algorytmu i jego konwersja do reprezentacji w postaci RTL można znaleźć w rozdziale 2~\cite{FPGA_SD}.}. W większości przypadków jednak samo wykrywanie operacji niezależnych, mogących być wykonanych jednocześnie w układzie jest niewystarczające, by wykorzystać pełen potencjał, jaki dają układy FPGA. Dlatego każdy HLS posiada w swojej składni pewien zestaw poleceń stanowiących wskazówkę dla procesu syntezy, w jaki sposób należy poddać konwersji daną partię kodu dla uzyskania optymalnych w danych warunkach rezultatów.

\section{Xilinx i Vivado HLS}
Kluczem do stworzenia narzędzia HLS, które stanie się chętnie wykorzystywane przez projektantów układów elektronicznych jest spełnienie dwóch warunków:
\begin{enumerate}
\item Bazowanie na dobrze znanym języku programowania jak np. C, tak aby wprowadzić jak najmniejszą ilość restrykcji w jego składni, które mogłyby stanowić ograniczenia w zakresie tworzenia funkcjonalności.
\item Dostarczenie odpowiednich rozszerzeń do języka bazowego, które udostępniałyby dostęp do optymalizacji wynikających wprost z możliwości używanego sprzętu.
\end{enumerate}
Narzędziem, które spełnia oba te założenia jest rozwijany przez firmę Xilinx (twórców pierwszego układu FPGA XC2064) Vivado HLS wchodzący w skład pakietu do tworzenia funkcjonalności w oparciu o układy FPGA tego producenta: Vivado Design Suite. Vivado HLS na podstawie kodu C/C++\footnote{Możliwe jest również wykorzystanie SystemC oraz OpenCL~(Open Computing Language).} oraz informacji o żądanych przez użytkownika optymalizacjach, mających głównie na celu zwiększenie wydajności przetwarzania danych przez algorytm, dokonuje syntezy projektu do jego reprezentacji w VHDL i Verilog. Końcowym produktem syntezy jest \textit{moduł~IP}~(ang.~\textit{Intellectual Property core}), który może stać się częścią systemu przetwarzania danych za pomocą układu FPGA firmy Xilinx.

\subsection{Vivado HLS w opracowaniach}
Od momentu udostępnienia użytkownikom, Vivado HLS stał się obiektem zainteresowania środowisk akademickich i inżynierskich chcących zbadać przede wszystkim poprawność syntezy kodu C/C++ oraz jakość generowanego opisu RTL w porównaniu do metod tradycyjnych. W opracowaniu~\cite{C_VERILOG} autorzy dokonali sprawdzenia równoważności wielu algorytmów pomiędzy kodem C a uzyskanym na jego podstawie RTL. Ponadto dostrzegli, iż badane narzędzie dokonuje wielu nietrywialnych optymalizacji, wśród których wymienić można:
\begin{itemize}
\item Wykrywanie propagacji oraz zwijanie wyrażeń zawierających stałe np.  
\begin{lstlisting}
...
int x = 2;
int y = x * 4 / 5 + fun(i);
\end{lstlisting}
zostanie zoptymalizowane do postaci:
\begin{lstlisting}
...
int y = 1 + fun(i);
\end{lstlisting}
\item Usuwanie wykonania operacji, które nie mają wpływu na wynik działania funkcji.
\item Przenoszenie kodu niezależnego od iteracji pętli poza jej ciało.
\end{itemize}
Inni autorzy dokonali za to szczegółowych studiów przypadków implementacji często wykorzystywanych algorytmów za pomocą Vivado HLS. W publikacji~\cite{HLS_HDL_GRID} udowodniono poprawność stworzonego i zoptymalizowanego RTL, realizującego synchronizację w trójfazowych przekaźnikach mocy. Porównano jego wydajność i użycie zasobów względem znanego wcześniej projektu zapisanego bezpośrednio z użyciem VHDL\footnote{Różnica między nimi polegała na wykorzystaniu innej reprezentacji liczbowej - projekt Vivado HLS używał liczb zmienno-, a VHDL stałopozycyjnych.}. Projekt stworzony z użyciem nowego narzędzia był o ok. 10\% szybszy niż jego pierwowzór, jednak utylizacja zasobów była nawet dwukrotnie większa. Przydatność poszczególnych dyrektyw optymalizacyjnych udostępnianych przez Vivado HLS oraz problemy wynikające z natury analizowanych algorytmów a wpływające na stosowalność tych optymalizacji została omówiona w~\cite{VHLS_ESD}. Z kolei rozprawa~\cite{HLS_HDL_MATRIX} koncentruje się na analizie implementacji mnożenia macierzy za pomocą trzech różnych algorytmów. Autorzy pokazują w niej, jak poszczególne optymalizacje wpływają zarówno na czas wykonania jak i na wykorzystanie zasobów logicznych układu FPGA i porównują te metryki z tymi, które odpowiadają ich w pełni zoptymalizowanym wersjom stworzonym przez doświadczonych projektantów w HDL. Okazuje się, że w każdym przypadku najszybsza wersja opisana za pomocą Vivado HLS była wyraźnie wolniejsza i niemal w każdym przypadku wykorzystywała więcej zasobów docelowego układu FPGA.

Oprócz prac porównawczych, istnieją również dokumenty opisujące nietrywialne techniki optymalizacji, głównie związane z problemami występującymi w momencie konieczności iteracyjnego przetwarzania danych w pętlach~\cite{LOOP_PARALLELIZATION}\cite{HLS_HDL_MATRIX}. Pokazują one wprost, w jaki sposób można radzić sobie z tego typu wyzwaniami z użyciem Vivado HLS.

Chociaż autorzy przytoczonych publikacji są zgodni, co do tego, iż pomimo zastosowania odpowiednich optymalizacji kodu, otrzymane projekty nie oferują bezwzględnie maksymalnej wydajności z niewspółmiernie dużą utylizacją bloków logicznych, nadal jednak użycie Vivado HLS jest uzasadnione w przypadku braku specjalistycznej wiedzy związanej z językami opisu sprzętu. Narzędzie to pozwala również osiągnąć satysfakcjonujące rezultaty, wymagającego średnio ok. 3-krotnie mniejszego nakładu pracy względem rozwiązania tworzonego bezpośrednio w HDL przez doświadczonego projektanta.

\subsection{Podstawowe informacje związane z Vivado HLS}
Firma Xilinx udostępniając użytkownikom swoich rozwiązań technologicznych Vivado HLS ułatwiła zadanie początkującym projektantom/programistom. Tworzenie algorytmu za pomocą języka C/C++ jest nie tylko łatwiejsze niż tworzenie opisu RTL, ale również powstający kod jest w zamierzeniu znacznie bardziej czytelny. Co więcej, testowanie przygotowywanych algorytmów odbywa się również w środowisku symulacyjnym C/C++, a co za tym idzie można wykorzystywać tradycyjne narzędzia do sprawdzania funkcjonalnej poprawności~(\textit{debugowania}) algorytmów na dowolnym etapie, a także zmierzyć czas wykonania algorytmu przez procesor komputera. Na dodatek Vivado HLS bierze pod uwagę, dla jakiego konkretnego układu FPGA firmy Xilinx przeprowadzana jest synteza oraz przy jakiej częstotliwości pracy. Dzięki temu narzędzie to na podstawie znanej mu szybkości wykonywania operacji dla danego FPGA dokonuje oceny, które operacje mogą zostać wykonane w tym samym cyklu zegara, a które muszą zostać rozłożone na kilka takich cykli - bardziej zaawansowane technologicznie układy będą w stanie wykonać dany algorytm szybciej i/lub z użyciem mniejszej liczby zasobów sprzętowych\footnote{Oczywistą ceną za dostęp do tego typu optymalizacji jest ograniczenie stosowalności Vivado HLS tylko do układów wyprodukowanych przez firmę Xilinx.}.

Atrakcyjność rozwiązania jakim jest Vivado HLS polega głównie na tym, że na pierwszy rzut oka jego składnia niewiele różni się od tej znanej z języków C/C++. Należy stworzyć funkcję główną, która zazwyczaj będzie przyjmować pewien zbiór argumentów oraz zwracać wyniki na zewnątrz modułu~(argumenty te na drodze syntezy staną się portami wejścia/wyjścia tworzonego IP). Funkcja główna będzie realizować pewien algorytm wykorzystując odpowiednie konstrukcje wynikające ze składni języka bazowego i może się odwoływać do innych funkcji pomocniczych. W rzeczywistości Vivado HLS implementuje dużą część standardowych konstrukcji języków C/C++ oraz typów danych, jednak istnieją pewne ograniczenia, wśród których najważniejsze to\footnote{Spisane tutaj ograniczenia mają zastosowanie tylko i wyłącznie do ciała funkcji głównej i wszystkich funkcji wywoływanych przez nią, która zostaje poddana syntezie do RTL. W środowisku testowym C/C++ ograniczenia te nie występują. }:
\begin{itemize}
\item Brak wsparcia dla dynamicznego zarządzania pamięcią (polecenia \texttt{new/delete} oraz \texttt{malloc()/free()}), wynikający wprost z faktu, iż układ FPGA dysponuje ustalonymi zasobami sprzętowymi. Użycie tych zasobów musi być konkretne i znane na etapie implementacji funkcjonalności w układzie, by móc dokonać odpowiednich połączeń pomiędzy kolejnymi elementami logicznymi. O ile w przypadku tablic danych wystarczające może się okazać przyjęcie takiego rozmiaru by w danym momencie mieściły się w niej wszystkie potrzebne wartości, o tyle programiści przyzwyczajeni do \textit{programowania zorientowanego obiektowo}~(ang. \textit{object-oriented programming}) szybko natkną się na problemy z uwagi na:
\begin{itemize}
\item brak obsługi generycznych typów danych~(C++ STL) takich jak: \texttt{vector}, \texttt{map} czy \texttt{queue},
\item ograniczone wsparcie dla polimorfizmu, które jest dopuszczalne tylko jeśli typy danych można określić w sposób statyczny (na etapie kompilacji),
\item niepełną obsługę funkcjonalności związaną z użyciem wskaźników, w szczególności możliwe jest tylko rzutowanie wskaźników pomiędzy natywnymi typami języka bazowego.
\end{itemize}
\item Niedopuszczalne jest aby IP dokonywało odwołań do jakichkolwiek funkcji systemowych. Funkcjonalność realizowana poprzez stworzone IP jest sterowana tylko poprzez dane, które jest on w stanie odczytać z portów wejścia i nie posiada ono wiedzy na temat niczego innego~(włączając w to inne IP, które mogą działać równolegle z nim na tym samym układzie FPGA). Stąd też np. użycie funkcji \texttt{time()} przez IP jest niedopuszczalne, można jednak stworzyć port wejściowy, przez który będzie przekazywana odpowiednia wartość z zewnątrz. 
\item Niemożliwe jest stosowanie funkcji rekurencyjnych~(tzn. odwołujących się same do siebie) wprost\footnote{Omawiany problem implementacji śledzenia promieni z użyciem ukaładu FPGA z natury rzeczy jest problemem rekurencyjnym, gdzie promienie padające na powierzchnię obiektu dzielą się na promienie odbite i załamane.}. W miarę możliwości należy dążyć do przekształcenia algorytmu w taki sposób, aby dało się go opisać za pomocą pętli. Alternatywnie można podjąć się emulacji tego, w jaki sposób CPU radzi sobie z przetwarzaniem rekurencyjnym z użyciem stosu~\cite{HLS_RECURSIVE}.
\end{itemize} 
Powyższe ograniczenia, a zwłaszcza te dotyczące zarządzania pamięcią oraz przetwarzania rekurencyjnego, w wielu przypadkach prowadzić będą do stworzenia od podstaw istniejących już algorytmów tradycyjnie wykonywanych przez CPU. Przy tego typu konwersji należy również przemyśleć możliwości wykorzystania potencjału przetwarzania równoległego, który może zapewnić sprzęt.

Z drugiej jednak strony producent Vivado HLS dostarcza zbiór bibliotek, które są zoptymalizowane pod kątem czasu wykonania i implementacji w układach FPGA. Ma to szczególne znaczenie w przypadku odwoływania się do funkcji zawartych w bibliotekach matematycznych, gdzie udostępnione są nie tylko implementacje podstawowych funkcji takich jak np. \texttt{sin()}, \texttt{sqrt()}, ale również bardziej zaawansowanych jak \texttt{fft()}~(szybka transformata Fouriera). 

Użycie układów FPGA sprawia również, że programista ma dowolność w doborze i wykorzystaniu typów danych. Oprócz tradycyjnych typów jak \texttt{int}, \texttt{char}, \texttt{float} czy \texttt{double}, przechowujących standardowo 32, 8, 32 i 64 bity może on skorzystać z typów danych o dowolnej długości dla typów całkowitoliczbowych i stałopozycyjnych, jeśli tylko uzna, że takie postępowanie będzie uzasadnione - operacje arytmetyczne na mniejszych typach danych będą zwykle przeprowadzane szybciej a wykorzystanie bloków logicznych układu będzie niższe. Stałopozycyjne typy liczbowe zdefiniowane są poprzez:
\begin{itemize}
\item całkowitą ilość bitów, jaką zajmować będzie zmienna,
\item ilość bitów przypadającą na opis całkowitej części zmiennej z uwzględnieniem bitu znaku,
\item zachowanie określające sposób, w jaki dokonywane będzie zaokrąglanie,
\item zachowanie w przypadku przepełnienia (czyli co się stanie, gdy wynik działania arytmetycznego nie daje się zapisać przy pomocy zadanej liczby bitów).
\end{itemize}
Typy całkowitoliczbowe o dowolnej precyzji opisane są tylko poprzez ich długość bitową wyrażoną dodatnią liczbą całkowitą. Oba rodzaje typów liczbowych o zadanej precyzji występują w wersji z i bez znaku.

W obliczu operowania typami stałopozycyjnymi o dowolnej długości dużą niedogodnością jest fakt, iż jak dotąd (stan na wersję Vivado Design Suite 2018.1) nie zostały udostępnione użytkownikom Vivado HLS zmiennoprzecinkowe typy o dowolnej precyzji, mimo iż narzędzie \texttt{System Generator}~(również wchodzące w skład Vivado Design Suite) będące rozszerzeniem do środowiska \texttt{Simulink} oferuje taką funkcjonalność pozwalając dostosować według potrzeb ilość bitów danych przypadających na eksponentę oraz mantysę~\cite{Designing_with_Xilinx}\footnote{Jak się okaże własność ta będzie miała wpływ na końcowy projekt systemu śledzenia promieni.}. W ręce programistów Vivado HLS zostały oddane jedynie zmiennoprzecinkowe typy zgodne ze standardem IEEE-754~\cite{IEEE_754}:
\begin{itemize}
\item \texttt{half}: 1 bit znaku, 5 bitów eksponenty oraz 10 bitów mantysy,
\item \texttt{float}: 1 bit znaku, 8 bitów eksponenty oraz 23 bity mantysy,
\item \texttt{double}: 1 bit znaku, 11 bitów eksponenty oraz 52 bity mantysy.
\end{itemize}

Jeśli tylko stworzony moduł jest zgodny z obowiązującą składnią HLS, narzędzie dokonuje optymalnej implementacji dla ustalonego układu FPGA z uwzględnieniem optymalizacji zadanych przez użytkownika. Optymalizacje te, zwane w HLS \textit{dyrektywami}~(ang. \textit{optimization directives}), pozwalają na modyfikację, a przez to kontrolę nad domyślnym sposobem syntezy poszczególnych partii algorytmu jak i portów wejścia/wyjścia. Wpływ wymuszenia danej dyrektywy na odpowiednie \textit{metryki} można sprawdzić analizując informacje zawarte w wygenerowanym raporcie syntezy.
\begin{itemize}
\item Wykorzystanie zasobów~(ang. \textit{area}) to konserwatywne, czyli w najgorszym możliwym przypadku, zestawienie użycia zasobów sprzętowych (przerzutniki, LUT, BRAM, moduły DSP) koniecznych do realizacji zadanej w module funkcjonalności\footnote{Na etapie syntezy netlisty oraz implementacji w układzie dokonywana jest seria optymalizacji, mająca na celu m. in. zmniejszenie wykorzystania zasobów, dlatego wartości estymowane i faktyczne zawsze będą się różnić.}. 
\item Opóźnienie~(ang. \textit{latency}), czyli ilość cykli zegara wymaganych do przeprowadzenia wszystkich obliczeń. W przypadku pętli jest to ilość cykli zegara, aby przetworzyć wszystkie jej iteracje.
\item Opóźnienie iteracji pętli~(ang. \textit{loop iteration latency}) to ilość cykli zegara do ukończenia jednej iteracji pętli.
\item Interwał~(ang. \textit{initiation interval}, II) wyraża ilość cykli zegara, jaka upłynie zanim:
\begin{itemize}
\item funkcja będzie mogła przetworzyć kolejną porcję danych,
\item pętla będzie mogła przetworzyć dane w kolejnej iteracji.
\end{itemize} 
\end{itemize}
Przemyślany zapis algorytmiczny rozwiązywanego problemu w połączeniu z kombinacją odpowiednich dyrektyw i analizą raportów syntezy pozwala stworzyć moduł IP o optymalnych metrykach, które uzasadniałyby wykorzystanie układu FPGA i jednocześnie, na podstawie użycia zasobów, wskazywałyby na możliwość implementacji w układzie. Należy jednak podkreślić, że Vivado HLS jedynie dokonuje transformacji algorytmu do jego reprezentacji poprzez RTL i przez to nie daje gwarancji, że proces implementacji (przeprowadzany przez odrębne narzędzie) zakończy się sukcesem tj.~wygenerowaniem pliku konfiguracyjnego działającego układu.

\subsection{Wykorzystanie dyrektyw optymalizacyjnych}
Dyrektywy w Vivado HLS zmieniające domyślne parametry syntezy, a przez to wpływające na sposób implementacji na poziomie RTL, mają zastosowanie do:
\begin{itemize}
\item portów wejścia/wyjścia funkcji głównej modułu,
\item funkcji,
\item pętli,
\item regionów, czyli bloku kodu zawartego pomiędzy parą odpowiadających sobie nawiasów klamrowych,
\item tablic
\end{itemize}
i mogą zostać zapisane bezpośrednio w kodzie programu w postaci:
\begin{lstlisting}
#pragma HLS <DYREKTYWA> <PARAMETRY_DYREKTYWY>
\end{lstlisting}
jak i w oddzielnym pliku \texttt{directives.tcl}. Nie ma przy tym znaczenia z punktu widzenia syntezy, który sposób definiowania dyrektyw zostanie przyjęty przez programistę~(można nawet mieszać ze sobą oba sposoby). Należy tylko mieć na uwadze, że dyrektywy zapisane w kodzie mogą sprawiać problemy~(tzn. wywołać niepożądane optymalizacje), gdy dany kod jest współużytkowany przez kilka osób i w różnych projektach.

Poniższe zestawienie dyrektyw obejmuje tylko część z nich, z zaznaczeniem najważniejszych ich cech, które wywierają największy wpływ na optymalizację algorytmu poddanego syntezie HLS. Więcej informacji na temat dyrektyw można odnaleźć w podręczniku użytkownika HLS~\cite{UG902}.

\begin{itemize}
\item \texttt{INTERFACE}

Projekty opisywane poprzez HDL, w celu wykonywania operacji wejścia/wyjścia, wymagają posiadania tzw. portów, które działają zazwyczaj w oparciu o pewien protokół transmisji danych, który można zdefiniować używając dyrektywy \texttt{INTERFACE}. W zależności od typu danych~(pojedyncza wartość, tablica, wskaźnik) oraz sposobu dostępu~(wejście, wyjście, wejście/wyjście) Vivado HLS udostępnia odpowiednie protokoły transmisji - tutaj wspomniane zostaną dwa z nich.
\begin{itemize}
\item \texttt{AXI4-Lite} jest interfejsem, który pozwala na to, aby moduł mógł być kontrolowany poprzez CPU lub mikrokontroler. Dzięki niemu jeden interfejs może zostać wykorzystany do połączenia w grupę kilku portów~(mogą to być wartości, wskaźniki, tablice), które mogą w następstwie syntezy być kontrolowane przy pomocy stworzonego sterownika~(ang. \textit{C driver}). 
\begin{lstlisting}[caption=Przykład użycia interfejsu \texttt{AXI4-Lite}]
int fun(int* a, int* b)
{
	#pragma HLS INTERFACE s_axilite port=return bundle=BUS_A
	#pragma HLS INTERFACE s_axilite port=a 		  bundle=BUS_A
	#pragma HLS INTERFACE s_axilite port=b 		  bundle=BUS_A
	return *a + *b;
}
\end{lstlisting}
W powyższym przykładzie wartości wskazywane przez \texttt{a}, \texttt{b} oraz wartość zwracana są obsługiwane przez ten sam interfejs \texttt{AXI4-Lite} o nazwie \texttt{BUS\_A}. Wygenerowany sterownik pozwoli przy pomocy odrębnego mikrokontrolera po implementacji w układzie FPGA m. in. na:
\begin{itemize}
\item inicjalizację modułu,
\item dostarczenie informacji dla IP, gdzie w przestrzeni adresowej znajdują się wartości, na które wskazują \texttt{a} i \texttt{b},
\item uruchomienie modułu i sprawdzenie czy ten zakończył swoje działanie,
\item odczyt wyniku działania stworzonego IP.
\end{itemize}
\item \texttt{AXI4 Master}

Interfejs tego typu może zostać przypisany do portów będących tablicami i wskaźnikami, a jego cechą jest to, że pozwala dokonywać indywidualnych jak i seryjnych~(ang. \textit{burst}) transferów danych. W tym drugim przypadku wydajność transferu danych jest znacznie wyższa z uwagi na sekwencyjny odczyt/zapis względem zadanego adresu początkowego.
\begin{lstlisting}[caption=Przykład użycia interfejsu \texttt{AXI4 Master} z seryjnym dostępem do danych. Zmiana adresów wskazywanych umożliwiona została poprzez interfejs \texttt{AXI4-Lite}]
void fun(int* a, int* b)
{
	#pragma HLS INTERFACE s_axilite port=return bundle=BUS_A
	#pragma HLS INTERFACE m_axi port=a 		    bundle=MAXI_DATA
	#pragma HLS INTERFACE m_axi port=b 		    bundle=MAXI_DATA

	#pragma HLS INTERFACE s_axilite port=a 		bundle=BUS_A
	#pragma HLS INTERFACE s_axilite port=b 		bundle=BUS_A

	const unsigned n = 100;
	int loc_a[n];

	// Wykonaj kopie danych z uzyciem dostepu seryjnego
	// SPOSOB 1
	memcpy(loc_a, a, n * sizeof(int));

	Obliczenia: for (int i = 0; i < n - 1; ++i)
	{
		loc_a[i] = loc_a[i] * loc_a[i + 1];
//		loc_a[i] = a[i] * a[i + 1];
	}

	// Zapisz nowe dane do b (rowniez seryjnie)
	// SPOSOB 2
	Zapis: for (int i = 0; i < n; ++i)
	{
	#pragma HLS PIPELINE
		b[i] = loc_a[i];
	}
}
\end{lstlisting}
W powyższym przykładzie portom \texttt{a} i \texttt{b} nakazano zachowanie zgodne z protokołem \texttt{AXI4 Master} oraz poprzez interfejs \texttt{AXI4-Lite} umożliwiono sterowanie nimi z poziomu zewnętrznego mikrokontrolera. Najpierw do tablicy \texttt{loc\_a} przepisana zostaje zawartość \texttt{n=50} kolejnych wartości wskazywanych przez \texttt{a} za pomocą funkcji \texttt{memcpy()}~(i tylko w takim kontekście Vivado HLS umożliwia jej użycie). Następnie dokonywane są pewne operacje na tych wartościach, by następnie zostać przepisane pod adres wskazywany przez \texttt{b}. Co ważne, również operacja zapisu wykonywana jest w trybie seryjnym - bez użycia \texttt{memcpy()} za to jako pętla z nadaną dyrektywą \texttt{PIPELINE}, gdzie dostęp do adresów następuje bezwarunkowo~(dostęp do pamięci nie jest poprzedzony warunkiem logicznym) w kolejności rosnącej.

Opóźnienie takiego kodu, jak w powyższym przykładzie obliczone przez Vivado HLS 2017.4 dla układu znajdującego się na płytce ewaluacyjnej KCU116 wynosi 416 cykli (ze standardowym zegarem 100 MHz). Wystarczy jednak pominąć instrukcję transferu danych do \texttt{loc\_a} i bezpośrednio w pętli \texttt{Obliczenia} odwoływać się do zawartości \texttt{a} aby dostęp do danych przestał być sekwencyjny a opóźnienie wzrosło do 1197 cykli zegara. 
\end{itemize}

\item \texttt{PIPELINE}

Jest to podstawowa optymalizacja mająca zastosowanie do funkcji i pętli umożliwiająca naturalną eksplorację równoległego przetwarzania z wykorzystaniem układu FPGA.  Wykorzystywany jest tutaj fakt, że jeśli przetwarzanie w danej funkcji czy ciele pętli składa się z kilku następujących po sobie etapów tak jak w poniższym kodzie przykładowym, to z każdym z nich wiąże się alokacja pewnych zasobów sprzętowych.
\begin{lstlisting}[caption=Kod ilustrujący zastosowania dyrektywy PIPELINE]
void fun(...)
{
//#pragma HLS PIPELINE
	Op1;
	Op2;
	Op3;
}
\end{lstlisting}
Zakładając, że każda z operacji trwa 1 cykl zegara, opóźnienie pojedynczej iteracji pętli wywołującej \texttt{fun()} to 3 cykle. W tym miejscu należy zauważyć, iż w momencie, gdy \texttt{Op1} przekaże wywołanie do \texttt{Op2} zasoby sprzętowe odpowiedzialne za realizację \texttt{Op1} stają się bezczynne, podczas gdy mogłyby zacząć przetwarzać kolejną porcję danych. W ten sposób opóźnienie wykonania $n$-krotnie tej funkcji zamiast $3n$ cykli wyniosłoby tylko $n + 2$~(interwał zoptymalizowanej wersji tej funkcji to 1 cykl).
\addimage{chapters/ch2/img/pipeline.png}{scale=0.5}{Przykład działania dyrektywy \texttt{PIPELINE}. Niepoddana optymalizacji funkcja a) może być wywołana dopiero gdy poprzednie jej wywołanie zostanie ukończone~(wykona się \texttt{Op3}). Użycie \texttt{PIPELINE} powoduje, że funkcja jest gotowa do przetwarzania danych w momencie gdy \texttt{Op1} z poprzedniego wywołania przekaże działanie dalej - efektem jest znaczne zwiększenie przepustowości przetwarzania}{Przykład działania dyrektywy \texttt{PIPELINE}}{ch2:img:pipeline}
Jeśli funkcja lub pętla, którą użytkownik zamierza zoptymalizować stosując \texttt{PIPELINE} zawiera w swoim ciele inną pętlę lub jej hierarchię, ilość ich iteracji musi być znana w momencie kompilacji - w przeciwnym razie HLS nie będzie w stanie zastosować tej optymalizacji~(patrz dyrektywa \texttt{UNROLL}).

\item \texttt{ARRAY\_PARTITION}

Efektywność zastosowania dyrektywy \texttt{PIPELINE} do danej funkcji czy pętli okazuje się być często ograniczona poprzez intensywny dostęp do pamięci, w której zapisane są tablice danych. Gdy dany algorytm próbuje odwoływać się do tej samej tablicy więcej niż dwukrotnie w tym samym cyklu zegara należy się zastanowić nad przeprojektowaniem algorytmu stanowiącego ograniczenia, gdyż układy BRAM implementujące funkcjonalność tablic umożliwiają wykonanie do dwóch operacji zapisu/odczytu danych w pojedynczym cyklu zegara. W przypadku gdy taka zmiana nie jest możliwa można się posłużyć dyrektywą \texttt{ARRAY\_PARTITION} do podziału tablicy stanowiącej ograniczenie przepustowości. Można tego dokonać na 3 sposoby zilustrowane poniższym schematem - wybór optymalnej wersji zależy od wzoru dostępu do danych znajdujących się w partycjonowanej tablicy.
\addimage{chapters/ch2/img/array_partition.png}{scale=0.6}{Sposoby podziału tablicy na mniejsze elementy. W przypadku a) pierwotna tablica zostaje podzielona na $f=2$ równych elementów - pierwsza otrzymuje elementy o mniejszych, a druga o większych indeksach~(podział blokowy ang. \textit{block}). Przykład b) rozmieszcza co $f=2$ element pierwotnej tablicy w mniejszych tablicach~(podział cykliczny ang. \textit{cyclic}). Przykład c) odpowiada rozbiciu tablicy na poszczególne rejestry~(podział całkowity ang. \textit{complete})}{Sposoby podziału tablicy na mniejsze elementy}{ch2:img:array_partition}

\item \texttt{UNROLL}

Domyślne parametry Vivado HLS dokonują syntezy pętli w taki sposób, że istnieje tylko jeden zespół bloków logicznych odwzorowujących algorytm wykonywany przez ciało pętli, który jest używany przez wszystkie jej iteracje. Za pomocą dyrektywy \texttt{UNROLL} możliwa jest zmiana tego zachowania:
\begin{itemize}
\item dokonanie częściowego rozwinięcia pętli, które dokona $f$-krotnej replikacji logiki odpowiedzialnej za ciało pętli,
\item pełne rozwinięcie wszystkich $n$ iteracji pętli (ilość iteracji musi być znana w momencie kompilacji kodu).  
\end{itemize}
W obu przypadkach rozwinięcia pętli, wszystkie zreplikowane bloki będą przetwarzać dane jednocześnie dla maksymalnej wydajności (o ile nie występują ograniczenia związane z dostępem do tablic oraz nie istnieją zależności pomiędzy wielkościami występującymi w różnych iteracjach) kosztem zwiększonej konsumpcji zasobów. Należy pamiętać, że pełne rozwinięcie pętli jest narzucane automatycznie w przypadku, gdy funkcja bądź pętla nadrzędna zostanie poddana działaniu dyrektywy \texttt{PIPELINE}. Jeśli ilość iteracji (a przez to ilość zreplikowanych bloków) nie będzie znana w momencie kompilacji, proces optymalizacji tego kodu zakończy się niepowodzeniem.

\item \texttt{DATAFLOW}

Załóżmy, że w kodzie poddawanym syntezie HLS udaje się wyodrębnić następującą sekwencję przetwarzania:
\begin{lstlisting}[caption=Blok kodu mogący zostać poddany optymalizacji DATAFLOW]
int fun(int in)
{
//#pragma HLS DATAFLOW
	...
	fun_A(in, res1);
	fun_B(res1, res2);
	
	return res2;
}
\end{lstlisting}
Funkcja nadrzędna przyjmuje pewien parametr wejściowy \texttt{in}, który jest parametrem wejściowym do \texttt{fun\_A()}. Wynikiem działania \texttt{fun\_A()} jest wartość \texttt{res1}, która staje się parametrem wejściowym do \texttt{fun\_B()} - wynik jej działania, \texttt{res2},  zostaje zwrócony przez ciało funkcji nadrzędnej \texttt{fun()}. Tego typu sekwencyjne przetwarzanie danych, gdzie efekt działania jednej z funkcji~(zadania) jest parametrem wejściowym kolejnej z nich, jest kandydatem do zastosowania dyrektywy \texttt{DATAFLOW}. Optymalizacja ta podobnie jak \texttt{PIPELINE} umożliwia zwiększenie wydajności algorytmu w układzie FPGA poprzez równoległe działanie wielu zadań jednocześnie - dzieje się to jednakże w oparciu o kanały transmisji danych między zadaniami.

Użycie \texttt{DATAFLOW}~(dla funkcji i pętli) powoduje, iż pomiędzy poszczególnymi zadaniami w sekwencji tworzone są kanały buforujące dane. Te zaś w zależności od typu danych, będą implementowane jako kolejki typu \textit{FIFO}~(ang. \textit{first in, first out}) dla danych skalarnych, albo jako bufory typu \textit{ping-pong} dla danych tablicowych\footnote{Na bufor tego typu składają się dwa bufory o identycznym rozmiarze. Kiedy jeden z nich służy do odczytu danych, do drugiego dane są zapisywane. W momencie, gdy bufor, z którego były czytane dane zostaje opróżniony, role buforów ulegają zmianie.}. Każde zadanie w sekwencji działa indywidualnie, jednak jest uzależnione od tego, czy bufory dostarczające do niego dane są niepuste. Takie zachowanie pozwala potencjalnie na efektywniejsze zrównoleglenie zadań względem \texttt{PIPELINE}, które statycznie dokonuje szeregowania wykonania operacji, jednak za cenę większego zużycia zasobów związanego z implementacją wymaganych buforów. 

\addimage{chapters/ch2/img/dataflow.png}{scale=0.5}{Schemat działania \texttt{DATAFLOW}. Pomiędzy dwoma zadaniami \texttt{fun\_A()} i \texttt{fun\_B()} zostaje stworzony kanał przepływu danych, dzięki któremu wartości reprezentowane przez \texttt{res1} są odpowiednio buforowane i przekazywane jako argument wejściowy kolejnego zadania. Działanie \texttt{fun\_B()} rozpocznie się, gdy dane w buforze wejściowym staną się dostępne - od tej pory oba przedstawione zadania będą pracować jednocześnie}{Schemat działania \texttt{DATAFLOW}}{ch2:img:dataflow}

Dokonując optymalizacji \texttt{DATAFLOW} na danej funkcji lub pętli należy mieć na uwadze pewne obostrzenia związane z jej zastosowaniem:
\begin{itemize}
\item Dane wytworzone przez jedno z zadań mogą stanowić parametr wejściowy tylko jednego następnego zadania w sekwencji.
\item Efekt działania danego zadania nie może zostać użyty w kolejnej iteracji przez zadanie, wykonujące się przed nim - sprzężenie~(ang. \textit{feedback}) pomiędzy kolejnymi iteracjami jest nieobsługiwane. 
\item Wykonanie zadania z sekwencji nie może być w żaden sposób warunkowane.
\item Pętle wchodzące w skład sekwencji mogą mieć tylko jeden warunek kończący ich działanie.
\end{itemize}

\item \texttt{DEPENEDENCE}

Zadanie, jakie jest postawione przed Vivado HLS polega na odtworzeniu funkcjonalności opisanej poprzez algorytm za pomocą RTL w sposób, który nie narusza jego integralności tzn. dla dowolnego zbioru parametrów wejściowych moduł zaimplementowany w układzie FPGA musi dawać identyczne wyniki jak jego odpowiednik opisany kodem C/C++ uruchomiony na CPU. Z tego powodu wykrywane są zależności pomiędzy operacjami, które zachowują oryginalny ciąg przyczynowo-skutkowy. Zachowanie to w szczególności może powodować, iż przepustowość pętli z dyrektywą \texttt{PIPELINE} określona przez jej interwał, zostanie ograniczona przez zależności występujące pomiędzy kolejnymi iteracjami.

\begin{lstlisting}[caption=Zależność interwału pętli od występujących zależności pomiędzy kolejnymi iteracjami]
...
for(int i = 0; i < N - 1; ++i)
{
#pragma HLS PIPELINE
	float a = tab[i] + tab[i + 1];
	float b = sqrt(a);
	tab[i + 1] = b;
	
}
\end{lstlisting}
W przypadku takim, jak powyżej pętla nie jest w stanie przetworzyć danych z maksymalną przepustowością~(II=1) ponieważ efekt działania kolejnej operacji zależy od czasu obliczenia \texttt{b}, które przypisywane jest do \texttt{tab[i + 1]}~(\texttt{tab[i]} w kolejnej iteracji). 

Istnieją jednak pewne sytuacje, gdy dbanie przez HLS o zapewnienie poprawności działania jest niepożądane i prowadzić będzie do zbyt dużego ograniczenia szybkości obliczeń. Takim przykładem może być próba implementacji w HLS procesora sterowanego listą rozkazów. W dużym uproszczeniu procesor taki przetwarza po kolei listę instrukcji, zaś każda instrukcja dokonuje pewnych operacji na rejestrach~(zmiennych wewnętrznych). 

\begin{lstlisting}[caption=Ilustracja problemu związanego z wykrywaniem zależności przez Vivado HLS i wpływu na wydajność]
while(true)
{
#pragma HLS PIPELINE
	...
	switch(inst)
	{
		case ADD:
			reg = reg + 1;
			break;
		case NEG:
			reg = -reg;
			break;
		case SQRT:
			reg = sqrt(reg);
			break;
		default:
			break;
	}
}
\end{lstlisting}
W powyższym przykładzie HLS dokonując analizy zależności pomiędzy wykorzystaniem \texttt{reg} założy konserwatywnie, że interwał przetwarzania instrukcji będzie określony poprzez instrukcję wykonującą się najdłużej~(tutaj jest to funkcja \texttt{sqrt()}), gdyż tylko wtedy istnieje pewność, że moduł będzie wykonywał się w sposób poprawny. Prowadzi to do sytuacji, że nawet instrukcja pusta~(realizowana przez \texttt{default}) będzie wykonywana tak długo jak \texttt{sqrt()}, co w jawny sposób ogranicza szybkość przetwarzania. Dyrektywa \texttt{DEPENDENCE} w założeniu pozwoli wymusić, by rozważanie zależności zostało w przypadku zmiennej \texttt{reg} pominięte\footnote{Stosując tę dyrektywę należy mieć pewność, że nie narusza to integralności algorytmu albo projektant jest w stanie poradzić sobie z ubocznymi konsekwencjami jej użycia.}.

\item \texttt{ALLOCATION}

Poszukiwanie najwydajniejszego rozwiązania z wykorzystaniem dyrektyw wymienionych do tej pory może prowadzić do nadmiernej konsumpcji zasobów raportowanej po wykonaniu syntezy HLS. Dyrektywa \texttt{ALLOCATION} pozwala na ograniczenie użycia operatorów~(np. dodawanie, mnożenie) oraz instancji funkcji występujących na danym poziomie hierarchii, przez co zostanie zwiększone ich współdzielenie pomiędzy operacjami.

%\item \texttt{LOOP\_MERGE}
\item \texttt{INLINE}

Każda funkcja, o ile nie jest wystarczająco mała, domyślnie jest oddzielnym elementem w hierarchii wywołań a przez to alokująca zasoby sprzętowe na własny użytek.  Stąd użycie zasobów może być optymalizowane tylko w obrębie danej funkcji. Użycie dyrektywy \texttt{INLINE} dla danej funkcji włącza ją do hierarchii funkcji nadrzędnej, potencjalnie dając możliwość lepszego współdzielenia zasobów przez różne operacje~(funkcje posiadające niewiele logiki są automatycznie włączane do hierarchii funkcji wywołującej).

\end{itemize}
\subsection{Integracja stworzonego modułu IP w układzie FPGA}
Stworzenie i weryfikacja poprawności działania modułu IP przy użyciu Vivado HLS i udostępnionych razem z nim narzędzi jest ważnym, ale nie ostatnim krokiem na drodze do jego działania w realnym układzie FPGA. Nowy moduł o stworzonej funkcjonalności przeważnie jest projektowany jako część większego systemu przetwarzania danych. Wiąże się to z koniecznością zaprojektowania poprawnego tzw.~\textit{schematu blokowego}~(ang. \textit{block design}) implementującego przepływ danych i kanały komunikacji między modułami. Elementy tego schematu blokowego muszą następnie zostać poddane syntezie do reprezentacji za pomocą netlisty by następnie dokonać próby jej implementacji i wygenerowania pliku konfiguracyjnego dla konkretnego urządzenia. Wszystkie te etapy wykonywane są przez narzędzie zwane \textit{Vivado}.
\subsubsection{Budowa schematu blokowego}
Wraz z Vivado Design Suite dostarczana jest baza często używanych i pomocnych w rozwiązywaniu wielu problemów IP\footnote{Dostęp do niektórych z nich może być ograniczony przez odrębne postanowienia licencyjne.}. Wśród nich należy wymienić:
\begin{itemize}
\item Moduły będące implementacją prostych rozwiązań procesorowych~(tzw.~\textit{softprocesory}) mogących pełnić funkcję mikrokontrolerów monitorujących i sterujących działaniem całego budowanego systemu. Ich wydajność oraz maksymalne częstotliwości pracy nie pozwolą wydajnie przeprowadzać skomplikowanych operacji, jednak ich zaletą jest szeroka możliwość dostrojenia ich parametrów w zakresie przewidzianym przez producenta do potrzeb użytkownika. Przykładem takiego procesora jest 32-bitowy  \texttt{Microblaze}~\cite{MB_QUICK}\cite{MB_UG984}, którego podstawowa konfiguracja może być rozszerzona m. in. o:
\begin{itemize}
\item pełną obsługę obliczeń zmiennopozycyjnych pojedynczej precyzji~(\texttt{float}),
\item buforowany dostęp do danych i instrukcji za pomocą pamięci podręcznej~(ang.~\textit{cache}) o wybranej konfiguracji rozmiaru,
\item rozbudowany moduł do analizy błędów wykonania.
\end{itemize}
Szczególnie istotny jest tutaj fakt, iż \texttt{Microblaze} posiada własny kompilator C/C++, który jest świadomy wybranej przez użytkownika konfiguracji tego~IP. W szczególności, jeśli użytkownik zdecydował się umieścić moduł akcelerujący przetwarzanie danych zmiennopozycyjnych~(ang.~\textit{floating-point processing unit},~FPU) wtedy kompilator użyje dedykowanych instrukcji wszędzie tam, gdzie zajdzie potrzeba wykonania operacji na liczbach zmiennopozycyjnych~(w przeciwnym razie funkcjonalność ta będzie emulowana za pomocą sekwencji operacji podstawowych).
\item Kontroler pamięci zewnętrznej DDR3/DDR4 pozwalający nawiązać komunikację z zasobami mogącymi przechowywać znacznie większe ilości danych niż oferują to elementy wbudowane w FPGA.
\item Układ generujący sygnały zegarowe o zadanej częstotliwości.
\item Licznik czasu pozwalający mierzyć jak długo wykonywane są poszczególne zadania przez tworzony system.
\item Cała rodzina IP służąca do przetwarzania, konwersji i transmisji sygnałów reprezentujących dane wizualne.
\end{itemize}
Umieszczenie potrzebnych modułów na schemacie blokowym wymaga następnie, aby połączyć ze sobą odpowiednie porty wejścia/wyjścia w taki sposób, aby cały system działał poprawnie~(zobacz schemat ukazany na rysunku~\ref{ch2:img:bd_example}). Pomocny okazuje się na tym etapie dostęp do podręcznika użytkownika danego modułu, do którego uzyskuje się dostęp bezpośrednio z poziomu widoku schematu blokowego. Ponadto Vivado potrafi wykrywać niepołączone interfejsy z rodziny \texttt{AXI} oraz sygnały \texttt{reset} i zegara (\texttt{clock}), oferując automatyzację połączeń. Trzeba pamiętać, że modyfikacja konfiguracji modułu może prowadzić do powstania, usunięcia bądź zmiany szerokości bitowej portu/portów - w związku z tym może być wymagana interwencja ze strony użytkownika celem zaktualizowania przepływu sygnałów między modułami.

Poprawność konfiguracji połączeń można sprawdzić dzięki wbudowanemu narzędziu. Dokonuje ono walidacji czy wszystkie wymagane porty zostały połączone ze sobą oraz czy spełnione zostały wszystkie inne warunki~(ang.~\textit{constraints}) wymagane do poprawnego działania projektu.

\begin{landscape}

\begin{center}
\addimage{chapters/ch2/img/bd_example.png}{scale=0.41}{Schemat blokowy prostego przykładowego systemu przetwarzania danych. Sercem systemu w tym przypadku jest mikroprocesor \texttt{Microblaze}  wyposażony w możliwość sprawdzania poprawności przetwarzania za pomocą \texttt{Microblaze Debug Module}. Drugim istotnym elementem jest generator interfejsu do pamięci zewnętrznej \texttt{DDR4 SDRAM} - dzięki niemu możliwe jest zapisywanie i odczyt danych przez \texttt{Microblaze} do i z zewnętrznej względem układu FPGA pamięci RAM. Jednak, aby \texttt{Microblaze} mógł się komunikować z modułem zarządzającym pamięcią zewnętrzną są one połączone ze sobą za pomocą łącznika danych~(\texttt{AXI Interconnect}). Na tej samej zasadzie z mikroprocesorem połączone są licznik czasu \texttt{AXI Timer} oraz moduł do komunikacji zewnętrznej \texttt{AXI Uartlite}~(wykorzystywany najczęściej do wypisywania tekstu na terminalu). W systemie tym występują dwa główne sygnały zegarowe: pierwszy (\texttt{default\_sysclk1\_300}) jest sygnałem bazowym interfejsu pamięci zewnętrznej, zaś drugi generowany przez \texttt{Clocking Wizard} decyduje m. in o wydajności pracy mikroprocesora.  }{Schemat blokowy prostego przykładowego systemu przetwarzania danych}{ch2:img:bd_example}
\end{center}

\end{landscape}

\subsubsection{Synteza}
Narzędzia wchodzące w skład Vivado, które dokonują syntezy, przetwarzają niezależny od architektury kod RTL do postaci odwzorowującej przepływ danych z użyciem konkretnych elementów logicznych znajdujących się w układzie FPGA. Trzeba jednak zdawać sobie sprawę z tego, iż napisany w odpowiedni sposób kod RTL może ułatwić narzędziom ekstrakcję konkretnych zachowań, które będą mogły być odwzorowane bezpośrednio w wyspecjalizowanych układach np. DSP. 

Powyższy problem nie występuje w przypadku tworzenia modułów z użyciem Vivado HLS. Dzięki temu, iż wie ono, dla jakiego układu FPGA dokonywana jest translacja, tworzone są takie konstrukcje w kodzie Verilog/VHDL, które wywołają syntezę optymalnej sekwencji elementów logicznych. 

Mimo to nie jest prawdą, że dla danego projektu, na który składają się poszczególne moduły IP, istnieje tylko jedna reprezentacja za pomocą netlisty - jej końcowa postać zależy od parametrów syntezy. Kilka standardowych zbiorów ustawień, zwanych strategiami, dostarczanych jest przez producenta. Wśród nich są takie~(\texttt{Flow\_AreaOptimized\_medium}, \texttt{Flow\_AreaOptimized\_high}), które dostosowują netlistę by zajmowała jak najmniej zasobów, ale też i takie które w zamian za zwiększenie użycia logiki układu w teorii mogą pozwolić na uzyskanie wyższych częstotliwości pracy~(\texttt{Flow\_PerfOptimized\_high}). Dozwolone jest również samodzielnie dokonywanie zmian, a tym samym tworzenie własnych strategii syntezy~\cite{UG901}. 

\subsubsection{Implementacja}
Proces implementacji za pomocą Vivado polega na umieszczeniu i połączeniu w układzie FPGA wytworzonej na etapie syntezy netlisty w taki sposób, aby spełnione były wszelkie warunki nałożone na projekt~(dotyczące np. opóźnień sygnału, które wynikają z zastosowanej częstotliwości zegara, wyprowadzeń odpowiednich sygnałów na wybrane porty wejścia/wyjścia z układu FPGA\footnote{Przykładem tego może być wykorzystanie zewnętrznej względem układu FPGA pamięci RAM.}), dając w rezultacie konfigurację działającego układu o zaprojektowanej funkcjonalności. Proces ten składa się w ogólności z kilku pod-procesów, z których część jest opcjonalna, jednak zwiększają one prawdopodobieństwo~(poprzez dokonywane przez nie optymalizacje) spełnienia specyficznych warunków stawianych przed projektem jak np. wysokiej częstotliwości przetwarzania czy założonego limitu konsumpcji energii elektrycznej~\cite{UG904}. 

Tak samo jak w przypadku syntezy, producent dostarcza kilkunastu różnych strategii implementacji pozwalających zoptymalizować projekt pod wybranym aspektem (np. poboru mocy, konsumpcji bloków logicznych, częstotliwości pracy). Można również tworzyć własne strategie.

Poziom komplikacji danego układu, rozumianego jako zespół tworzącego go modułów IP, wybrana strategia implementacji, szybkość komputera~(częstotliwość procesora oraz możliwości przetwarzania współbieżnego, dostępna pojemność pamięci RAM, szybkość dysku twardego/SSD) oraz rodzaj docelowego układu FPGA wpływać będą na czas potrzebny na przeprowadzenie procesu implementacji - ten może wynosić tak kilkanaście minut jak i kilkadziesiąt godzin. Aby efekt implementacji uznać za poprawny, spełnione muszą być następujące warunki:
\begin{itemize}
\item Układ FPGA musi posiadać wystarczającą ilość elementów logicznych wymaganych do implementacji projektu. Praktyczna zasada mówi o tym, aby projekt nie wymagał użycia więcej niż 70\% zasobów~\cite{Designing_with_Xilinx}.
\item Sieć połączeń musi być w stanie skomunikować wszystkie potrzebne punkty~(porty sygnałowe elementów logicznych) ze sobą. 
\item Nie mogą zostać naruszone wymagania czasowe związane z propagacją sygnałów. 

Sygnały zegarowe są elementem synchronizacyjnym zapewniającym, że przesyłanie danych pomiędzy kolejnymi etapami przetwarzania odbywa się bez błędów. Kiedy sygnał reprezentujący wartość w wyniku działania danego elementu logicznego ulega zmianie, w czasie dokonywania się tej zmiany wartość jest niestabilna. Stąd wymagany jest pewien czas~(ten zależny jest między innymi od układu FPGA oraz zakresu temperatur pracy), zanim będzie można użyć tej nowej wartości. 
\begin{itemize}
\item \textit{Czas konfiguracji} $t_s$~(ang. \textit{setup time}) jest to najmniejszy czas przed kolejnym zboczem zegara, kiedy sygnał musi być ustabilizowany.
\item \textit{Okres wstrzymania} $t_h$~(ang. \textit{hold time}) jest minimalnym czasem, przez który sygnał musi być stabilny po zboczu zegara.
\end{itemize}

\addimage{chapters/ch2/img/clock_sync.png}{scale=0.8}{Czas konfiguracji i okres wstrzymania - $t_s$ oraz $t_h$ definiują tzw. okno czasowe w którym sygnał musi być stabilny. Synchronizacja następuje względem narastającego zbocza sygnału zegarowego}{Czas konfiguracji i okres wstrzymania}{ch2:img:clock_sync}

W przypadku niespełnienia którejkolwiek z powyższych metryk ($t_s$, $t_h$) w którymkolwiek miejscu przetwarzania danych, mamy do czynienia z naruszeniem~(ang. \textit{setup violation}, \textit{hold violation}), które najprawdopodobniej będzie wiązało się z niepoprawnie działającym układem. Raport po implementacji prezentuje dodatkowe parametry mówiące o tym:
\begin{itemize}
\item ile wynosi największe spóźnienie się z konfiguracją sygnału tzw.~\textit{worst negative slack}~(WNS),
\item o ile za krótko wynosi najgorszy z okresów wstrzymania tzw.~\textit{worst hold slack}~(WHS).
\end{itemize}
Jeśli implementacja przebiegła poprawnie WNS oraz WHS są nieujemne.

\end{itemize}

%\subsection{Dobór układu w projekcie}

%\section{Sytnteza układu oraz implementacja w FPGA}
\section*{Podsumowanie}
W powyższych paragrafach, dokonano zwięzłego opisu tego, czym są układy FPGA, na jakiej zasadzie działają oraz jakiego rodzaju wyzwania wiążą się z ich wykorzystaniem. Jednym z nich jest niewątpliwie sposób, w jaki dokonuje się opisu zachowania sprzętu, czyli sposobu przetwarzania danych. Zaprezentowane rozwiązanie polega na wykorzystaniu syntezy wysokiego poziomu, w tym przypadku Vivado HLS, która na podstawie algorytmicznego opisu za pomocą C/C++ o zmodyfikowanych możliwościach~(tj. z ograniczoną składnią i dyrektywami optymalizacyjnymi) potrafi dokonać poprawnej konwersji do języków opisu sprzętu. Niewątpliwą zaletą takiego rozwiązania jest fakt, iż nie wymaga ono specjalistycznej wiedzy oraz zwiększa produktywność programisty/projektanta. Z drugiej jednak strony, oddzielne badania i porównania sugerują, iż osiągnięcie identycznie niskiego zużycia zasobów połączonego z wysoką wydajnością, jaką zapewnia bezpośrednia konfiguracja sprzętu z użyciem VHDL czy Verilog, jest właściwie niemożliwa. Mimo to Vivado HLS wydaje się być ciekawym narzędziem, zwłaszcza do tworzenia rozwiązań prototypowych.
